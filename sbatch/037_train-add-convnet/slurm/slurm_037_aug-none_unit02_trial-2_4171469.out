2018-01-19 13:29:10.890144: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-19 13:29:10.890380: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-19 13:29:10.890398: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-19 13:29:10.890407: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-19 13:29:10.890415: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-01-19 13:28:54.621328 Start.
Training additive context-aware convnet on BirdVox-70k. 
Training set: unit03, unit05, unit07.
Validation set: unit10, unit01.
Test set: unit02.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_dense1 (Dense)              (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense2 (Dense)              (None, 1)             64          spec_dense1[0][0]                
____________________________________________________________________________________________________
bg_dense2 (Dense)                (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
add (Add)                        (None, 1)             0           spec_dense2[0][0]                
                                                                   bg_dense2[0][0]                  
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             2           add[0][0]                        
====================================================================================================
Total params: 682,078
Trainable params: 682,076
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.501587  7.945893  0.492920  8.084066
1   0.497925  8.004276  0.497192  8.015952
2   0.506226  7.871942  0.501953  7.940055
3   0.497559  8.010114  0.503662  7.912810
4   0.496216  8.031521  0.499023  7.986761
5   0.504150  7.905025  0.498779  7.990653
6   0.502563  7.930324  0.497070  8.017899
7   0.490601  8.121041  0.504883  7.893349
8   0.503906  7.908917  0.502441  7.932271
9   0.490723  8.119095  0.497192  8.015952
10  0.498657  7.992599  0.499878  7.973138
11  0.506714  7.864157  0.499268  7.982869
12  0.498047  8.002330  0.503418  7.916702
13  0.502075  7.938109  0.503052  7.922540
14  0.513672  7.753230  0.499146  7.984815
15  0.506470  7.868050  0.510010  7.811613
16  0.499268  7.982869  0.506958  7.860265
17  0.501465  7.947839  0.484497  8.218346
18  0.492920  8.084066  0.506714  7.864157
19  0.512817  7.766853  0.511963  7.780475
20  0.510254  7.807721  0.502197  7.936163
21  0.495117  8.049036  0.497070  8.017899
22  0.502441  7.932271  0.500122  7.969246
23  0.493164  8.080173  0.498535  7.994545
24  0.501465  7.947839  0.499878  7.973138
25  0.496826  8.021791  0.500122  7.969246
26  0.492432  8.091850  0.496948  8.019845
27  0.500000  7.971192  0.495483  8.043198
28  0.499146  7.984815  0.496216  8.031521
29  0.498901  7.988707  0.497559  8.010114
30  0.508545  7.834966  0.501221  7.951731
31  0.489380  8.140502  0.505615  7.881672

2018-01-19 17:46:06.170906 Finish.
Total elapsed time: 04:17:12.17.
