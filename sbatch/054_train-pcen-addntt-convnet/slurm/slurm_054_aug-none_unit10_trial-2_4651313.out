2018-02-24 20:27:14.511474: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.511704: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.511716: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.511721: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.511726: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.808889 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit01, unit02, unit03.
Validation set: unit05, unit07.
Test set: unit10.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.869995  0.532291  0.876587  0.596134
1   0.504272  7.998471  0.500488  8.081418
2   0.500977  8.071042  0.501709  8.057086
3   0.502563  8.041558  0.495728  8.150089
4   0.498779  8.099446  0.498169  8.107894
5   0.494263  8.169607  0.485107  8.315972
6   0.506958  7.962694  0.506958  7.961643
7   0.499878  8.074799  0.491699  8.205694
8   0.496338  8.130072  0.496338  8.129241
9   0.498291  8.096994  0.499756  8.072638
10  0.486938  8.278541  0.504883  7.988642
11  0.505981  7.970314  0.494019  8.162530
12  0.497803  8.100980  0.503540  8.007966
13  0.493896  8.162905  0.511353  7.881065
14  0.510132  7.900300  0.497803  8.098597
15  0.498535  8.086405  0.509277  7.912890
16  0.509644  7.906652  0.511230  7.880753
17  0.506104  7.963103  0.493530  8.165486
18  0.504639  7.986197  0.488770  8.241747
19  0.496948  8.109721  0.500610  8.050504
20  0.495483  8.132976  0.496582  8.115114
21  0.494263  8.152365  0.493286  8.167982
22  0.497559  8.099014  0.507690  7.935612
23  0.497314  8.102772  0.487671  8.258135
24  0.500977  7.991845  0.502563  7.959318
25  0.503052  7.946534  0.507446  7.872103
26  0.507324  7.870727  0.506958  7.873618
27  0.502441  7.943346  0.500732  7.968563
28  0.500244  7.974775  0.496338  8.035649
29  0.500977  7.960614  0.496338  8.033603
30  0.497925  8.007563  0.500732  7.962148
31  0.488159  8.162096  0.499512  7.980669
32  0.500732  7.960876  0.510742  7.801005
33  0.497070  8.018750  0.505249  7.888173
34  0.502686  7.928902  0.494141  8.065008
35  0.507446  7.852796  0.502075  7.938349
36  0.498169  8.000570  0.503906  7.909058
37  0.508911  7.829236  0.490845  8.117230
38  0.502441  7.932332  0.503052  7.922586
39  0.503296  7.918682  0.498413  7.996517
40  0.506592  7.866122  0.505371  7.885578
41  0.492798  8.086022  0.514160  7.745453
42  0.504150  7.905031  0.497192  8.015956
43  0.501953  7.940058  0.495361  8.045146
44  0.498413  7.996493  0.505859  7.877781
45  0.501953  7.940056  0.499146  7.984815
46  0.499023  8.051128  0.503174  8.085255
47  0.504639  8.048600  0.514893  7.877916
48  0.501587  8.090026  0.500244  8.109598
49  0.500366  8.105879  0.494019  8.206519
50  0.495483  8.181391  0.508545  7.969393
51  0.499268  8.117557  0.498657  8.126055
52  0.494507  8.191683  0.492676  8.219945
53  0.501221  8.081017  0.496582  8.154590
54  0.492432  8.220330  0.493652  8.199501
55  0.498169  8.125575  0.502686  8.051649
56  0.496948  8.143017  0.497192  8.137974
57  0.500610  8.081793  0.496582  8.145628
58  0.502197  8.054045  0.497925  8.121829
59  0.497192  8.132573  0.502808  8.041001
60  0.497437  8.126525  0.500000  8.084157
61  0.503052  8.033938  0.492310  8.206049
62  0.496826  8.132238  0.501221  8.060394
63  0.497070  8.126301  0.500488  8.070221

2018-02-25 04:19:16.464460 Finish.
Total elapsed time: 07:52:07.46.
