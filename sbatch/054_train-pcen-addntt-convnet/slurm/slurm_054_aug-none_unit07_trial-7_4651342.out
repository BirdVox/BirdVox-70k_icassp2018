2018-02-24 20:27:16.970124: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:16.970452: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:16.970465: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:11.927766 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit10, unit01, unit02.
Validation set: unit03, unit05.
Test set: unit07.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.503174  7.931433  0.495239  8.056240
1   0.499023  7.994523  0.504639  7.903731
2   0.495605  8.046706  0.495361  8.049655
3   0.506470  7.871801  0.491089  8.116322
4   0.499268  7.985389  0.513306  7.761100
5   0.505859  7.879431  0.505127  7.890769
6   0.508301  7.876559  0.497681  8.102881
7   0.502319  8.024161  0.497681  8.097491
8   0.496216  8.136398  0.496338  8.157510
9   0.493896  8.158086  0.501953  8.003168
10  0.493408  8.124844  0.495850  8.074404
11  0.503296  7.948278  0.506104  7.897349
12  0.500854  7.976726  0.508179  7.856263
13  0.501587  7.958632  0.499146  7.995169
14  0.494385  8.069256  0.500244  7.974239
15  0.503174  7.926296  0.504761  7.899896
16  0.496216  8.035272  0.491577  8.108467
17  0.501099  7.956093  0.507568  7.852437
18  0.493774  8.071958  0.496460  8.028804
19  0.495605  8.042173  0.505615  7.882374
20  0.499146  7.985357  0.493164  8.080579
21  0.488281  8.158325  0.504517  7.899412
22  0.499268  7.983037  0.506836  7.862332
23  0.496094  8.033556  0.500732  7.959579
24  0.505005  8.158903  0.503052  8.210022
25  0.505249  8.150383  0.500366  8.208634
26  0.507690  8.075205  0.505005  8.104620
27  0.490112  8.333333  0.503540  8.106455
28  0.496704  8.207878  0.495972  8.211549
29  0.496582  8.194844  0.496704  8.186486
30  0.500366  8.122050  0.501221  8.103237
31  0.513062  7.908104  0.507324  7.996579
32  0.491943  8.241069  0.506226  8.007657
33  0.495728  8.174086  0.498901  8.120302
34  0.507935  7.972390  0.514282  7.867868
35  0.498291  8.123628  0.501465  8.070553
36  0.496338  8.151425  0.491089  8.234308
37  0.502686  8.045777  0.501221  8.067799
38  0.487061  8.294522  0.483765  8.346149
39  0.488647  8.266012  0.505737  7.989131
40  0.491699  8.214027  0.507690  7.954918
41  0.498779  8.097241  0.501953  8.044790
42  0.495117  8.153737  0.492432  8.195802
43  0.506348  7.970347  0.502319  8.034140
44  0.497437  8.111777  0.498169  8.098932
45  0.501221  8.048780  0.494751  8.152123
46  0.503784  8.005668  0.511597  7.878919
47  0.500610  8.055251  0.496948  8.113563
48  0.502075  8.030290  0.492798  8.179218
49  0.501587  8.037025  0.500488  8.054234
50  0.502686  8.018388  0.501953  8.029792
51  0.501709  8.033388  0.507202  7.944535
52  0.499878  8.062327  0.487427  8.262779
53  0.502319  8.022547  0.504028  7.994827
54  0.504150  7.992723  0.503906  7.996535
55  0.499268  8.071208  0.501709  8.031774
56  0.498535  8.082869  0.509033  7.913607
57  0.497925  8.092615  0.488403  8.246051
58  0.494751  8.143716  0.492554  8.179113
59  0.490479  8.212548  0.501709  8.031524
60  0.509521  7.905595  0.502075  8.025609
61  0.498779  8.078730  0.499634  8.064954
62  0.500854  8.045278  0.494995  8.139719
63  0.500122  8.057081  0.497681  8.096432

2018-02-25 04:15:01.889268 Finish.
Total elapsed time: 07:47:50.89.
