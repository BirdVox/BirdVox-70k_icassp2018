2018-02-24 20:27:12.656513: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.656774: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.656786: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.656792: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.656796: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:08.256670 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit02, unit03, unit05.
Validation set: unit07, unit10.
Test set: unit01.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.900391  1.449061  0.500244  8.003242
1   0.492188  8.127440  0.500366  7.993799
2   0.507935  7.870796  0.503052  7.946498
3   0.491089  8.135400  0.499023  8.007192
4   0.494263  8.081580  0.501343  7.967266
5   0.507446  7.868670  0.499390  7.995873
6   0.490601  8.134873  0.498779  8.003408
7   0.505005  7.903182  0.503784  7.921703
8   0.487183  8.185519  0.495850  8.046526
9   0.505859  7.886202  0.492798  8.093716
10  0.503540  7.921811  0.496704  8.030167
11  0.498413  8.002357  0.502319  7.939538
12  0.505737  7.884558  0.505127  7.893819
13  0.498291  8.002378  0.500000  7.974729
14  0.496948  8.023020  0.498535  7.997139
15  0.502930  7.929657  0.493896  8.170024
16  0.492065  8.199602  0.504028  8.001861
17  0.503784  8.004420  0.496704  8.117438
18  0.497559  8.102866  0.508545  7.925072
19  0.498657  8.083873  0.492554  8.181732
20  0.498047  8.092774  0.494873  8.143550
21  0.501953  8.029126  0.494995  8.140999
22  0.501465  8.036497  0.503784  7.998914
23  0.497925  8.093198  0.501709  8.032063
24  0.495117  8.138201  0.509521  7.905934
25  0.501953  8.027848  0.509644  7.903829
26  0.500244  8.055281  0.486328  8.279539
27  0.501343  8.037502  0.503174  8.007963
28  0.495728  8.127965  0.500977  8.043346
29  0.495972  8.124004  0.491699  8.192860
30  0.500000  8.059062  0.498657  8.080700
31  0.496216  8.120048  0.497925  8.092500
32  0.506836  7.948868  0.498535  8.082660
33  0.504395  7.988218  0.507446  7.939029
34  0.501465  8.035438  0.499634  8.064951
35  0.494507  8.147558  0.507446  7.948007
36  0.499023  8.075314  0.504761  7.982316
37  0.502563  8.017730  0.493042  8.171198
38  0.500732  8.047243  0.498901  8.076137
39  0.501709  7.989490  0.499756  8.011448
40  0.503296  7.954351  0.496216  8.066627
41  0.496704  8.058255  0.499756  8.008997
42  0.499268  8.016154  0.498657  8.025237
43  0.499023  8.018728  0.507324  7.885703
44  0.502075  7.968672  0.506958  7.890096
45  0.506226  7.901020  0.494873  8.081235
46  0.510986  7.823562  0.507080  7.885031
47  0.501953  7.965946  0.499023  8.011816
48  0.496704  8.047946  0.499512  8.002326
49  0.510498  7.826313  0.499878  7.994746
50  0.492676  8.108689  0.489380  8.160348
51  0.501831  7.960966  0.498291  8.016517
52  0.499268  8.000074  0.500122  7.985574
53  0.503418  7.932169  0.501221  7.966339
54  0.499390  7.994693  0.500122  7.982182
55  0.506104  7.886018  0.504272  7.914410
56  0.499390  7.991488  0.503052  7.932348
57  0.500000  7.980281  0.489136  8.152775
58  0.500488  7.971123  0.507324  7.861490
59  0.498291  8.004893  0.493652  8.078252
60  0.493286  8.083544  0.503052  7.927328
61  0.512207  7.780890  0.496582  8.029526
62  0.496582  8.029110  0.498535  7.997574
63  0.501099  7.956352  0.501099  7.956017

2018-02-25 04:26:29.128770 Finish.
Total elapsed time: 07:59:21.13.
