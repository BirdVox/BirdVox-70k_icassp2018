2018-02-24 20:27:13.583363: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.583627: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.583641: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.583646: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.583651: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.623643 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit05, unit07, unit10.
Validation set: unit01, unit02.
Test set: unit03.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.502197  8.041601  0.498901  8.092683
1   0.499878  8.075207  0.492188  8.197542
2   0.504761  7.993507  0.490845  8.216519
3   0.504883  7.989155  0.497803  8.102248
4   0.499023  8.081700  0.510376  7.897904
5   0.502686  8.021164  0.503418  8.008710
6   0.492310  8.187203  0.503784  8.001738
7   0.506348  7.959981  0.494385  8.152391
8   0.498779  8.081212  0.510010  7.899874
9   0.502319  8.023556  0.496460  8.117744
10  0.503540  8.003412  0.498535  8.083883
11  0.496704  8.113230  0.507202  7.943868
12  0.497314  8.103111  0.486816  8.272201
13  0.494873  8.142247  0.509644  7.904085
14  0.496460  8.116507  0.492188  8.185304
15  0.498657  8.080971  0.496704  8.112402
16  0.493530  8.163519  0.499390  8.069042
17  0.489868  8.222482  0.503418  8.004060
18  0.509155  7.911566  0.498657  8.080757
19  0.506592  7.952853  0.498901  8.076712
20  0.501099  8.047385  0.498535  8.060132
21  0.495850  8.078415  0.505737  7.904551
22  0.508423  7.853827  0.499146  7.995837
23  0.495361  8.052850  0.498291  8.003581
24  0.488159  8.163591  0.494507  8.061205
25  0.508057  7.844473  0.492310  8.094955
26  0.497559  8.010931  0.498779  7.991201
27  0.510132  7.810051  0.498657  7.992855
28  0.508911  7.829306  0.498535  7.994663
29  0.496582  8.025764  0.501221  7.951784
30  0.499878  7.973174  0.497314  8.014029
31  0.502686  7.928394  0.502441  7.925753
32  0.501343  8.104858  0.509399  8.098998
33  0.501953  8.200341  0.511108  8.037466
34  0.491943  8.334605  0.488647  8.376837
35  0.506226  8.084068  0.500366  8.169509
36  0.499634  8.173224  0.495850  8.226421
37  0.493164  8.262598  0.510742  7.972392
38  0.496582  8.194318  0.505859  8.038671
39  0.495239  8.204238  0.499023  8.137811
40  0.505249  8.032491  0.503784  8.051290
41  0.489868  8.271201  0.496216  8.164653
42  0.499756  8.103751  0.503174  8.044961
43  0.494263  8.185253  0.499390  8.099413
44  0.501953  8.055221  0.508301  7.950160
45  0.499146  8.095277  0.493286  8.187383
46  0.501831  8.047587  0.496582  8.130226
47  0.493530  8.177686  0.489624  8.239011
48  0.494507  8.158879  0.499512  8.076861
49  0.500610  8.057984  0.502930  8.019501
50  0.508789  7.924113  0.493774  8.165235
51  0.504150  7.997239  0.497925  8.096880
52  0.491455  8.200564  0.491455  8.200012
53  0.502686  8.018537  0.499634  8.067299
54  0.503296  8.007921  0.497192  8.105974
55  0.493774  8.160801  0.504028  7.995286
56  0.504639  7.985254  0.511475  7.874895
57  0.505493  7.971165  0.500732  8.047773
58  0.500000  8.059479  0.499634  8.065294
59  0.498413  8.084902  0.489380  8.230440
60  0.502197  8.023803  0.497681  8.096563
61  0.502319  8.021767  0.498047  8.090606
62  0.497192  8.104360  0.500854  8.045319
63  0.499878  8.061048  0.506348  7.956759

2018-02-25 04:19:01.266809 Finish.
Total elapsed time: 07:51:52.27.
