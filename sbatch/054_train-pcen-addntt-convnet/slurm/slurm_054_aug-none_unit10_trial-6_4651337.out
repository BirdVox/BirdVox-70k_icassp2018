2018-02-24 20:27:14.725677: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.725994: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.726007: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:12.070588 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit01, unit02, unit03.
Validation set: unit05, unit07.
Test set: unit10.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.506592  7.877125  0.502563  7.940450
1   0.507690  7.857988  0.513794  7.759565
2   0.502441  7.940437  0.503296  7.925729
3   0.499390  7.988098  0.499512  7.985713
4   0.492310  8.147473  0.508423  7.934360
5   0.497070  8.114438  0.504150  7.998675
6   0.499878  8.066771  0.499756  8.068124
7   0.499268  8.075557  0.505249  7.978756
8   0.500244  8.046972  0.496338  8.088916
9   0.491821  8.150375  0.499878  8.014489
10  0.492920  8.120196  0.499634  8.008451
11  0.498901  8.016265  0.497559  8.034106
12  0.505371  7.906571  0.499512  7.997217
13  0.505371  7.901485  0.495728  8.053079
14  0.489136  8.156373  0.494019  8.076871
15  0.507812  7.855582  0.498535  8.002211
16  0.495850  8.043970  0.498535  8.000185
17  0.515625  7.726932  0.503906  7.913021
18  0.495483  8.046699  0.503906  7.911866
19  0.498901  7.991206  0.493408  8.078370
20  0.499878  7.974894  0.501099  7.955131
21  0.503662  7.914021  0.507080  7.859311
22  0.498413  7.997309  0.494507  8.059428
23  0.495239  8.047629  0.504517  7.899616
24  0.494507  8.059112  0.497192  8.016223
25  0.495972  8.035628  0.498901  7.988872
26  0.495239  8.047219  0.496338  8.029672
27  0.493652  8.072463  0.500000  7.971247
28  0.502075  7.938150  0.504150  7.905055
29  0.493408  8.076303  0.488525  8.154140
30  0.499390  7.980934  0.493286  8.078235
31  0.495972  8.035418  0.494507  8.058770
32  0.498291  7.998440  0.500977  7.955625
33  0.502319  7.934218  0.494995  8.050983
34  0.506226  7.871942  0.499512  7.978977
35  0.494385  8.060713  0.499390  7.980923
36  0.504272  8.157537  0.500000  8.236173
37  0.485474  8.454859  0.509521  8.054175
38  0.501587  8.172270  0.504517  8.116212
39  0.487793  8.378469  0.505005  8.094237
40  0.501099  8.151303  0.508423  8.027663
41  0.499146  8.172258  0.495850  8.220672
42  0.496948  8.198765  0.492676  8.263612
43  0.504883  8.063258  0.501099  8.120800
44  0.503906  8.072438  0.505859  8.037967
45  0.498169  8.159209  0.498413  8.152653
46  0.510620  7.953497  0.498535  8.145952
47  0.498047  8.151660  0.503296  8.064944
48  0.505005  8.035417  0.505371  8.027567
49  0.500366  8.106389  0.502197  8.075050
50  0.489014  8.285797  0.500977  8.091244
51  0.496216  8.166306  0.502808  8.058396
52  0.501831  8.072524  0.504272  8.031568
53  0.505371  8.012301  0.499512  8.105188
54  0.496338  8.154833  0.498169  8.123811
55  0.490845  8.240397  0.502441  8.052018
56  0.501831  8.060435  0.498169  8.118044
57  0.494019  8.183564  0.504395  8.014953
58  0.500610  8.074618  0.492432  8.205121
59  0.497070  8.129077  0.499634  8.086489
60  0.496582  8.134454  0.497925  8.111597
61  0.509766  7.919581  0.501587  8.050254
62  0.500244  8.070796  0.502808  8.028392
63  0.499146  8.086388  0.508545  7.933873

2018-02-25 04:24:23.764463 Finish.
Total elapsed time: 07:57:11.76.
