2018-02-24 20:27:12.249697: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.249903: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.249915: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.249920: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.249925: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.741690 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit02, unit03, unit05.
Validation set: unit07, unit10.
Test set: unit01.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.509033  7.827552  0.496094  8.033682
1   0.494873  8.053063  0.502319  7.933217
2   0.506836  7.946383  0.496704  8.151194
3   0.498901  8.101283  0.504639  7.999594
4   0.510620  7.898732  0.505859  7.972101
5   0.496460  8.121617  0.503418  8.007886
6   0.506470  7.957692  0.495483  8.133952
7   0.491333  8.200311  0.503052  8.010985
8   0.497314  8.167793  0.489990  8.293712
9   0.499146  8.133490  0.494385  8.197172
10  0.496704  8.150348  0.503174  8.037938
11  0.491089  8.222343  0.507935  7.945817
12  0.500366  8.059173  0.496826  8.108516
13  0.504517  7.979359  0.498535  8.068343
14  0.496094  8.101381  0.491577  8.167671
15  0.503052  7.979488  0.494629  8.108683
16  0.501343  7.997005  0.500122  8.011985
17  0.500366  8.004032  0.497314  8.048779
18  0.497803  8.037484  0.497803  8.034123
19  0.494385  8.085616  0.495117  8.071082
20  0.497803  8.025745  0.498413  8.013620
21  0.493042  8.097156  0.509888  7.826621
22  0.505859  7.889137  0.494019  8.076308
23  0.504639  7.905634  0.499268  7.989992
24  0.500000  7.977248  0.507568  7.855603
25  0.494385  8.064966  0.505005  7.894909
26  0.504761  7.898195  0.496216  8.033871
27  0.505981  7.907133  0.493774  8.296710
28  0.505615  8.100120  0.491577  8.319508
29  0.512207  7.981150  0.500732  8.160653
30  0.502808  8.122542  0.494873  8.246043
31  0.504150  8.092670  0.497192  8.201169
32  0.495972  8.217587  0.503784  8.088536
33  0.491577  8.282456  0.493164  8.254138
34  0.490356  8.296880  0.508179  8.007183
35  0.501465  8.113156  0.505981  8.038180
36  0.499878  8.134551  0.498169  8.160150
37  0.505005  8.048179  0.509888  7.967745
38  0.494507  8.214067  0.498413  8.149568
39  0.498657  8.144229  0.498901  8.138936
40  0.496460  8.177046  0.501953  8.087307
41  0.495361  8.192455  0.503540  8.059564
42  0.498657  8.137283  0.496704  8.167806
43  0.509155  7.966224  0.501221  8.093240
44  0.501709  8.084542  0.494019  8.207680
45  0.513184  7.897991  0.500122  8.107736
46  0.499512  8.116811  0.501343  8.086534
47  0.501709  8.079876  0.500244  8.102725
48  0.500000  8.105900  0.497681  8.142515
49  0.497192  8.149612  0.506104  8.005197
50  0.503662  8.043755  0.503662  8.042950
51  0.498657  8.122804  0.496704  8.153454
52  0.505615  8.008982  0.508301  7.964838
53  0.507690  7.973805  0.493042  8.209022
54  0.489868  8.259277  0.505249  8.010449
55  0.504639  8.019354  0.504761  8.016437
56  0.499756  8.096144  0.498291  8.118774
57  0.495850  8.157134  0.506348  7.986918
58  0.497559  8.127565  0.502319  8.049799
59  0.500854  8.072373  0.493774  8.185439
60  0.498047  8.115523  0.504517  8.010180
61  0.507568  7.959932  0.499512  8.088721
62  0.507935  7.951902  0.505737  7.986252
63  0.501709  8.050132  0.509644  7.921189

2018-02-25 04:24:22.145938 Finish.
Total elapsed time: 07:57:13.15.
