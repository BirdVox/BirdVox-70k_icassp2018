2018-02-24 20:27:18.130088: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:18.130357: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:18.130370: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:13.845429 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit01, unit02, unit03.
Validation set: unit05, unit07.
Test set: unit10.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.839966  0.418846  0.577271  0.764892
1   0.522461  7.523418  0.498657  8.096374
2   0.505737  7.980592  0.497803  8.106955
3   0.501831  8.040745  0.498047  8.100545
4   0.502930  8.020822  0.495361  8.141853
5   0.496704  8.119387  0.506836  7.955308
6   0.502319  8.027439  0.501587  8.038617
7   0.501221  8.043976  0.502197  8.027725
8   0.498535  8.086310  0.493530  8.166564
9   0.506470  7.957646  0.503296  8.008465
10  0.502197  8.025881  0.497192  8.106277
11  0.500122  8.058821  0.508667  7.920873
12  0.496826  8.111536  0.501099  8.042496
13  0.490967  8.205652  0.500488  8.052045
14  0.502319  8.022413  0.503540  8.002629
15  0.500366  8.053693  0.500854  8.045739
16  0.498657  8.081085  0.505981  7.962968
17  0.496948  8.108514  0.497681  8.096661
18  0.492432  8.181226  0.495361  8.133971
19  0.493286  8.167391  0.497925  8.092600
20  0.493652  8.161444  0.503784  7.998121
21  0.508545  7.921374  0.503296  8.005966
22  0.494019  8.155491  0.506104  7.960697
23  0.494019  8.155477  0.502319  8.021680
24  0.499390  8.068897  0.498657  8.080699
25  0.496216  8.120048  0.501587  8.033475
26  0.495117  8.137753  0.501099  8.041343
27  0.506836  7.948867  0.506958  7.946899
28  0.489990  8.220387  0.506714  7.950834
29  0.500854  8.045275  0.492065  8.186938
30  0.500488  8.039241  0.502563  7.989652
31  0.504272  7.957946  0.501953  7.991528
32  0.512573  7.819497  0.499756  8.021222
33  0.497314  8.057735  0.500977  7.997000
34  0.495483  8.082376  0.495972  8.072439
35  0.495605  8.076257  0.498901  8.021730
36  0.501953  7.971212  0.500244  7.996625
37  0.490112  8.156423  0.498657  8.018499
38  0.490112  8.153125  0.507202  7.879099
39  0.488403  8.177314  0.501831  7.961788
40  0.496582  8.044099  0.495239  8.064163
41  0.491455  8.123232  0.503906  7.923497
42  0.488770  8.163662  0.497559  8.022419
43  0.495972  8.046677  0.493896  8.078748
44  0.504028  7.916290  0.494385  8.069129
45  0.494141  8.072198  0.499268  7.989670
46  0.493652  8.078475  0.509521  7.824799
47  0.506714  7.868948  0.504761  7.899505
48  0.500732  7.963215  0.504517  7.902403
49  0.505005  7.894200  0.503174  7.922998
50  0.509277  7.825358  0.497559  8.011871
51  0.491333  8.110859  0.498169  8.001636
52  0.503906  7.909970  0.509033  7.828051
53  0.502686  7.929100  0.504028  7.907559
54  0.496582  8.026164  0.498535  7.994932
55  0.502563  7.930636  0.496704  8.023983
56  0.500977  7.955820  0.495117  8.049188
57  0.497681  8.008287  0.501343  7.949876
58  0.504883  7.893419  0.498779  7.990706
59  0.501465  7.947879  0.499390  7.980952
60  0.498901  7.988729  0.498901  7.988723
61  0.500488  7.963419  0.494995  8.050990
62  0.504883  7.893355  0.500488  7.963412
63  0.500732  7.959519  0.496826  8.021793

2018-02-25 04:13:58.609037 Finish.
Total elapsed time: 07:46:45.61.
