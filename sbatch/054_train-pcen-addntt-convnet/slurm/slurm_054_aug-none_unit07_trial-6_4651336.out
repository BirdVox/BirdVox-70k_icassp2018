2018-02-24 20:27:15.249192: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.249428: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.249445: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.249452: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.249459: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.592598 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit10, unit01, unit02.
Validation set: unit03, unit05.
Test set: unit07.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.958862  0.146991  0.972900  0.109060
1   0.958252  0.153225  0.979858  0.089252
2   0.968750  0.127278  0.985718  0.077196
3   0.892578  0.343361  0.953491  0.197430
4   0.930298  0.246486  0.973511  0.120435
5   0.951538  0.168586  0.971191  0.116767
6   0.956909  0.164058  0.983643  0.081562
7   0.893555  0.366660  0.944946  0.277387
8   0.927002  0.240240  0.892822  0.279415
9   0.872192  1.480980  0.983276  0.100900
10  0.954712  0.179860  0.983276  0.099492
11  0.590454  6.482231  0.497559  8.048738
12  0.503540  7.949504  0.504150  7.936298
13  0.503052  7.950975  0.496948  8.045648
14  0.497681  8.031729  0.497070  8.039352
15  0.502319  7.953841  0.498169  8.018279
16  0.498047  8.018710  0.495605  8.056195
17  0.500366  7.979033  0.504517  7.911664
18  0.493896  8.079914  0.499146  7.995224
19  0.498657  8.002119  0.498779  7.999327
20  0.503784  7.918790  0.507202  7.863590
21  0.491333  8.115956  0.499512  7.984973
22  0.494873  8.058401  0.506104  7.878864
23  0.494141  8.069145  0.503540  7.918883
24  0.499023  7.990526  0.493896  8.071919
25  0.504639  7.900364  0.489990  8.133611
26  0.505127  7.892049  0.506470  7.870409
27  0.498901  7.990863  0.496216  8.033485
28  0.505005  7.893199  0.501709  7.945586
29  0.505127  7.890957  0.493652  8.073760
30  0.495728  8.040562  0.500122  7.970394
31  0.495972  8.036466  0.499512  7.979938
32  0.500122  7.970128  0.493408  8.077086
33  0.512329  7.775374  0.499756  7.975756
34  0.497437  8.012674  0.496948  8.020403
35  0.496216  8.032030  0.496216  8.031982
36  0.507446  7.852899  0.490479  8.123365
37  0.502197  7.936504  0.498901  7.989013
38  0.505493  7.883894  0.504272  7.903325
39  0.506836  7.862431  0.496460  8.027824
40  0.500366  7.965528  0.505493  7.883771
41  0.487305  8.173721  0.498413  7.996610
42  0.499756  7.975189  0.496094  8.033558
43  0.501831  7.942080  0.493164  8.080242
44  0.505371  7.885623  0.498291  7.998488
45  0.504883  7.893392  0.498291  7.998475
46  0.499634  7.977062  0.494385  8.060739
47  0.503296  7.918671  0.495117  8.049055
48  0.496094  8.033483  0.500610  7.961475
49  0.500122  7.969257  0.505737  7.879735
50  0.507324  7.854434  0.505371  7.885570
51  0.508301  7.838863  0.497925  8.004280
52  0.499390  7.980926  0.487549  8.169696
53  0.497803  8.119190  0.499023  8.090310
54  0.493286  8.180793  0.497070  8.118683
55  0.500366  8.065008  0.508179  7.938608
56  0.484253  8.323839  0.501343  8.047987
57  0.501099  8.051545  0.509888  7.909506
58  0.503296  8.015388  0.500977  8.052405
59  0.496826  8.118942  0.502686  8.024141
60  0.499512  8.074944  0.507935  7.938830
61  0.496094  8.129334  0.507080  7.951908
62  0.500122  8.063719  0.500732  8.053542
63  0.500977  8.049275  0.489380  8.235862

2018-02-25 04:08:03.237923 Finish.
Total elapsed time: 07:40:54.24.
