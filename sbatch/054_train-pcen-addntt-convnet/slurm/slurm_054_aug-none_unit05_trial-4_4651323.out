2018-02-24 20:27:13.160193: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.160506: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.160524: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.160531: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.160539: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.365777 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit07, unit10, unit01.
Validation set: unit02, unit03.
Test set: unit05.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.931396  0.231541  0.888428  0.306437
1   0.646729  5.168965  0.512329  7.802100
2   0.497559  8.034633  0.491089  8.135193
3   0.496216  8.051384  0.496460  8.045575
4   0.497314  8.030319  0.495972  8.050191
5   0.506470  7.881490  0.506104  7.886062
6   0.498901  7.999770  0.497925  8.014283
7   0.498291  8.007513  0.499146  7.993006
8   0.490845  8.124559  0.511475  7.794928
9   0.498657  7.998613  0.492310  8.099189
10  0.499512  7.983824  0.500122  7.973577
11  0.496338  8.033453  0.496704  8.027187
12  0.564819  6.261353  0.704102  1.154699
13  0.533447  7.171605  0.507080  7.916414
14  0.499023  8.038743  0.505981  7.922864
15  0.500732  8.003018  0.497192  8.056321
16  0.500244  8.005154  0.499634  8.012565
17  0.509521  7.852965  0.508667  7.864739
18  0.494385  8.090815  0.511841  7.810985
19  0.497559  8.037303  0.507080  7.884189
20  0.512329  7.799313  0.503174  7.944117
21  0.505981  7.898304  0.494141  8.086054
22  0.500366  7.985866  0.500000  7.990793
23  0.497070  8.036661  0.487305  8.191533
24  0.510620  7.819077  0.507935  7.861161
25  0.501953  7.955846  0.496948  8.034982
26  0.497559  8.024650  0.497314  8.027959
27  0.504272  7.916496  0.492676  8.100856
28  0.498291  8.010861  0.504639  7.909204
29  0.498535  8.006089  0.495239  8.058229
30  0.496704  8.034506  0.502075  7.948522
31  0.509033  7.837271  0.488647  8.161956
32  0.496094  8.042961  0.499634  7.986252
33  0.499756  7.984057  0.499146  7.993549
34  0.503296  7.927163  0.495850  8.045664
35  0.505493  7.891730  0.509521  7.827321
36  0.498535  8.002295  0.499146  7.992395
37  0.495483  8.050618  0.497681  8.015431
38  0.496338  8.036689  0.500977  7.962588
39  0.497192  8.022773  0.487183  8.182208
40  0.504883  7.899882  0.496094  8.039857
41  0.492310  8.100043  0.500000  7.977294
42  0.495483  8.049153  0.506104  7.879695
43  0.501465  7.953496  0.497070  8.023402
44  0.504150  7.910375  0.498901  7.993899
45  0.492676  8.092990  0.497925  7.996577
46  0.498901  8.004975  0.505493  8.017140
47  0.495483  8.181759  0.496338  8.167256
48  0.508179  7.975503  0.501343  8.084776
49  0.495728  8.174379  0.496948  8.153792
50  0.493530  8.207980  0.504150  8.035895
51  0.497559  8.141244  0.504150  8.034095
52  0.506470  7.995825  0.499878  8.101183
53  0.514648  7.862239  0.512085  7.902686
54  0.497681  8.134006  0.491089  8.239404
55  0.499512  8.102820  0.499146  8.107902
56  0.503052  8.044148  0.495972  8.157477
57  0.502686  8.048504  0.511963  7.898218
58  0.498413  8.115894  0.494019  8.186011
59  0.497559  8.128269  0.498413  8.113820
60  0.508301  7.953805  0.500366  8.081057
61  0.511719  7.897468  0.500366  8.079848
62  0.503174  8.034019  0.501587  8.059028
63  0.512817  7.877469  0.494995  8.164188

2018-02-25 04:15:22.489707 Finish.
Total elapsed time: 07:48:13.49.
