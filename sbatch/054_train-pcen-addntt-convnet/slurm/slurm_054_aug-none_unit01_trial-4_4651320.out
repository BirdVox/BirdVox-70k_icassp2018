2018-02-24 20:27:14.234749: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.235068: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.235089: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.235096: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.235103: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.536622 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit02, unit03, unit05.
Validation set: unit07, unit10.
Test set: unit01.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.496094  8.047404  0.494751  8.066998
1   0.503906  7.919583  0.502319  7.943554
2   0.501343  7.958040  0.493896  8.075761
3   0.500000  7.977642  0.501953  7.945757
4   0.503174  7.925675  0.495972  8.039922
5   0.509155  7.829265  0.500122  7.972831
6   0.504639  7.900450  0.496826  8.024650
7   0.499390  7.983483  0.502197  7.937917
8   0.512207  7.778621  0.491821  8.103391
9   0.502319  7.935831  0.500244  7.968729
10  0.498901  7.999192  0.497192  8.030059
11  0.502441  7.939666  0.497925  8.008091
12  0.500610  7.963973  0.507202  7.857991
13  0.504639  7.898413  0.494385  8.061549
14  0.504272  7.903720  0.502686  7.928863
15  0.512817  7.767237  0.503662  7.913110
16  0.496460  8.027870  0.506592  7.866294
17  0.495239  8.047244  0.502319  7.934339
18  0.500488  7.963506  0.491821  8.099986
19  0.510498  7.805454  0.502441  7.932330
20  0.491821  8.101621  0.496948  8.019874
21  0.502808  7.926455  0.499390  7.980353
22  0.500854  8.052830  0.506958  8.037700
23  0.499268  8.148645  0.499268  8.138536
24  0.493286  8.227565  0.501709  8.085098
25  0.501221  8.087384  0.497070  8.149072
26  0.508179  7.965557  0.498901  8.110890
27  0.493286  8.197759  0.498779  8.105791
28  0.499146  8.096913  0.498413  8.105916
29  0.504150  8.011014  0.491089  8.219258
30  0.495850  8.140556  0.508545  7.934085
31  0.489868  8.233537  0.511963  7.875932
32  0.491699  8.201286  0.504883  7.987620
33  0.501831  8.035820  0.499512  8.072286
34  0.507812  7.937727  0.494751  8.147547
35  0.499756  8.066293  0.495483  8.134620
36  0.503052  8.012194  0.498657  8.082625
37  0.498291  8.088204  0.491577  8.196126
38  0.513672  7.839768  0.499878  8.061891
39  0.495117  8.138461  0.502441  8.020262
40  0.504395  7.988669  0.497070  8.106623
41  0.500977  8.043587  0.502686  8.015976
42  0.492798  8.175299  0.498779  8.078848
43  0.496948  8.108331  0.499512  8.066988
44  0.498657  8.080743  0.496704  8.112209
45  0.500366  8.053173  0.507202  7.942982
46  0.503540  8.002003  0.497437  8.100375
47  0.501709  8.031509  0.492188  8.184974
48  0.499146  8.072823  0.504028  7.994121
49  0.493530  8.163329  0.496826  8.110205
50  0.500366  8.053147  0.499756  8.062983
51  0.500732  8.062770  0.494507  8.168474
52  0.502686  8.034508  0.512817  7.869702
53  0.501709  8.044011  0.505371  7.982995
54  0.501099  8.048759  0.500244  8.060115
55  0.499512  8.069695  0.501343  8.038448
56  0.494385  8.147419  0.503540  7.999520
57  0.487793  8.248678  0.508545  7.915951
58  0.496094  8.112589  0.501831  8.019246
59  0.499023  8.062139  0.494873  8.126420
60  0.494995  8.122590  0.491577  8.175175
61  0.498413  8.064286  0.496826  8.087655
62  0.499634  8.040963  0.509399  7.883322
63  0.494141  8.124630  0.490967  8.173254

2018-02-25 04:01:33.781253 Finish.
Total elapsed time: 07:34:24.78.
