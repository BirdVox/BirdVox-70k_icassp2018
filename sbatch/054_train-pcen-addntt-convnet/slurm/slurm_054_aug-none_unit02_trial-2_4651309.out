2018-02-24 20:27:15.030191: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.030454: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.030470: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.030476: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.030482: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.450636 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit03, unit05, unit07.
Validation set: unit10, unit01.
Test set: unit02.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.502563  7.947642  0.504639  7.912749
1   0.498901  8.002659  0.505859  7.890268
2   0.501343  7.961007  0.499756  7.985111
3   0.503174  7.929581  0.505737  7.887731
4   0.499390  7.988073  0.502563  7.936668
5   0.497803  8.011864  0.500488  7.968219
6   0.502441  7.936677  0.493408  8.079835
7   0.497070  8.021301  0.499146  7.987244
8   0.494141  8.067197  0.501343  7.951810
9   0.489624  8.138556  0.503906  7.909473
10  0.506836  7.869334  0.497681  8.128108
11  0.494507  8.165896  0.506958  7.954035
12  0.490479  8.216748  0.503418  8.006397
13  0.496704  8.113860  0.500977  8.044464
14  0.501343  8.038277  0.501709  8.032154
15  0.509644  7.904123  0.500488  8.051572
16  0.501099  8.041653  0.504883  7.980502
17  0.492554  8.199098  0.499146  8.145684
18  0.507812  7.990152  0.495850  8.166239
19  0.505249  8.004993  0.494873  8.159879
20  0.493042  8.180032  0.496704  8.113097
21  0.501587  8.027703  0.502075  8.012716
22  0.501099  8.021861  0.502686  7.990416
23  0.495239  8.103630  0.487793  8.217082
24  0.491211  8.157891  0.511719  7.826455
25  0.492188  8.133829  0.497314  8.048276
26  0.501953  7.970939  0.505859  7.905443
27  0.502686  7.953199  0.499512  8.001100
28  0.502686  7.948135  0.502197  7.953679
29  0.496582  8.041245  0.503784  7.924581
30  0.498169  8.012503  0.498047  8.012946
31  0.500854  7.966891  0.496704  8.031845
32  0.488159  8.167034  0.496704  8.029839
33  0.505249  7.892792  0.489014  8.150858
34  0.501587  7.949769  0.503906  7.912200
35  0.506226  7.874731  0.500977  7.957958
36  0.507202  7.858335  0.496338  8.031196
37  0.511475  7.789605  0.500000  7.972287
38  0.494995  8.051878  0.500366  7.966070
39  0.504395  7.901710  0.502319  7.934669
40  0.506104  7.874245  0.496948  8.020119
41  0.505371  7.885777  0.509155  7.825394
42  0.492554  8.090024  0.501099  7.953765
43  0.500366  7.965419  0.494873  8.052974
44  0.507812  7.846675  0.497437  6.941400
45  0.506592  8.131037  0.511841  8.068045
46  0.504395  8.185226  0.502319  8.215784
47  0.500366  8.244299  0.497437  8.288479
48  0.497192  8.289298  0.507324  8.122803
49  0.505249  8.152995  0.499023  8.250012
50  0.503052  8.181698  0.500732  8.215627
51  0.492798  8.340014  0.492065  8.348251
52  0.507202  8.100667  0.494141  8.307523
53  0.497559  8.248728  0.498535  8.229225
54  0.497192  8.247078  0.498169  8.227493
55  0.502319  8.156731  0.506836  8.080011
56  0.496582  8.241350  0.504517  8.109472
57  0.507446  8.058253  0.508423  8.038464
58  0.500854  8.156398  0.501709  8.138524
59  0.499023  8.177710  0.491821  8.289652
60  0.501709  8.126149  0.504150  8.082627
61  0.497314  8.188664  0.504517  8.068401
62  0.500854  8.123294  0.495728  8.201775
63  0.492676  8.246873  0.503296  8.071599

2018-02-25 04:18:18.744897 Finish.
Total elapsed time: 07:51:09.74.
