2018-02-24 20:27:17.233143: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:17.233451: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:17.233464: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:13.458945 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit05, unit07, unit10.
Validation set: unit01, unit02.
Test set: unit03.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.980835  0.092977  0.820435  1.323013
1   0.984619  0.080482  0.837891  0.958358
2   0.982422  0.095148  0.876465  0.746869
3   0.987671  0.063580  0.862671  0.804292
4   0.986938  0.060106  0.855347  0.966808
5   0.986084  0.063913  0.852295  0.893780
6   0.987305  0.065250  0.848755  0.911142
7   0.988281  0.062933  0.861938  0.856003
8   0.990967  0.047997  0.854492  0.834829
9   0.979004  0.099728  0.854858  0.884762
10  0.984619  0.067912  0.837769  1.028514
11  0.990234  0.044077  0.813232  1.474762
12  0.989990  0.049843  0.828369  1.083538
13  0.990479  0.049199  0.856934  0.824140
14  0.989502  0.045519  0.846313  0.964055
15  0.987183  0.059593  0.853027  0.896255
16  0.991821  0.039377  0.858765  1.015977
17  0.989014  0.055256  0.848999  1.114564
18  0.987915  0.064179  0.858154  0.989256
19  0.988770  0.057530  0.856201  1.028572
20  0.988525  0.058785  0.838013  1.173488
21  0.990356  0.047233  0.841431  1.090783
22  0.990967  0.043077  0.857910  0.840046
23  0.993286  0.035413  0.807739  1.831714
24  0.954468  0.170734  0.739502  1.135238
25  0.919800  1.195976  0.793091  3.338992
26  0.655640  5.433869  0.502930  7.977676
27  0.492554  8.134925  0.498657  8.032760
28  0.508667  7.870226  0.496460  8.062233
29  0.494873  8.085433  0.497925  8.034833
30  0.492188  8.124622  0.494385  8.088001
31  0.505981  7.901706  0.497314  8.038520
32  0.493042  8.105399  0.499634  7.999117
33  0.492310  8.114786  0.494385  8.080636
34  0.489868  8.151653  0.501221  7.969702
35  0.514404  7.758627  0.495483  8.059394
36  0.498901  8.004084  0.494751  8.069450
37  0.509033  7.841007  0.492554  8.102996
38  0.489014  8.158746  0.498047  8.014063
39  0.495728  8.050411  0.503052  7.932862
40  0.506348  7.896660  0.489624  8.179659
41  0.499634  8.018379  0.501953  7.979965
42  0.499756  8.013803  0.494019  8.104133
43  0.485596  8.237378  0.495972  8.070952
44  0.505005  7.925999  0.497192  8.049623
45  0.497925  8.037068  0.496704  8.055662
46  0.498413  8.027589  0.488892  8.178563
47  0.502686  7.957866  0.498535  8.023250
48  0.501587  7.973842  0.500610  7.988659
49  0.491089  8.139726  0.497681  8.033911
50  0.498779  8.015692  0.500244  7.991637
51  0.497803  8.029877  0.499878  7.996112
52  0.505371  7.907876  0.496094  8.055118
53  0.498047  8.023337  0.495483  8.063563
54  0.503052  7.942281  0.506958  7.879382
55  0.505249  7.906021  0.505127  7.907362
56  0.506470  7.885366  0.500000  7.987922
57  0.499756  7.991245  0.502930  7.940078
58  0.503296  7.933689  0.508911  7.843621
59  0.501465  7.961801  0.498413  8.009924
60  0.500610  7.974383  0.500977  7.968036
61  0.501587  7.957814  0.484009  8.237563
62  0.506226  7.882904  0.500244  7.977795
63  0.504395  7.911178  0.495361  8.054743

2018-02-25 04:28:06.916490 Finish.
Total elapsed time: 08:00:53.92.
