2018-02-24 20:27:17.742655: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:17.742967: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:17.742980: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:13.451302 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit07, unit10, unit01.
Validation set: unit02, unit03.
Test set: unit05.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.499390  7.996032  0.495483  8.057130
1   0.492310  8.106681  0.498779  8.002534
2   0.494995  8.061956  0.491455  8.117520
3   0.500366  7.974665  0.505981  7.884383
4   0.492554  8.097764  0.493286  8.085425
5   0.500977  7.962223  0.494751  8.060899
6   0.505371  7.891072  0.505981  7.880847
7   0.488281  8.162586  0.493530  8.078479
8   0.497803  8.009987  0.506104  7.877290
9   0.511353  7.793286  0.499756  7.977857
10  0.506348  7.872496  0.497437  8.014302
11  0.501099  7.955691  0.499512  7.980773
12  0.505981  7.877440  0.499756  7.976511
13  0.501587  7.947162  0.497437  8.013181
14  0.496826  8.022782  0.505127  7.890326
15  0.497192  8.016717  0.500610  7.961424
16  0.505615  7.882855  0.488647  8.259684
17  0.509399  8.037157  0.499268  8.156869
18  0.504639  8.046698  0.498047  8.135116
19  0.499268  8.104807  0.505005  8.003778
20  0.498291  8.106419  0.505371  7.987681
21  0.502808  8.025843  0.500122  8.066464
22  0.505127  7.983918  0.494385  8.155457
23  0.506470  7.959516  0.501953  8.031320
24  0.500366  8.056171  0.502441  8.022091
25  0.496460  8.118034  0.496948  8.109758
26  0.499268  8.072073  0.504883  7.981303
27  0.494995  8.140479  0.491333  8.199334
28  0.499878  8.061481  0.505127  7.976768
29  0.500122  8.057358  0.504272  7.990393
30  0.505859  7.964766  0.505371  7.972594
31  0.494141  8.153578  0.500854  8.045339
32  0.490967  8.204693  0.501221  8.039405
33  0.496460  8.116130  0.504272  7.990200
34  0.502197  8.023643  0.505981  7.962646
35  0.494263  8.151527  0.508545  7.921323
36  0.498779  8.078725  0.494629  8.145621
37  0.503052  8.009860  0.494019  8.155457
38  0.494873  8.141685  0.513062  7.848521
39  0.502686  8.015762  0.499512  8.066918
40  0.503052  8.009859  0.495361  8.133814
41  0.495483  8.194927  0.498657  8.199342
42  0.499512  8.172563  0.500000  8.153508
43  0.490845  8.290072  0.506104  8.037818
44  0.496948  8.175555  0.493896  8.216204
45  0.510620  7.942140  0.501709  8.076923
46  0.504883  8.019520  0.493774  8.189958
47  0.496094  8.146761  0.502319  8.041428
48  0.510620  7.903418  0.502563  8.026317
49  0.499878  8.063969  0.496582  8.111475
50  0.522827  7.688385  0.500366  8.041903
51  0.494385  8.133029  0.496094  8.101661
52  0.493530  8.138711  0.500244  8.027960
53  0.499756  8.032309  0.498901  8.042590
54  0.496948  8.070642  0.498779  8.038453
55  0.488647  8.197214  0.503540  7.957106
56  0.493408  8.116160  0.498169  8.037863
57  0.497192  8.051224  0.499268  8.015999
58  0.488403  8.187229  0.490723  8.148340
59  0.496582  8.053166  0.497681  8.033940
60  0.498291  8.022632  0.503906  7.931577
61  0.510498  7.825069  0.509033  7.847040
62  0.497437  8.030636  0.501587  7.963218
63  0.499634  7.993192  0.493164  8.095198

2018-02-25 04:29:42.573664 Finish.
Total elapsed time: 08:02:29.57.
