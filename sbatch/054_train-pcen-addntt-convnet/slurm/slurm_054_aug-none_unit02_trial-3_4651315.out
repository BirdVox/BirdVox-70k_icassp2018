2018-02-24 20:27:15.805786: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.805993: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.806009: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.806016: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.806023: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.652825 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit03, unit05, unit07.
Validation set: unit10, unit01.
Test set: unit02.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.748291  0.515171  0.509521  0.772196
1   0.757812  0.505864  0.538818  0.754243
2   0.750732  0.696241  0.498535  8.088467
3   0.500977  8.052506  0.496094  8.130166
4   0.499146  8.080047  0.494507  8.153953
5   0.496948  8.113866  0.503540  8.006928
6   0.499390  8.073229  0.504761  7.986099
7   0.502075  8.028904  0.511108  7.882856
8   0.492310  8.185474  0.503174  8.010006
9   0.504272  7.991996  0.512695  7.855956
10  0.500244  8.056412  0.500244  8.056197
11  0.495850  8.126852  0.493530  8.164075
12  0.499146  8.073438  0.497803  8.094963
13  0.501709  8.031909  0.494019  8.155781
14  0.503174  8.008151  0.510620  7.888074
15  0.500488  8.051336  0.502075  8.025721
16  0.499268  8.070946  0.491333  8.198813
17  0.493652  8.161412  0.500610  8.049248
18  0.503174  8.007920  0.493408  8.165315
19  0.490845  8.206628  0.503906  7.996096
20  0.500488  8.051184  0.498047  8.090533
21  0.498413  8.084629  0.496948  8.108238
22  0.496338  8.118075  0.491333  8.198744
23  0.497314  8.102334  0.505371  7.972476
24  0.494751  8.150564  0.489502  8.263660
25  0.492432  8.162276  0.508423  7.884535
26  0.497314  8.055508  0.491699  8.141003
27  0.504272  7.938475  0.502319  7.967935
28  0.505737  7.912225  0.503174  7.951977
29  0.496094  8.063867  0.499756  8.004523
30  0.504150  7.933536  0.483521  8.260216
31  0.497803  8.032873  0.500610  7.927018
32  0.495850  8.203149  0.512695  8.099076
33  0.494019  8.379073  0.498047  8.295478
34  0.504272  8.180208  0.503662  8.176301
35  0.494995  8.304317  0.498169  8.242145
36  0.491455  8.340631  0.500610  8.183749
37  0.500000  8.185159  0.495728  8.245879
38  0.507324  8.051492  0.493652  8.264600
39  0.503662  8.096560  0.503540  8.092005
40  0.499023  8.158767  0.503296  8.084028
41  0.494019  8.228132  0.498047  8.157928
42  0.499756  8.125529  0.489380  8.288066
43  0.501099  8.094880  0.500244  8.104497
44  0.497070  8.151879  0.502197  8.065611
45  0.502197  8.062340  0.494873  8.177256
46  0.497803  8.127232  0.499268  8.100944
47  0.495483  8.159562  0.495728  8.153365
48  0.500244  8.078570  0.503174  8.029453
49  0.504761  8.002208  0.494507  8.165902
50  0.504028  8.011044  0.501953  8.043174
51  0.492065  8.201385  0.507568  7.950403
52  0.500610  8.061577  0.490112  8.229853
53  0.496460  8.126709  0.486938  8.279380
54  0.496094  8.131098  0.509033  7.921848
55  0.503052  8.017631  0.499023  8.081955
56  0.500122  8.063695  0.504517  7.992330
57  0.513428  7.848210  0.501953  8.032686
58  0.501709  8.036188  0.500000  8.063315
59  0.502075  8.029485  0.495483  8.135364
60  0.494751  8.146835  0.497314  8.105196
61  0.494385  8.152128  0.496216  8.122338
62  0.499023  8.076837  0.491943  8.190719
63  0.493042  8.172803  0.514771  7.822383

2018-02-25 04:20:26.263616 Finish.
Total elapsed time: 07:53:17.26.
