2018-02-24 20:27:15.857762: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.858041: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.858053: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:11.764613 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit02, unit03, unit05.
Validation set: unit07, unit10.
Test set: unit01.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.504272  7.924005  0.487427  8.191088
1   0.503906  7.927045  0.492554  8.106760
2   0.494263  8.078356  0.503906  7.923494
3   0.500000  7.984740  0.510864  7.810540
4   0.502808  7.938066  0.491455  8.118165
5   0.505127  7.899390  0.498901  7.997855
6   0.497925  8.012707  0.491333  8.116850
7   0.499878  7.980249  0.489258  8.148955
8   0.491089  8.119217  0.502808  7.931867
9   0.501465  7.952802  0.503052  7.927050
10  0.502930  7.928590  0.501221  7.955447
11  0.497437  8.015428  0.497925  8.007227
12  0.495972  8.038154  0.498901  7.990617
13  0.494751  8.057082  0.512573  7.771528
14  0.502808  7.928191  0.509766  7.815899
15  0.501831  7.943383  0.502197  7.936543
16  0.508179  7.841875  0.505127  7.889975
17  0.493652  8.073205  0.494019  8.066840
18  0.497925  8.122847  0.493530  8.339461
19  0.506714  8.108771  0.499512  8.209851
20  0.490967  8.336842  0.489380  8.352965
21  0.509277  8.024832  0.498779  8.187280
22  0.509888  8.002633  0.497803  8.192211
23  0.498169  8.181837  0.480835  8.457008
24  0.503052  8.095202  0.501221  8.121172
25  0.507568  8.015680  0.493774  8.234954
26  0.499756  8.135760  0.510986  7.952048
27  0.503296  8.073516  0.497803  8.159634
28  0.493774  8.222307  0.503784  8.058762
29  0.503052  8.068495  0.501831  8.086134
30  0.501709  8.086176  0.491333  8.251520
31  0.505371  8.023447  0.507080  7.994117
32  0.503296  8.053405  0.498047  8.136319
33  0.508301  7.969423  0.499878  8.103574
34  0.506836  7.989872  0.497803  8.133928
35  0.497803  8.132439  0.501221  8.075866
36  0.498657  8.115750  0.501709  8.065133
37  0.497559  8.130645  0.497070  8.137136
38  0.500732  8.076773  0.501953  8.055765
39  0.500244  8.082021  0.504761  8.007936
40  0.494629  8.169999  0.494141  8.176631
41  0.496582  8.136085  0.509888  7.920436
42  0.508423  7.942903  0.500000  8.077529
43  0.496094  8.139402  0.506836  7.965182
44  0.499634  8.080239  0.499756  8.077257
45  0.497314  8.115645  0.501221  8.051736
46  0.494629  8.157090  0.501221  8.049967
47  0.502563  8.027503  0.496826  8.119176
48  0.496216  8.128269  0.489990  8.227890
49  0.499390  8.075722  0.496094  8.128201
50  0.497681  8.102034  0.509888  7.904713
51  0.497437  8.104890  0.504639  7.988315
52  0.507446  7.942624  0.500732  8.050421
53  0.501831  8.032345  0.501221  8.041834
54  0.493408  8.167452  0.501587  8.035341
55  0.502686  8.017387  0.504639  7.985675
56  0.503906  7.997285  0.497437  8.101383
57  0.500244  8.055978  0.504150  7.992877
58  0.501221  8.039982  0.510620  7.888376
59  0.500122  8.057499  0.500732  8.047584
60  0.496704  8.112451  0.490601  8.210773
61  0.504028  7.994300  0.506470  7.954911
62  0.502441  8.019811  0.505615  7.968629
63  0.505005  7.978447  0.504639  7.984333

2018-02-25 04:17:11.010820 Finish.
Total elapsed time: 07:50:00.01.
