2018-02-24 20:27:15.186661: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.186932: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.186949: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.186957: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.186964: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.763738 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit05, unit07, unit10.
Validation set: unit01, unit02.
Test set: unit03.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.486206  8.284680  0.499756  8.065513
1   0.495117  8.139730  0.502930  8.013338
2   0.503052  8.011035  0.490967  8.205536
3   0.506470  7.955455  0.497437  8.100880
4   0.498413  8.085018  0.513428  7.842908
5   0.504028  7.994337  0.513550  7.840809
6   0.501587  8.033587  0.501953  8.027651
7   0.503784  7.980556  0.500366  8.001224
8   0.504883  7.914370  0.500488  7.970683
9   0.495483  8.174929  0.510010  7.934160
10  0.502808  8.038581  0.494385  8.166396
11  0.499390  8.081569  0.499878  8.070465
12  0.502563  8.025158  0.500366  8.058915
13  0.497681  8.101079  0.504150  7.995853
14  0.507446  7.942060  0.499023  8.077247
15  0.493652  8.163401  0.495361  8.135492
16  0.503662  8.001428  0.507568  7.938228
17  0.493774  8.160379  0.495728  8.128737
18  0.500488  8.046950  0.511108  7.857943
19  0.504517  7.958539  0.489136  8.200680
20  0.507935  7.899587  0.499146  8.038610
21  0.495361  8.098118  0.505493  7.935810
22  0.491089  8.164696  0.505249  7.938187
23  0.505859  7.927676  0.514282  7.792596
24  0.505005  7.939673  0.501587  7.993314
25  0.500488  8.009953  0.502197  7.981808
26  0.498291  8.043157  0.508057  7.886520
27  0.495728  8.082101  0.493530  8.116133
28  0.498413  8.037269  0.505859  7.917515
29  0.498535  8.033219  0.502686  7.965969
30  0.504272  7.939572  0.504395  7.936509
31  0.502197  7.970412  0.502197  7.969267
32  0.507812  7.878597  0.498291  8.029229
33  0.500000  8.000820  0.515625  7.750544
34  0.498779  8.017936  0.503174  7.946698
35  0.503784  7.935802  0.506958  7.884032
36  0.493774  8.093056  0.494995  8.072439
37  0.493652  8.092715  0.503906  7.928112
38  0.503906  7.927011  0.505859  7.894777
39  0.501465  7.963776  0.503418  7.931585
40  0.496094  8.047339  0.491821  8.114452
41  0.497559  8.022032  0.500610  7.972441
42  0.511108  7.804190  0.503662  7.922032
43  0.498169  8.008793  0.497803  8.013838
44  0.503662  7.919692  0.501465  7.954011
45  0.503296  7.924171  0.502563  7.935223
46  0.505127  7.893793  0.498535  7.998345
47  0.505127  7.892780  0.496094  8.036341
48  0.502075  7.940590  0.509888  7.815672
49  0.495483  8.044997  0.506226  7.873449
50  0.504639  7.898504  0.507690  7.849628
51  0.506226  7.872798  0.496704  8.024428
52  0.503174  7.921153  0.499512  7.979418
53  0.494751  8.055224  0.511719  7.784637
54  0.498657  7.992808  0.492188  8.095899
55  0.495117  8.049155  0.492188  8.095828
56  0.508301  7.838922  0.509766  7.815550
57  0.504517  7.899219  0.499634  7.977053
58  0.500854  7.957585  0.489380  8.140512
59  0.506226  7.871948  0.497925  8.004280
60  0.507690  7.848591  0.499268  7.982871
61  0.494141  8.064606  0.507690  7.848589
62  0.508179  7.840804  0.500366  7.965354
63  0.501709  7.943947  0.505127  7.889456

2018-02-25 04:11:41.937493 Finish.
Total elapsed time: 07:44:32.94.
