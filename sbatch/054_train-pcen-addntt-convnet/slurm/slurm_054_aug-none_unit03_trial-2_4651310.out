2018-02-24 20:27:13.956334: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.956649: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.956672: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.956681: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.956690: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.167857 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit05, unit07, unit10.
Validation set: unit01, unit02.
Test set: unit03.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.495728  8.138886  0.505371  7.982002
1   0.507812  7.941502  0.503906  8.003421
2   0.498535  8.089149  0.495728  8.133630
3   0.510376  7.896888  0.481445  8.362607
4   0.499268  8.074852  0.497681  8.099970
5   0.503418  8.007105  0.496948  8.111019
6   0.504517  7.988718  0.508301  7.927429
7   0.499146  8.074740  0.508179  7.928903
8   0.502686  8.017236  0.498169  8.089842
9   0.510620  7.888986  0.500488  8.052136
10  0.491577  8.195634  0.506836  7.949568
11  0.495728  8.128510  0.503662  8.000523
12  0.506104  7.961093  0.512695  7.854772
13  0.505493  7.970797  0.502808  8.014029
14  0.508179  7.927414  0.504150  7.992303
15  0.496216  8.120163  0.505493  7.970603
16  0.504395  7.988291  0.500610  8.049266
17  0.505981  7.962682  0.495239  8.135814
18  0.492798  8.162413  0.492188  8.122420
19  0.507446  7.868647  0.500366  7.976283
20  0.504272  7.911705  0.507935  7.851491
21  0.499634  7.982578  0.502930  7.928958
22  0.496582  8.029354  0.496826  8.024757
23  0.497559  8.012542  0.495605  8.043204
24  0.503418  7.918289  0.501587  7.947158
25  0.505127  7.898901  0.498169  8.137144
26  0.494629  8.178335  0.503174  8.027219
27  0.500244  8.068845  0.501953  8.037175
28  0.507935  7.938392  0.504883  7.985693
29  0.496216  8.124182  0.497559  8.101546
30  0.499878  8.063492  0.496704  8.114085
31  0.497681  8.097951  0.493286  8.168447
32  0.498779  8.079667  0.506470  7.955505
33  0.503906  8.084526  0.488770  8.427165
34  0.488281  8.429235  0.505859  8.141633
35  0.504639  8.158004  0.491211  8.371219
36  0.502075  8.193024  0.507080  8.109276
37  0.502441  8.181039  0.501587  8.191804
38  0.508667  8.074741  0.501343  8.189841
39  0.510620  8.037406  0.494263  8.298142
40  0.493896  8.301176  0.501221  8.180242
41  0.502808  8.151825  0.493042  8.306378
42  0.494507  8.279961  0.503296  8.135481
43  0.496704  8.238959  0.498291  8.210603
44  0.498657  8.201978  0.502441  8.138258
45  0.491577  8.310697  0.499390  8.182104
46  0.493286  8.277873  0.509766  8.009648
47  0.500122  8.162544  0.502319  8.124595
48  0.498535  8.183122  0.498901  8.174760
49  0.500610  8.144824  0.506958  8.040129
50  0.503906  8.087005  0.502197  8.112245
51  0.499756  8.149360  0.498657  8.164840
52  0.507935  8.013149  0.505859  8.044449
53  0.501709  8.109267  0.505981  8.038335
54  0.493286  8.240966  0.507446  8.010750
55  0.494751  8.213468  0.493652  8.229287
56  0.493530  8.229444  0.496826  8.174529
57  0.502319  8.084281  0.494995  8.200647
58  0.497559  8.157725  0.507202  8.000710
59  0.505249  8.030695  0.508301  7.980036
60  0.500977  8.096699  0.499390  8.120911
61  0.498291  8.137330  0.496582  8.163608
62  0.492310  8.231273  0.499390  8.115974
63  0.509888  7.945644  0.496826  8.155063

2018-02-25 03:38:34.979721 Finish.
Total elapsed time: 07:11:25.98.
