2018-02-24 20:27:15.046719: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.046978: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.046995: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.047003: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.047010: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.365777 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit10, unit01, unit02.
Validation set: unit03, unit05.
Test set: unit07.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.946899  0.177910  0.902222  0.272697
1   0.949585  0.171892  0.951904  0.169990
2   0.837646  2.065489  0.507568  7.894041
3   0.495361  8.082928  0.502075  7.971287
4   0.493652  8.102361  0.497070  8.045016
5   0.499390  8.005726  0.497314  8.036665
6   0.505493  7.904445  0.509033  7.846283
7   0.504150  7.922617  0.496094  8.049626
8   0.494263  8.077549  0.510010  7.825293
9   0.497314  8.026610  0.496460  8.039205
10  0.498047  8.012989  0.504517  7.908970
11  0.504883  7.902349  0.503418  7.924955
12  0.502808  7.934018  0.500488  7.970356
13  0.503662  7.919189  0.502808  7.932268
14  0.504150  7.910376  0.499634  7.981918
15  0.496338  8.034049  0.509888  7.817638
16  0.497803  8.009949  0.501709  7.947338
17  0.497925  8.007367  0.503540  7.917560
18  0.499756  7.977633  0.500854  7.959875
19  0.497681  8.010256  0.509277  7.825170
20  0.499512  7.980673  0.490845  8.118669
21  0.499390  7.982287  0.492310  8.095013
22  0.503052  7.923626  0.496094  8.034429
23  0.493530  8.075187  0.503296  7.919397
24  0.510376  7.806433  0.496582  8.026257
25  0.499878  7.973639  0.490356  8.125365
26  0.500732  7.959888  0.512085  7.778847
27  0.501221  7.952002  0.514038  7.747620
28  0.497681  8.008360  0.500610  7.961621
29  0.506470  7.930197  0.491699  8.219404
30  0.509399  7.931824  0.503784  8.020861
31  0.497559  8.120340  0.503418  8.025142
32  0.495483  8.152409  0.502075  8.045571
33  0.497559  8.117831  0.504761  8.001220
34  0.489868  8.240761  0.488770  8.257974
35  0.506226  7.976140  0.495605  8.146841
36  0.511597  7.888631  0.507324  7.957032
37  0.507202  7.958548  0.500854  8.060408
38  0.501465  8.050128  0.497803  8.108710
39  0.498047  8.104340  0.505371  7.985851
40  0.502441  8.032645  0.493286  8.179782
41  0.502441  8.031797  0.504028  8.005799
42  0.497192  8.115570  0.492920  8.184023
43  0.500366  8.063600  0.496460  8.126160
44  0.505371  7.982138  0.499023  8.084059
45  0.496094  8.130899  0.500366  8.061656
46  0.495239  8.143924  0.512329  7.868101
47  0.500122  8.064500  0.498779  8.085789
48  0.500854  8.052000  0.501099  8.047726
49  0.512451  7.864419  0.489624  8.232026
50  0.502686  8.021190  0.498169  8.093683
51  0.497192  8.109131  0.505737  7.971115
52  0.492676  8.181368  0.502197  8.027629
53  0.509766  7.905386  0.499878  8.064507
54  0.499268  8.074108  0.495239  8.138805
55  0.502808  8.016601  0.493408  8.167891
56  0.514771  7.823374  0.499023  8.076995
57  0.506714  7.952863  0.495483  8.133705
58  0.507080  7.946630  0.503296  8.007471
59  0.499390  8.070293  0.505493  7.971782
60  0.494263  8.152674  0.490356  8.215519
61  0.500977  8.044238  0.495728  8.128742
62  0.502930  8.012569  0.503784  7.998711
63  0.510376  7.892389  0.510986  7.882481

2018-02-25 04:15:36.420196 Finish.
Total elapsed time: 07:48:27.42.
