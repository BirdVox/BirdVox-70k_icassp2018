2018-02-24 20:27:10.827138: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:10.827438: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:10.827453: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:10.827459: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:10.827465: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:08.447697 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit03, unit05, unit07.
Validation set: unit10, unit01.
Test set: unit02.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.496460  8.127912  0.499268  8.081059
1   0.492554  8.187971  0.491455  8.204483
2   0.495239  8.142503  0.516602  7.797274
3   0.496338  8.123131  0.504028  7.998479
4   0.500854  8.049056  0.510620  7.891118
5   0.494141  8.156293  0.504761  7.984708
6   0.492920  8.175221  0.494629  8.147366
7   0.505493  7.971999  0.497192  8.105558
8   0.501343  8.038471  0.497437  8.101258
9   0.501343  8.038155  0.509033  7.914072
10  0.503784  7.998573  0.503540  8.002415
11  0.500244  8.055465  0.495361  8.134100
12  0.499390  8.069120  0.499878  8.061203
13  0.494629  8.145772  0.508057  7.929310
14  0.491089  8.202775  0.493774  8.159468
15  0.495117  8.138873  0.499878  8.068584
16  0.504150  7.958089  0.492310  8.124278
17  0.507690  7.869882  0.508179  7.855355
18  0.500488  7.974093  0.515137  7.737492
19  0.503296  7.924313  0.502441  7.936343
20  0.498169  8.003408  0.500366  7.967515
21  0.489258  8.144038  0.502808  7.927552
22  0.498779  7.991465  0.494629  8.057380
23  0.502808  7.926831  0.489990  8.131040
24  0.502686  7.928565  0.502686  7.928500
25  0.502930  7.924569  0.498901  7.988759
26  0.493530  8.074369  0.499512  7.978997
27  0.503174  7.920607  0.499634  7.977038
28  0.494385  8.060717  0.515381  7.725987
29  0.499634  7.977032  0.498779  7.990654
30  0.497314  8.205243  0.508667  8.084096
31  0.496216  8.262242  0.497803  8.218675
32  0.503174  8.119622  0.499146  8.173610
33  0.511353  7.968285  0.495728  8.212318
34  0.492188  8.262886  0.508911  7.987285
35  0.498779  8.145390  0.492920  8.234919
36  0.502930  8.069261  0.497192  8.157618
37  0.497559  8.148041  0.497925  8.138616
38  0.498169  8.131504  0.503174  8.047776
39  0.505005  8.015484  0.500977  8.077730
40  0.498535  8.114632  0.502441  8.049301
41  0.506836  7.976300  0.497925  8.117830
42  0.507935  7.954566  0.504639  8.005825
43  0.499512  8.086753  0.504150  8.010332
44  0.508911  7.932085  0.501953  8.042773
45  0.504272  8.004057  0.499268  8.083441
46  0.506714  7.962255  0.495239  8.146083
47  0.498657  8.089981  0.509399  7.915868
48  0.500366  8.060599  0.498535  8.089284
49  0.503296  8.011815  0.493652  8.164435
50  0.498657  8.174508  0.500244  8.240969
51  0.493042  8.356213  0.497192  8.288496
52  0.506958  8.130325  0.505127  8.159080
53  0.506958  8.128869  0.485840  8.468563
54  0.507812  8.113737  0.500854  8.225228
55  0.483521  8.503983  0.496094  8.300685
56  0.507446  8.117073  0.490479  8.389922
57  0.504028  8.170902  0.499756  8.239131
58  0.503052  8.185366  0.494629  8.320474
59  0.491211  8.374901  0.495239  8.309294
60  0.500854  8.218107  0.504395  8.160345
61  0.501831  8.200940  0.494385  8.320224
62  0.497192  8.274212  0.506836  8.117994
63  0.492798  8.343462  0.496704  8.279681

2018-02-25 04:27:22.645509 Finish.
Total elapsed time: 08:00:14.65.
