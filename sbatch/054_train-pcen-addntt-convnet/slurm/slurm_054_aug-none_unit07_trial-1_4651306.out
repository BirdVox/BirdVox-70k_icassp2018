2018-02-24 20:27:15.219874: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.220081: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.220099: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.220107: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.220115: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.365760 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit10, unit01, unit02.
Validation set: unit03, unit05.
Test set: unit07.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.635132  4.875815  0.500977  7.989042
1   0.500610  7.989535  0.510010  7.835237
2   0.497437  8.032389  0.500854  7.974964
3   0.501587  7.960970  0.502075  7.951089
4   0.512085  7.789821  0.499268  7.992489
5   0.493408  8.088943  0.510132  7.855564
6   0.505493  7.921242  0.499634  8.008394
7   0.493408  8.103675  0.496582  8.049721
8   0.502686  7.949954  0.497681  8.027566
9   0.496704  8.041428  0.490845  8.133297
10  0.504028  7.921869  0.508545  7.848719
11  0.495850  8.050164  0.498657  8.004527
12  0.500977  7.966812  0.497070  8.028396
13  0.491577  8.115378  0.503174  7.929943
14  0.500000  7.980055  0.498291  8.006839
15  0.493774  8.078435  0.500244  7.974902
16  0.506348  7.877246  0.494263  8.069572
17  0.496216  8.038127  0.491211  8.117620
18  0.496704  8.029773  0.496094  8.039238
19  0.499023  7.992286  0.494751  8.060159
20  0.498291  8.003497  0.496582  8.030522
21  0.509888  7.818191  0.500000  7.975620
22  0.509155  7.829470  0.501099  7.957722
23  0.504883  7.897212  0.486084  8.196731
24  0.504761  7.898808  0.494629  8.060165
25  0.494873  8.056112  0.489746  8.137688
26  0.508667  7.835891  0.500244  7.970021
27  0.503540  7.917332  0.497681  8.010602
28  0.511963  7.782774  0.496216  8.033686
29  0.500122  7.971284  0.506226  7.873854
30  0.508179  7.842598  0.507690  7.850265
31  0.490601  8.122609  0.501709  7.945406
32  0.506958  7.861624  0.494141  8.065865
33  0.500122  7.970414  0.497681  8.009247
34  0.496582  8.026678  0.505981  7.876749
35  0.486816  8.182211  0.493652  8.073158
36  0.501953  7.940758  0.498779  7.991293
37  0.493286  8.078810  0.497070  8.018426
38  0.497314  8.014484  0.502441  7.932701
39  0.496704  8.024125  0.499634  7.977378
40  0.505005  7.891714  0.504761  7.895572
41  0.491821  8.101828  0.497681  8.008387
42  0.494751  8.055068  0.500732  7.959687
43  0.500366  7.965504  0.497314  8.014138
44  0.489746  8.134779  0.501587  7.945993
45  0.503906  7.909004  0.494019  8.066625
46  0.491211  8.111375  0.513428  7.757177
47  0.508179  7.840851  0.499268  7.982908
48  0.504150  7.905059  0.499756  7.975112
49  0.492676  8.087982  0.500488  7.963428
50  0.503906  7.908934  0.500122  7.969260
51  0.492554  8.089915  0.498657  7.992608
52  0.500244  7.967308  0.497559  8.010120
53  0.500122  7.969251  0.504761  7.895299
54  0.501343  7.949788  0.500732  7.959518
55  0.512085  7.778531  0.504150  7.905027
56  0.499146  7.984816  0.498901  7.988708
57  0.492920  8.084067  0.507324  7.854428
58  0.497437  8.091994  0.502075  8.266096
59  0.498535  8.311117  0.495117  8.356087
60  0.495361  8.343617  0.500244  8.256636
61  0.499878  8.254789  0.502441  8.205848
62  0.497070  8.285193  0.496948  8.280031
63  0.501221  8.204386  0.499268  8.229172

2018-02-25 04:02:27.737939 Finish.
Total elapsed time: 07:35:18.74.
