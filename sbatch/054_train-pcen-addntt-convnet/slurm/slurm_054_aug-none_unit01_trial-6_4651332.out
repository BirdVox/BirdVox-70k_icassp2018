2018-02-24 20:27:12.720045: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.720389: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.720416: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.720426: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:12.720436: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.586988 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit02, unit03, unit05.
Validation set: unit07, unit10.
Test set: unit01.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.496948  8.022466  0.495972  8.037359
1   0.498535  7.996031  0.493530  8.075436
2   0.485352  8.205560  0.509521  7.820013
3   0.499390  7.981388  0.494995  8.051321
4   0.506958  7.860519  0.501709  7.943236
5   0.498657  8.096862  0.499634  8.104835
6   0.496338  8.137439  0.507080  7.953114
7   0.503174  8.012371  0.496948  8.110389
8   0.511963  7.867457  0.499878  8.061633
9   0.488770  8.240420  0.496948  8.108417
10  0.508911  7.915536  0.498901  8.076807
11  0.498169  8.088595  0.498047  8.090546
12  0.490723  8.208598  0.502930  8.011831
13  0.505249  7.974459  0.498413  8.084638
14  0.505737  7.966579  0.500977  8.043308
15  0.507080  7.944937  0.505249  7.974444
16  0.500488  8.051178  0.499268  8.069157
17  0.497314  8.102344  0.501587  8.033470
18  0.501343  8.036156  0.501343  8.023839
19  0.501587  8.007043  0.503906  7.960630
20  0.491089  8.159008  0.492188  8.136400
21  0.503418  7.953509  0.500000  8.004530
22  0.504639  7.927743  0.501831  7.969878
23  0.507568  7.876173  0.502319  7.957747
24  0.510498  7.825515  0.494995  8.070916
25  0.497437  8.030437  0.506226  7.888829
26  0.498779  8.006206  0.500732  7.973788
27  0.489014  8.159459  0.494019  8.078560
28  0.500122  7.980255  0.504028  7.917018
29  0.489502  8.147735  0.497559  7.989479
30  0.493164  8.087768  0.507324  7.620837
31  0.496460  8.165838  0.494141  8.212695
32  0.497437  8.142530  0.500000  8.087684
33  0.488770  8.256698  0.502808  8.023882
34  0.495239  8.137140  0.504272  7.986269
35  0.505371  7.962932  0.494873  8.124848
36  0.488892  8.215526  0.504517  7.962028
37  0.495483  8.102231  0.490845  8.172591
38  0.494507  8.111075  0.496338  8.078918
39  0.510864  7.844726  0.503784  7.955121
40  0.519409  7.703823  0.501831  7.981962
41  0.488892  8.186368  0.511353  7.826483
42  0.505249  7.922153  0.495239  8.080155
43  0.501953  7.971672  0.499756  8.005295
44  0.496094  8.062369  0.502930  7.952108
45  0.506714  7.890573  0.486572  8.210489
46  0.492554  8.113999  0.508789  7.854047
47  0.500000  7.993088  0.493774  8.091268
48  0.506226  7.891732  0.501343  7.968547
49  0.505127  7.907222  0.507202  7.873148
50  0.500488  7.979227  0.497559  8.024983
51  0.499146  7.998771  0.498169  8.013436
52  0.497314  8.026195  0.498413  8.007828
53  0.505005  7.901932  0.499634  7.986766
54  0.508789  7.840064  0.505493  7.891879
55  0.494385  8.068294  0.504639  7.904161
56  0.487183  8.181842  0.509155  7.830955
57  0.500854  7.962750  0.500366  7.970015
58  0.511841  7.786612  0.488281  8.161757
59  0.484863  8.215846  0.514893  7.736723
60  0.496948  8.022460  0.500854  7.959863
61  0.503906  7.910931  0.497192  8.017702
62  0.505615  7.883193  0.506348  7.871304
63  0.495605  8.042379  0.497925  8.005234

2018-02-25 04:10:37.706071 Finish.
Total elapsed time: 07:43:28.71.
