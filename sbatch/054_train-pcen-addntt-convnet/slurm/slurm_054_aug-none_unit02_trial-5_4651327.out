2018-02-24 20:27:14.364118: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.364333: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.364345: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.364350: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.364355: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.741686 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit03, unit05, unit07.
Validation set: unit10, unit01.
Test set: unit02.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.506470  7.885634  0.494263  8.078661
1   0.504272  7.917710  0.499390  7.994259
2   0.494629  8.069026  0.506592  7.877238
3   0.494629  8.067014  0.505859  7.887079
4   0.507324  7.862935  0.509155  7.832991
5   0.499268  7.989956  0.502686  7.934828
6   0.494629  8.062703  0.498779  7.995993
7   0.499634  7.981886  0.496948  8.024237
8   0.504883  7.897328  0.504761  7.898879
9   0.492065  8.100920  0.483521  8.236811
10  0.499023  7.989359  0.502441  7.934584
11  0.496704  8.025799  0.501587  7.947718
12  0.497070  8.019514  0.502808  7.927850
13  0.505981  7.877081  0.498901  7.989793
14  0.503662  7.913757  0.497192  8.016770
15  0.492798  8.086719  0.497681  8.008773
16  0.496948  8.020363  0.497437  8.012500
17  0.513672  7.753604  0.493408  8.076595
18  0.506104  7.874152  0.501221  7.951951
19  0.507690  7.848771  0.501099  7.953352
20  0.499878  7.973262  0.504883  7.893449
21  0.506104  7.873970  0.501221  7.948701
22  0.500000  8.085692  0.489014  8.259763
23  0.507690  7.950312  0.484375  8.320540
24  0.499268  8.077711  0.494629  8.150353
25  0.483398  8.330097  0.504272  7.992634
26  0.496948  8.110041  0.505371  7.973755
27  0.492310  8.183940  0.506104  7.961329
28  0.495361  8.134291  0.500732  8.047572
29  0.484863  8.303258  0.502563  8.017888
30  0.497437  8.100477  0.502686  8.015834
31  0.501099  8.041389  0.499878  8.061047
32  0.498169  8.148265  0.494629  8.185219
33  0.501587  8.055322  0.502930  8.019406
34  0.502930  8.010302  0.494873  8.131164
35  0.505981  7.948689  0.491455  8.175579
36  0.504639  7.961773  0.505615  7.942912
37  0.493774  8.128946  0.506470  7.923987
38  0.498169  8.054060  0.496460  8.079130
39  0.505127  7.938959  0.507568  7.898083
40  0.500122  8.014948  0.489380  8.184381
41  0.506226  7.914071  0.510864  7.838382
42  0.490479  8.161700  0.506226  7.908982
43  0.506714  7.899575  0.507568  7.884335
44  0.500488  7.995640  0.502930  7.955155
45  0.508911  7.858283  0.500610  7.989111
46  0.496826  8.047987  0.497681  8.032922
47  0.499268  8.006235  0.503418  7.938694
48  0.499878  7.993818  0.503784  7.930246
49  0.500244  7.985449  0.500000  7.988126
50  0.504150  7.920810  0.503784  7.925521
51  0.508423  7.850510  0.496460  8.040190
52  0.503296  7.930241  0.496338  8.040224
53  0.496460  8.037402  0.496216  8.040443
54  0.493164  8.088311  0.499512  7.986354
55  0.509399  7.828026  0.498169  8.006396
56  0.497681  8.013572  0.499023  7.991580
57  0.507812  7.850937  0.500610  7.965254
58  0.505859  7.881126  0.485718  8.201806
59  0.492920  8.086615  0.504883  7.895546
60  0.506348  7.871889  0.500000  7.972801
61  0.505615  7.883039  0.506348  7.871138
62  0.504883  7.894305  0.510498  7.804613
63  0.495728  8.039950  0.504883  7.893867

2018-02-25 04:24:30.048067 Finish.
Total elapsed time: 07:57:21.05.
