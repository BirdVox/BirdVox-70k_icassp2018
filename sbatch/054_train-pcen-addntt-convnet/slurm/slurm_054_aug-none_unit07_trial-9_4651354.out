2018-02-24 20:27:15.723467: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.723672: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.723685: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:11.662996 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit10, unit01, unit02.
Validation set: unit03, unit05.
Test set: unit07.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.983643  0.078540  0.950073  0.160246
1   0.986816  0.072856  0.964844  0.142626
2   0.984985  0.072031  0.947021  0.141608
3   0.973022  0.139648  0.927002  0.283615
4   0.974243  0.121338  0.955811  0.162253
5   0.748779  3.865519  0.677490  2.585392
6   0.952881  0.221818  0.951904  0.209921
7   0.916870  1.039433  0.495483  8.164097
8   0.498169  8.114586  0.502441  8.041818
9   0.496216  8.139790  0.504517  8.003922
10  0.500244  8.040428  0.501587  7.970801
11  0.503174  7.962251  0.505005  7.926442
12  0.497192  8.046998  0.503418  7.944429
13  0.501709  7.969210  0.497437  8.035099
14  0.503784  7.932065  0.499390  8.000410
15  0.499023  8.004766  0.494751  8.071474
16  0.495239  8.062446  0.504639  7.911410
17  0.500366  7.978460  0.499390  7.993008
18  0.500610  7.972629  0.489624  8.146895
19  0.507935  7.854185  0.500854  7.966293
20  0.493286  8.086261  0.497192  8.023324
21  0.500122  7.976022  0.503784  7.917068
22  0.485107  8.214310  0.497925  8.009481
23  0.497559  8.014884  0.507690  7.852943
24  0.494385  8.064698  0.505371  7.889200
25  0.500610  7.964788  0.496826  8.024824
26  0.507568  7.853310  0.495850  8.039891
27  0.498413  7.998810  0.499146  7.986931
28  0.492676  8.089898  0.504272  7.904853
29  0.494019  8.068179  0.503662  7.914300
30  0.501099  7.955048  0.501831  7.943257
31  0.502930  7.925643  0.489746  8.135726
32  0.499268  7.983848  0.496948  8.020744
33  0.499146  7.985644  0.490845  8.117912
34  0.496826  8.022494  0.498657  7.993246
35  0.502197  7.936759  0.506714  7.864705
36  0.483032  8.328458  0.497437  8.185365
37  0.507935  8.006984  0.501465  8.104044
38  0.498901  8.139877  0.502930  8.069939
39  0.499756  8.116926  0.505493  8.020573
40  0.496948  8.154986  0.499878  8.104650
41  0.494629  8.186549  0.499146  8.111190
42  0.501465  8.071558  0.508545  7.955303
43  0.500610  8.081298  0.496826  8.140481
44  0.504028  8.022777  0.504150  8.019257
45  0.506958  7.972602  0.503540  8.026344
46  0.501831  8.052660  0.499023  8.096724
47  0.507080  7.965773  0.500610  8.068990
48  0.489502  8.247051  0.504395  8.006049
49  0.507568  7.953994  0.490845  8.222666
50  0.494507  8.162811  0.505249  7.988852
51  0.500488  8.064815  0.492676  8.189978
52  0.501099  8.053496  0.499512  8.078362
53  0.501831  8.040302  0.498535  8.092757
54  0.497803  8.103925  0.501953  8.036401
55  0.509521  7.913817  0.509155  7.919131
56  0.504883  7.987439  0.505859  7.971151
57  0.498047  8.096559  0.489868  8.227879
58  0.502441  8.024750  0.503662  8.004614
59  0.496826  8.114371  0.503296  8.009677
60  0.494141  8.156863  0.504028  7.997127
61  0.499756  8.065660  0.489380  8.232583
62  0.504761  7.984391  0.498413  8.086434
63  0.509888  7.901249  0.502686  8.017112

2018-02-25 04:35:50.324586 Finish.
Total elapsed time: 08:08:39.32.
