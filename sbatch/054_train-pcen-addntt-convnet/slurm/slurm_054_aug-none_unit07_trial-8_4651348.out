2018-02-24 20:27:15.232663: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.232865: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.232878: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:11.334849 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit10, unit01, unit02.
Validation set: unit03, unit05.
Test set: unit07.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.502075  7.969720  0.493164  8.104835
1   0.492432  8.112299  0.490112  8.145761
2   0.497192  8.125619  0.492065  8.211934
3   0.492310  8.202723  0.494629  8.161116
4   0.505371  7.985106  0.501099  8.051512
5   0.499268  8.079209  0.497803  8.101223
6   0.505127  7.981955  0.503052  8.014326
7   0.504028  7.997760  0.500854  8.048183
8   0.494873  8.144032  0.499268  8.072705
9   0.500732  8.048720  0.502808  8.014943
10  0.497925  8.093400  0.506104  7.961362
11  0.492798  8.175668  0.505249  7.974845
12  0.500854  8.045581  0.495239  8.136007
13  0.508667  7.919520  0.501221  8.039493
14  0.497070  8.106357  0.500977  8.043369
15  0.497803  8.094508  0.506226  7.958733
16  0.505981  7.962659  0.507935  7.931171
17  0.499023  8.074797  0.499512  8.066924
18  0.500732  8.055205  0.502808  8.019623
19  0.502563  8.027545  0.497925  8.223929
20  0.493408  8.302734  0.498169  8.224403
21  0.499023  8.208927  0.498779  8.211214
22  0.510986  8.012896  0.499512  8.196279
23  0.499634  8.192754  0.505737  8.092791
24  0.494629  8.270212  0.506104  8.083597
25  0.508179  8.048425  0.498901  8.196184
26  0.499146  8.190408  0.500244  8.170805
27  0.497314  8.216062  0.510742  7.997613
28  0.505615  8.078164  0.507324  8.048478
29  0.498779  8.184003  0.494385  8.252578
30  0.506348  8.057449  0.502563  8.116082
31  0.501221  8.135320  0.496948  8.201732
32  0.497559  8.189411  0.499390  8.157371
33  0.496704  8.198112  0.487793  8.339161
34  0.491943  8.269679  0.494507  8.225746
35  0.503418  8.079511  0.509399  7.980477
36  0.497559  8.168730  0.501221  8.107092
37  0.499390  8.134036  0.492188  8.247547
38  0.503662  8.060082  0.507446  7.996574
39  0.505371  8.027581  0.501465  8.088111
40  0.499756  8.113308  0.498413  8.132619
41  0.507812  7.978881  0.500732  8.090783
42  0.499512  8.108342  0.500122  8.096415
43  0.508911  7.952768  0.487427  8.297100
44  0.501465  8.068984  0.502563  8.049458
45  0.493042  8.201212  0.494751  8.171984
46  0.491455  8.223526  0.497559  8.123599
47  0.495850  8.149688  0.504517  8.008567
48  0.491821  8.211853  0.508423  7.942956
49  0.499390  8.087325  0.501099  8.058575
50  0.494507  8.163692  0.495361  8.148813
51  0.510254  7.907735  0.505615  7.981485
52  0.501099  8.053332  0.489746  8.235381
53  0.497681  8.106620  0.507080  7.954269
54  0.501953  8.036114  0.496460  8.123882
55  0.498047  8.097591  0.492798  8.181503
56  0.504272  7.995921  0.493774  8.164517
57  0.504761  7.986884  0.500122  8.061119
58  0.504883  7.983909  0.494873  8.144794
59  0.507568  7.939771  0.497925  8.094831
60  0.501465  8.037446  0.489136  8.235863
61  0.499390  8.070331  0.499756  8.064189
62  0.505005  7.979386  0.501343  8.038231
63  0.492920  8.173843  0.502930  8.012371

2018-02-25 04:24:04.726502 Finish.
Total elapsed time: 07:56:53.73.
