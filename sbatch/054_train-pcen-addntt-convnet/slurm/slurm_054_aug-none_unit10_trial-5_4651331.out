2018-02-24 20:27:14.810133: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.810421: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.810433: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:12.070528 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit01, unit02, unit03.
Validation set: unit05, unit07.
Test set: unit10.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.963135  0.142822  0.895020  0.280665
1   0.876465  0.301099  0.619873  2.564033
2   0.706421  1.419582  0.499023  8.126830
3   0.495605  8.172612  0.493530  8.199287
4   0.496826  8.141852  0.498779  8.106625
5   0.499634  8.089932  0.502075  8.047920
6   0.502563  8.037842  0.507812  7.951186
7   0.502930  8.028136  0.497925  8.107161
8   0.494629  8.158860  0.487305  8.275569
9   0.498413  8.095351  0.495972  8.133594
10  0.495239  8.144432  0.495728  8.135646
11  0.495728  8.134846  0.506348  7.962914
12  0.500610  8.008918  0.498779  8.013628
13  0.487915  8.183774  0.504272  7.920505
14  0.494873  8.068496  0.508789  7.844961
15  0.501221  7.964240  0.507080  7.869552
16  0.504150  7.915184  0.500244  7.976459
17  0.498657  8.000907  0.494873  8.060440
18  0.493530  8.081167  0.509888  7.819754
19  0.500610  7.967111  0.505981  7.880972
20  0.511963  7.785175  0.495605  8.045540
21  0.498657  7.996534  0.493896  8.072099
22  0.502319  7.937533  0.508301  7.841905
23  0.502686  7.931193  0.505127  7.892052
24  0.496216  8.033926  0.501099  7.955902
25  0.505615  7.883740  0.499756  7.977004
26  0.497070  8.019687  0.494873  8.054592
27  0.497803  8.007776  0.500977  7.957072
28  0.509033  7.828536  0.485962  8.196257
29  0.493408  8.077465  0.503784  7.911969
30  0.497192  8.016987  0.503662  7.913775
31  0.493164  8.081076  0.494263  8.063500
32  0.507812  7.847428  0.506592  7.866834
33  0.510010  7.812293  0.502075  7.938739
34  0.501709  7.944532  0.506958  7.860806
35  0.499878  8.031976  0.498413  8.170618
36  0.494873  8.206581  0.500610  8.102741
37  0.500610  8.096939  0.498047  8.133484
38  0.494263  8.191134  0.496338  8.154794
39  0.512817  7.887009  0.495361  8.166441
40  0.497314  8.133436  0.500000  8.088757
41  0.501953  8.056110  0.504517  8.013696
42  0.497314  8.128812  0.506836  7.974412
43  0.493408  8.189981  0.498657  8.104534
44  0.501465  8.058478  0.500122  8.079326
45  0.508423  7.944762  0.498291  8.107299
46  0.498169  8.108514  0.495850  8.145144
47  0.504761  8.000775  0.497925  8.110217
48  0.497925  8.109492  0.489136  8.250429
49  0.501343  8.052965  0.497681  8.111282
50  0.504761  7.996474  0.496704  8.125644
51  0.488770  8.252870  0.510742  7.898052
52  0.495850  8.137457  0.493652  8.172245
53  0.502686  8.026049  0.503418  8.013654
54  0.509888  7.908816  0.503662  8.008612
55  0.497437  8.108443  0.507080  7.952505
56  0.497192  8.111409  0.498901  8.083408
57  0.502686  8.021994  0.493530  8.169153
58  0.498291  8.092045  0.495850  8.131034
59  0.492432  8.185796  0.502075  8.030042
60  0.505005  7.982533  0.504639  7.988157
61  0.494385  8.153179  0.502075  8.028982
62  0.503052  8.013022  0.498413  8.087577
63  0.506714  7.953593  0.505127  7.978987

2018-02-25 04:22:42.954266 Finish.
Total elapsed time: 07:55:30.95.
