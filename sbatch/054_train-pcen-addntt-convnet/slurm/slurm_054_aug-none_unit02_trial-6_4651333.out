2018-02-24 20:27:15.385676: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.385952: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.385965: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.385971: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.385976: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.772060 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit03, unit05, unit07.
Validation set: unit10, unit01.
Test set: unit02.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.494385  8.158564  0.491211  8.208048
1   0.500000  8.065115  0.497192  8.109244
2   0.507812  7.937207  0.488403  8.249283
3   0.493652  8.164093  0.491455  8.198989
4   0.496948  8.110052  0.501221  8.040759
5   0.495728  8.129107  0.505127  7.977238
6   0.500244  8.055890  0.500244  8.055093
7   0.497925  8.066406  0.497192  8.039007
8   0.496582  8.037798  0.514893  7.739838
9   0.507812  7.850443  0.498291  8.000685
10  0.505005  7.892888  0.500000  7.972119
11  0.498901  7.989331  0.506592  7.866499
12  0.499390  7.981190  0.495361  8.045314
13  0.494995  8.051096  0.500854  7.954075
14  0.492798  8.285980  0.496460  8.234158
15  0.497070  8.210247  0.502686  8.107311
16  0.511475  7.955572  0.506470  8.026888
17  0.494263  8.215649  0.501709  8.088123
18  0.502563  8.067869  0.496094  8.166057
19  0.510132  7.934545  0.499512  8.100805
20  0.503296  8.035608  0.494995  8.165477
21  0.501953  8.050001  0.490967  8.223988
22  0.497070  8.123014  0.500732  8.061585
23  0.500610  8.061552  0.496216  8.130541
24  0.500977  8.052286  0.498657  8.088273
25  0.500488  8.057619  0.494019  8.160855
26  0.492065  8.191490  0.498047  8.094311
27  0.497681  8.099594  0.496338  8.120677
28  0.510010  7.899866  0.500000  8.060803
29  0.493896  8.158864  0.501953  8.028723
30  0.503052  8.010796  0.496948  8.108977
31  0.501953  8.028159  0.500488  8.051638
32  0.498779  8.079086  0.500610  8.049487
33  0.507568  7.937274  0.501221  8.039532
34  0.504272  7.990305  0.495728  8.127999
35  0.500854  8.045340  0.489502  8.228302
36  0.484863  8.303056  0.501709  8.031525
37  0.499878  8.061031  0.496460  8.116117
38  0.503418  8.003964  0.498901  8.076760
39  0.506836  7.948869  0.499023  8.074790
40  0.499634  8.064952  0.491089  8.202679
41  0.500244  8.055113  0.507935  7.931158
42  0.500488  8.051178  0.494141  8.152812
43  0.500122  8.133122  0.507812  7.994835
44  0.502197  8.069893  0.503662  8.034835
45  0.495728  8.153052  0.510864  7.904392
46  0.507324  7.954884  0.496216  8.126457
47  0.500122  8.059406  0.506714  7.949779
48  0.493164  8.161735  0.501099  8.031333
49  0.495728  8.113404  0.502319  8.004869
50  0.494507  8.126248  0.499512  8.043375
51  0.499756  8.036625  0.507935  7.903449
52  0.506714  7.920314  0.506470  7.921667
53  0.501831  7.993242  0.507202  7.905286
54  0.490112  8.175549  0.506958  7.904838
55  0.501831  7.984543  0.501099  7.994221
56  0.508545  7.873615  0.497070  8.054679
57  0.491577  8.140477  0.504517  7.932438
58  0.511475  7.819839  0.501221  7.981660
59  0.504761  7.923649  0.504639  7.924039
60  0.496582  8.050998  0.510010  7.835463
61  0.501709  7.966403  0.499634  7.998112
62  0.493530  8.094110  0.493774  8.088931
63  0.491943  8.116906  0.504150  7.921101

2018-02-25 04:12:47.793051 Finish.
Total elapsed time: 07:45:38.79.
