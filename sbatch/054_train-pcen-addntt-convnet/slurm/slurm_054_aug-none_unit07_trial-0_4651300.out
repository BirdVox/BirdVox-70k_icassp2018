2018-02-24 20:27:13.136673: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.136873: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.136887: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.136892: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.136898: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:08.688070 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit10, unit01, unit02.
Validation set: unit03, unit05.
Test set: unit07.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.489624  8.174833  0.503540  7.945092
1   0.587646  6.025981  0.886353  0.374891
2   0.546265  7.279684  0.510742  7.916904
3   0.757690  1.637480  0.918823  0.337736
4   0.814331  0.482612  0.774658  0.483860
5   0.793213  2.219611  0.502808  8.078273
6   0.499268  8.123649  0.508301  7.969251
7   0.494263  8.189753  0.498779  8.112029
8   0.497437  8.130063  0.492188  8.211508
9   0.503540  8.026136  0.503296  8.027955
10  0.502930  8.032221  0.498291  8.105524
11  0.490234  8.234224  0.509155  7.928208
12  0.500366  8.069020  0.497559  8.113492
13  0.492798  8.189573  0.489624  8.240119
14  0.503052  8.023164  0.505493  7.983315
15  0.500977  8.055672  0.512451  7.870299
16  0.493286  8.178817  0.499268  8.082033
17  0.501343  8.048237  0.491821  8.201365
18  0.495361  8.143986  0.492188  8.194827
19  0.496338  8.127630  0.503418  8.013216
20  0.502563  8.026703  0.502197  8.032323
21  0.497803  8.102881  0.503540  8.010134
22  0.503296  8.013805  0.500732  8.054860
23  0.501587  8.040830  0.491943  8.196010
24  0.490234  8.223307  0.500244  8.061720
25  0.498657  8.087055  0.488159  8.256022
26  0.498901  8.082642  0.492554  8.184719
27  0.505615  7.973964  0.499878  8.066211
28  0.499023  8.079764  0.495117  8.142505
29  0.496826  8.114748  0.505493  7.974841
30  0.495483  8.135976  0.504395  7.992144
31  0.504883  7.984080  0.515381  7.814680
32  0.507935  7.934516  0.504150  7.995328
33  0.508667  7.922356  0.508545  7.924153
34  0.502686  8.018432  0.505737  7.969084
35  0.500122  8.059439  0.505127  7.978621
36  0.499634  8.067020  0.507446  7.940960
37  0.504272  7.991987  0.495972  8.125653
38  0.500977  8.044866  0.499023  8.076232
39  0.492065  8.188275  0.510010  7.898942
40  0.497681  8.097568  0.503662  8.001065
41  0.497192  8.105259  0.507812  7.934000
42  0.493774  8.160192  0.495483  8.132574
43  0.499878  8.061676  0.496704  8.112768
44  0.495728  8.128452  0.495728  8.128397
45  0.495361  8.134250  0.498047  8.090918
46  0.512573  7.856739  0.501343  8.037713
47  0.503052  8.010133  0.501465  8.035678
48  0.493408  8.165507  0.492188  8.185154
49  0.509521  7.905740  0.495117  8.137888
50  0.502686  8.015881  0.504150  7.992253
51  0.492676  8.177187  0.497437  8.100439
52  0.502808  8.013855  0.498535  8.082709
53  0.490845  8.206655  0.491577  8.194842
54  0.491699  8.179523  0.503174  7.941185
55  0.504517  7.916455  0.506104  7.889238
56  0.504517  7.913479  0.502563  7.943711
57  0.506714  7.876854  0.502563  7.942402
58  0.497314  8.025589  0.502930  7.935618
59  0.488403  8.166838  0.497070  8.028332
60  0.498291  8.008597  0.507202  7.866281
61  0.503174  7.930294  0.500610  7.970970
62  0.502075  7.947455  0.493286  8.087422
63  0.506470  7.877114  0.502563  7.939267

2018-02-25 04:25:38.221227 Finish.
Total elapsed time: 07:58:30.22.
