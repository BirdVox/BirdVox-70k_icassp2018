2018-02-24 20:27:25.597312: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:25.598200: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:25.598212: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:20.288341 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit03, unit05, unit07.
Validation set: unit10, unit01.
Test set: unit02.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.984985  0.079369  0.891479  0.389801
1   0.985474  0.073700  0.891968  0.432338
2   0.984009  0.078254  0.852417  0.451430
3   0.984009  0.073530  0.879761  0.424100
4   0.988037  0.059143  0.777954  0.734961
5   0.983887  0.065808  0.879272  0.408346
6   0.984131  0.064243  0.869507  0.424730
7   0.985718  0.064952  0.838867  0.540933
8   0.988159  0.054687  0.855713  0.456399
9   0.985474  0.062376  0.865479  0.441156
10  0.986206  0.058640  0.857666  0.423096
11  0.975342  0.126042  0.675537  1.217284
12  0.564697  6.611547  0.491821  8.157734
13  0.494995  8.100223  0.507324  7.897789
14  0.501465  7.986736  0.502930  7.959359
15  0.505737  7.911339  0.498169  8.029003
16  0.500732  7.985642  0.503174  7.944407
17  0.492554  8.111759  0.510376  7.825799
18  0.500732  7.977970  0.489868  8.149697
19  0.502563  7.946025  0.496582  8.040177
20  0.493774  8.083882  0.497314  8.026446
21  0.504761  7.906855  0.506836  7.872935
22  0.500610  7.971445  0.501221  7.961009
23  0.502686  7.937026  0.510864  7.806037
24  0.502563  7.937833  0.500854  7.964563
25  0.503906  7.915447  0.504272  7.909163
26  0.505371  7.891246  0.504639  7.902536
27  0.497681  8.013111  0.493896  8.073101
28  0.499756  7.979380  0.504517  7.903184
29  0.496948  8.023568  0.498047  8.005788
30  0.498657  7.995815  0.490723  8.122076
31  0.506714  7.866921  0.492920  8.086619
32  0.500977  7.957984  0.494751  8.057047
33  0.488892  8.150287  0.488403  8.157904
34  0.493652  8.074068  0.496948  8.021375
35  0.499023  7.988156  0.497803  8.007317
36  0.500610  7.990043  0.500732  8.106591
37  0.501709  8.079225  0.498413  8.127197
38  0.512207  7.902778  0.503784  8.036753
39  0.502930  8.049026  0.503906  8.031837
40  0.501099  8.075737  0.485718  8.322315
41  0.479614  8.419426  0.500488  8.081725
42  0.501099  8.070692  0.495605  8.158051
43  0.492310  8.210046  0.496338  8.144001
44  0.512207  7.887154  0.492920  8.196971
45  0.508179  7.950021  0.497070  8.128072
46  0.501587  8.054322  0.493286  8.187175
47  0.489868  8.241370  0.500122  8.075211
48  0.500244  8.072398  0.510986  7.898419
49  0.508545  7.936974  0.500122  8.071948
50  0.498291  8.100712  0.499756  8.076362
51  0.496826  8.122878  0.493652  8.173338
52  0.495850  8.137261  0.509033  7.924115
53  0.496094  8.132055  0.501465  8.044873
54  0.504517  7.995107  0.509644  7.911901
55  0.502441  8.027450  0.499512  8.074145
56  0.503296  8.012656  0.503174  8.014139
57  0.491211  8.206505  0.497559  8.103751
58  0.495605  8.134820  0.496948  8.112777
59  0.505249  7.978614  0.497681  8.100243
60  0.501099  8.044823  0.511719  7.873329
61  0.488159  8.252775  0.497314  8.104931
62  0.500244  8.057458  0.494995  8.141821
63  0.498535  8.084546  0.503662  8.001703

2018-02-25 05:02:14.353306 Finish.
Total elapsed time: 08:34:54.35.
