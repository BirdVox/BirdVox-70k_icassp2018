2018-02-24 20:27:15.243684: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.243967: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.243986: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.243995: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.244003: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.592628 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit07, unit10, unit01.
Validation set: unit02, unit03.
Test set: unit05.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.500854  7.980862  0.499756  8.083890
1   0.502808  7.992072  0.499146  8.012591
2   0.502930  7.941880  0.502075  7.948359
3   0.503906  7.915598  0.493530  8.078392
4   0.505615  7.884333  0.495972  8.037038
5   0.504761  7.896362  0.486816  8.182023
6   0.502563  7.930754  0.494751  8.055138
7   0.502441  7.932444  0.487183  8.175639
8   0.491577  8.105543  0.500610  7.961505
9   0.502319  7.934245  0.497681  8.008185
10  0.496948  8.027525  0.493896  8.453440
11  0.505737  8.221602  0.511597  8.090721
12  0.493042  8.367918  0.504272  8.168322
13  0.497559  8.262386  0.503052  8.160992
14  0.496094  8.262437  0.500610  8.179630
15  0.494873  8.263420  0.495972  8.237477
16  0.494263  8.257728  0.501953  8.126804
17  0.489746  8.317318  0.498169  8.175572
18  0.496826  8.191822  0.497070  8.182702
19  0.494995  8.211462  0.501221  8.106604
20  0.494507  8.210728  0.496582  8.173337
21  0.496582  8.169757  0.508789  7.969551
22  0.506104  8.009697  0.498901  8.122752
23  0.495605  8.173116  0.503662  8.040593
24  0.498901  8.114895  0.502563  8.053518
25  0.499634  8.098592  0.514771  7.852538
26  0.494629  8.175279  0.495483  8.159663
27  0.500977  8.069431  0.508667  7.943834
28  0.493530  8.186299  0.506226  7.980208
29  0.499756  8.083135  0.494507  8.166423
30  0.495605  8.147499  0.496582  8.130576
31  0.494751  8.158994  0.503174  8.022167
32  0.499878  8.074304  0.502197  8.035959
33  0.502563  8.029167  0.496948  8.118809
34  0.510620  7.897645  0.504517  7.995246
35  0.496094  8.130290  0.502563  8.025317
36  0.493164  8.176181  0.504272  7.996519
37  0.502686  8.021536  0.498535  8.087890
38  0.497559  8.103139  0.499634  8.069218
39  0.499878  8.064857  0.492676  8.180534
40  0.504028  7.997189  0.494141  8.156213
41  0.510254  7.896191  0.504761  7.984439
42  0.497437  8.102236  0.501343  8.039034
43  0.498657  8.082112  0.498413  8.085852
44  0.509155  7.912541  0.501709  8.032406
45  0.507446  7.939800  0.500122  8.057732
46  0.494873  8.142235  0.499023  8.075247
47  0.491455  8.197159  0.499878  8.061330
48  0.499146  8.073080  0.502808  8.014004
49  0.499146  8.072991  0.509033  7.913585
50  0.501221  8.039481  0.498047  8.090613
51  0.498291  8.086660  0.492554  8.179119
52  0.497437  8.100406  0.499756  8.063012
53  0.499146  8.072843  0.497925  8.092512
54  0.507568  7.937072  0.502808  8.013803
55  0.498291  8.157818  0.504028  8.122812
56  0.499756  8.190288  0.498169  8.214432
57  0.492920  8.297543  0.483887  8.441602
58  0.502808  8.135042  0.507080  8.064540
59  0.490479  8.330434  0.493652  8.277539
60  0.495117  8.252140  0.512695  7.966981
61  0.499634  8.175631  0.501465  8.144198
62  0.499146  8.179627  0.494385  8.254366
63  0.498169  8.191351  0.485107  8.399821

2018-02-25 04:08:34.485463 Finish.
Total elapsed time: 07:41:25.49.
