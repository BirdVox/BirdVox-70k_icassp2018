2018-02-24 20:27:15.772944: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.773232: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.773245: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:11.348822 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit01, unit02, unit03.
Validation set: unit05, unit07.
Test set: unit10.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.901855  0.305610  0.914795  0.316246
1   0.921997  0.261213  0.927856  0.240810
2   0.581421  6.626161  0.495239  8.152888
3   0.501953  8.041787  0.505615  7.980377
4   0.500244  8.065265  0.498779  8.087411
5   0.495605  8.137457  0.496948  8.114825
6   0.492065  8.192751  0.498535  8.087770
7   0.498779  8.083270  0.506592  7.956832
8   0.495239  8.139390  0.496094  8.125227
9   0.501587  8.036361  0.486816  8.274131
10  0.500244  8.057444  0.489868  8.224445
11  0.509521  7.907465  0.499023  8.076480
12  0.499878  8.062540  0.495850  8.127311
13  0.504761  7.983543  0.498047  8.091629
14  0.499512  8.067906  0.498047  8.091410
15  0.498779  8.079512  0.493530  8.164029
16  0.495361  8.134440  0.506592  7.953355
17  0.491821  8.191366  0.502808  8.014230
18  0.489380  8.230610  0.501953  8.027908
19  0.492554  8.179369  0.512329  7.860591
20  0.501343  8.037639  0.502563  8.017935
21  0.497070  8.106451  0.507080  7.945092
22  0.506836  7.949009  0.496826  8.110331
23  0.497070  8.106382  0.494873  8.141785
24  0.507080  7.945021  0.487427  8.261786
25  0.505371  7.972549  0.493408  8.165361
26  0.508789  7.917445  0.508789  7.917439
27  0.498047  8.090578  0.501831  8.029580
28  0.496338  8.118115  0.501343  8.037442
29  0.496826  8.110237  0.508667  7.919383
30  0.505127  7.976438  0.496338  8.118099
31  0.503174  8.007914  0.497192  8.104321
32  0.493896  8.157442  0.498535  8.082674
33  0.501343  8.037418  0.504395  7.988228
34  0.501221  8.039382  0.496948  8.108245
35  0.502075  8.025607  0.500122  8.057087
36  0.503784  7.998059  0.506226  7.958708
37  0.496216  8.120045  0.497192  8.104304
38  0.507202  7.942965  0.499512  8.066920
39  0.493164  8.169232  0.501831  8.029536
40  0.500732  8.047244  0.513550  7.840652
41  0.493530  8.163328  0.496826  8.110204
42  0.495850  8.125944  0.501099  8.041340
43  0.509399  7.907547  0.494019  8.155457
44  0.498047  8.092365  0.503662  7.988550
45  0.511353  7.846619  0.500366  8.011838
46  0.494995  8.093359  0.496338  8.068760
47  0.501831  7.978954  0.506592  7.901040
48  0.498413  8.029703  0.501709  7.975505
49  0.494385  8.090750  0.500366  7.993904
50  0.498779  8.017801  0.498657  8.018367
51  0.504639  7.921697  0.501587  7.969057
52  0.498535  8.016479  0.501343  7.970506
53  0.499268  8.002436  0.498535  8.012975
54  0.489746  8.152015  0.490112  8.145114
55  0.501709  7.959230  0.504639  7.911535
56  0.502319  7.947578  0.501953  7.952501
57  0.513916  7.760924  0.503540  7.925499
58  0.496826  8.031745  0.499634  7.986215
59  0.500244  7.975767  0.502808  7.934201
60  0.505371  7.892687  0.501709  7.950442
61  0.492676  8.093877  0.499878  7.978500
62  0.506470  7.872904  0.498535  7.998912
63  0.500488  7.967335  0.509399  7.824849

2018-02-25 04:24:12.273309 Finish.
Total elapsed time: 07:57:01.27.
