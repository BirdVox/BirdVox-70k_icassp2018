2018-02-24 20:27:14.659975: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.660194: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:14.660206: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:11.334902 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit02, unit03, unit05.
Validation set: unit07, unit10.
Test set: unit01.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.494263  8.169092  0.496948  8.124157
1   0.496216  8.134550  0.496094  8.135190
2   0.503662  8.012046  0.500122  8.068009
3   0.496216  8.130005  0.501099  8.050384
4   0.495605  8.138107  0.500000  8.066496
5   0.491821  8.197625  0.505249  7.980531
6   0.493408  8.170789  0.513916  7.839675
7   0.501953  8.031988  0.507202  7.946902
8   0.499268  8.074364  0.489502  8.231361
9   0.494873  8.144431  0.497559  8.100807
10  0.493530  8.165440  0.496948  8.110070
11  0.501465  8.037030  0.499512  8.068286
12  0.502441  8.020873  0.500732  8.048240
13  0.497559  8.099246  0.502319  8.022370
14  0.514526  7.825505  0.501099  8.041413
15  0.505981  7.963044  0.500732  8.046574
16  0.491333  8.199011  0.500244  8.051163
17  0.502808  8.094862  0.496582  8.293566
18  0.503296  8.160983  0.505859  8.101796
19  0.501953  8.153285  0.499756  8.178711
20  0.497559  8.206166  0.500488  8.151546
21  0.498291  8.180506  0.496216  8.207769
22  0.502441  8.101789  0.506958  8.023514
23  0.497437  8.171894  0.503174  8.074446
24  0.492798  8.237034  0.497803  8.151810
25  0.502319  8.074750  0.498413  8.133545
26  0.506226  8.003741  0.501709  8.072756
27  0.507446  7.976779  0.507080  7.979279
28  0.498657  8.111917  0.501221  8.067579
29  0.494385  8.175017  0.501221  8.062195
30  0.500000  8.079495  0.499634  8.083125
31  0.498413  8.100778  0.501099  8.055569
32  0.497925  8.105035  0.490356  8.225424
33  0.502197  8.033185  0.502075  8.033850
34  0.500000  8.066182  0.504639  7.990374
35  0.489746  8.229534  0.500122  8.061479
36  0.492065  8.190659  0.491211  8.203809
37  0.498291  8.089182  0.498413  8.086750
38  0.500610  8.050961  0.502441  8.021111
39  0.489624  8.227437  0.509033  7.914361
40  0.492065  8.187666  0.506958  7.947464
41  0.491577  8.195252  0.510376  7.892145
42  0.511597  7.872392  0.493408  8.165489
43  0.502930  8.011973  0.500488  8.051283
44  0.496216  8.120119  0.502563  8.017643
45  0.496582  8.114178  0.497070  8.104646
46  0.505127  7.974197  0.500977  7.975786
47  0.505493  7.919104  0.501709  7.972998
48  0.499146  8.010671  0.503784  7.934071
49  0.490967  8.136510  0.506836  7.881853
50  0.504272  7.921440  0.508911  7.846337
51  0.499268  7.999152  0.500244  7.982733
52  0.499023  8.001486  0.501465  7.961903
53  0.488281  8.171513  0.508545  7.847924
54  0.500366  7.977837  0.499268  7.994897
55  0.491577  8.117088  0.504150  7.916240
56  0.505615  7.892516  0.492554  8.100383
57  0.502808  7.936565  0.503174  7.930384
58  0.500854  7.967029  0.494385  8.069841
59  0.497192  8.024756  0.501953  7.948533
60  0.498779  7.998809  0.497803  8.014053
61  0.492432  8.099359  0.494751  8.062058
62  0.495239  8.053950  0.501465  7.954373
63  0.493408  8.082492  0.502686  7.934264

2018-02-25 04:23:58.707013 Finish.
Total elapsed time: 07:56:47.71.
