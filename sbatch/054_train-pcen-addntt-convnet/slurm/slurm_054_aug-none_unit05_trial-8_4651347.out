2018-02-24 20:27:15.388323: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.388587: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.388600: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:11.723298 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit07, unit10, unit01.
Validation set: unit02, unit03.
Test set: unit05.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.496582  8.033162  0.501953  7.946223
1   0.493286  8.083392  0.495605  8.045525
2   0.499634  7.980615  0.498413  7.999461
3   0.499146  7.987308  0.504517  7.901254
4   0.509399  7.823078  0.494019  8.067988
5   0.496582  8.026888  0.494263  8.063655
6   0.499634  7.977864  0.499023  7.987449
7   0.500000  7.971765  0.496460  8.028099
8   0.500244  8.067850  0.491455  8.227501
9   0.507568  7.955102  0.496948  8.118381
10  0.499634  8.071689  0.498047  8.094841
11  0.498169  8.091585  0.508057  7.931230
12  0.512329  7.861785  0.492432  8.182034
13  0.504883  7.981060  0.501709  8.031988
14  0.506836  8.047245  0.502930  8.146209
15  0.494507  8.269790  0.496216  8.232882
16  0.496460  8.220919  0.503296  8.104361
17  0.502319  8.113272  0.497070  8.190587
18  0.509033  7.994106  0.495605  8.202590
19  0.502075  8.094273  0.496216  8.182622
20  0.505127  8.035783  0.505737  8.021346
21  0.515503  7.861162  0.512573  7.903408
22  0.505005  8.019764  0.501953  8.064133
23  0.500610  8.081381  0.497681  8.123937
24  0.507935  7.956417  0.502930  8.032162
25  0.499146  8.088540  0.494995  8.150756
26  0.507324  7.950342  0.501343  8.041843
27  0.497559  8.098408  0.490234  8.211414
28  0.505005  7.972278  0.494873  8.130153
29  0.510986  7.869725  0.489380  8.210654
30  0.494995  8.117718  0.506104  7.937228
31  0.505981  7.935900  0.494263  8.119476
32  0.497192  8.069648  0.503906  7.959520
33  0.501343  7.997428  0.492798  8.130728
34  0.493408  8.118208  0.497681  8.047342
35  0.502075  7.974671  0.500000  8.005184
36  0.506836  7.893775  0.496216  8.060702
37  0.492188  8.122686  0.511719  7.809122
38  0.508057  7.865463  0.504517  7.919909
39  0.498779  8.009534  0.500000  7.988286
40  0.506104  7.889342  0.506470  7.881921
41  0.504517  7.911622  0.495483  8.054253
42  0.501709  7.953766  0.491699  8.112166
43  0.506836  7.869807  0.509644  7.824058
44  0.504272  7.908825  0.511719  7.789304
45  0.504883  7.897592  0.505005  7.894999
46  0.498291  8.001490  0.498535  7.997096
47  0.497070  8.020035  0.499634  7.978788
48  0.495605  8.042702  0.495117  8.050210
49  0.501709  7.944901  0.502075  7.938867
50  0.500244  7.967907  0.503540  7.915228
51  0.492554  8.090275  0.492920  8.084349
52  0.500488  7.963626  0.490967  8.115366
53  0.498901  7.988830  0.503784  7.910952
54  0.507446  7.852546  0.499390  7.980969
55  0.510986  7.796077  0.497192  8.015975
56  0.500122  7.969262  0.499512  7.978987
57  0.502319  7.934223  0.503540  7.914760
58  0.499268  7.982872  0.501221  7.951733
59  0.499878  7.973139  0.498535  7.994546
60  0.503784  7.910864  0.500488  7.963408
61  0.499878  7.973138  0.499268  7.982869
62  0.504883  7.893349  0.496460  8.027629
63  0.507568  8.058436  0.502808  8.149326

2018-02-25 04:15:51.228437 Finish.
Total elapsed time: 07:48:40.23.
