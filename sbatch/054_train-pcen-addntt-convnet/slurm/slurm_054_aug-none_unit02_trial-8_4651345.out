2018-02-24 20:27:16.376538: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:16.376796: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:16.376809: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:11.723243 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit03, unit05, unit07.
Validation set: unit10, unit01.
Test set: unit02.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.890747  0.323903  0.825928  0.502431
1   0.926270  0.252403  0.740601  0.686409
2   0.930908  0.268965  0.876587  0.377719
3   0.932251  0.256166  0.880371  0.361049
4   0.519043  7.676096  0.501709  7.974653
5   0.499878  8.000423  0.500854  7.981850
6   0.494995  8.072867  0.490479  8.142672
7   0.492554  8.109844  0.501221  7.995399
8   0.491577  8.146629  0.498901  8.027808
9   0.497803  8.043704  0.506592  7.902068
10  0.512573  7.805375  0.498047  8.035682
11  0.499512  8.011173  0.497192  8.047032
12  0.493774  8.100496  0.488037  8.190962
13  0.508179  7.868924  0.500000  7.998397
14  0.501953  7.966395  0.494995  8.076468
15  0.505981  7.900503  0.505249  7.911368
16  0.500244  7.990374  0.490479  8.145280
17  0.503296  7.940180  0.499023  8.007532
18  0.484985  8.230588  0.495728  8.058586
19  0.492310  8.112345  0.498413  8.014307
20  0.509888  7.830655  0.501831  7.958377
21  0.502319  7.949888  0.483887  8.243042
22  0.502808  7.940711  0.501343  7.963379
23  0.510254  7.820649  0.501099  7.965944
24  0.502075  7.949737  0.501831  7.952996
25  0.510742  7.810324  0.498413  8.006278
26  0.506470  7.877264  0.493896  8.077147
27  0.507324  7.862543  0.496582  8.033275
28  0.496338  8.036674  0.498413  8.003107
29  0.491577  8.111636  0.503784  7.916586
30  0.501099  7.958990  0.501221  7.956644
31  0.500488  7.967952  0.500488  7.967594
32  0.492676  8.091815  0.500366  7.968892
33  0.497803  8.009469  0.505981  7.878800
34  0.500732  7.962226  0.501343  7.952249
35  0.489136  8.146636  0.501587  7.947921
36  0.506348  7.871831  0.492432  8.093501
37  0.504150  7.906512  0.498169  8.001713
38  0.494873  8.054118  0.489990  8.131829
39  0.492920  8.085006  0.494263  8.063488
40  0.495728  8.040039  0.499512  7.979619
41  0.497437  8.012623  0.501099  7.954166
42  0.499634  7.977455  0.496704  8.024101
43  0.512085  7.778843  0.502197  7.936430
44  0.498535  7.994773  0.505615  7.881864
45  0.496582  8.025844  0.488159  8.160097
46  0.515503  7.724150  0.497437  8.012151
47  0.507935  7.844771  0.492188  8.095802
48  0.502197  7.936211  0.491333  8.109403
49  0.499023  8.012961  0.495728  8.074543
50  0.493896  8.133436  0.502441  7.989871
51  0.496460  8.083250  0.492554  8.144183
52  0.501221  8.005205  0.503906  7.961678
53  0.505005  7.943545  0.498535  8.046083
54  0.502563  7.981275  0.504272  7.953438
55  0.493286  8.127995  0.499390  8.030091
56  0.506470  7.916614  0.502686  7.976328
57  0.486084  8.240377  0.493652  8.119089
58  0.503662  7.958871  0.490723  8.164508
59  0.497681  8.052924  0.503540  7.958844
60  0.503540  7.958168  0.495239  8.089813
61  0.502808  7.968458  0.497925  8.045592
62  0.494507  8.099364  0.500488  8.003274
63  0.502197  7.975289  0.494995  8.089355

2018-02-25 04:14:33.535344 Finish.
Total elapsed time: 07:47:22.54.
