2018-02-24 20:27:16.828292: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:16.828550: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:16.828565: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:16.828571: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:16.828577: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.741687 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit05, unit07, unit10.
Validation set: unit01, unit02.
Test set: unit03.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.499756  7.981630  0.500122  7.974619
1   0.494751  8.059376  0.506958  7.864002
2   0.502930  7.927637  0.496826  8.024419
3   0.499023  7.988981  0.501709  7.945800
4   0.499390  7.982484  0.499146  7.986114
5   0.509033  7.821286  0.494751  8.214166
6   0.500366  8.127391  0.494019  8.213980
7   0.509766  7.953585  0.493652  8.207850
8   0.491333  8.241095  0.497314  8.140920
9   0.495605  8.165351  0.493774  8.191975
10  0.498657  8.110822  0.489258  8.260028
11  0.504883  8.006201  0.493530  8.187312
12  0.492920  8.195507  0.505493  7.991287
13  0.496338  8.137458  0.495239  8.153828
14  0.507080  7.961766  0.501587  8.049137
15  0.494629  8.160216  0.494751  8.157209
16  0.506470  7.967367  0.499023  8.086453
17  0.506592  7.963600  0.500244  8.065068
18  0.497437  8.109538  0.496704  8.120580
19  0.507446  7.946730  0.507812  7.940139
20  0.506836  7.955246  0.503418  8.009724
21  0.505371  7.977681  0.490967  8.209309
22  0.507812  7.998377  0.492310  8.279736
23  0.493164  8.246228  0.501099  8.101921
24  0.502319  8.067653  0.495972  8.155006
25  0.506592  7.973757  0.493652  8.168788
26  0.494629  8.143417  0.491577  8.182803
27  0.492920  8.153303  0.497803  8.067806
28  0.506592  7.921005  0.493774  8.119031
29  0.493042  8.125210  0.504883  7.931256
30  0.496216  8.064939  0.501953  7.969251
31  0.511841  7.807986  0.493164  8.102337
32  0.492676  8.107220  0.493530  8.090893
33  0.494995  8.065257  0.499390  7.993080
34  0.502930  7.934876  0.500488  7.972169
35  0.493042  8.089537  0.498413  8.002680
36  0.507446  7.857668  0.492798  8.090290
37  0.493530  8.077884  0.505615  7.884562
38  0.500610  7.963832  0.502563  7.932230
39  0.497070  8.019442  0.502197  7.937385
40  0.493286  8.079206  0.500977  7.956387
41  0.487183  8.176134  0.500854  7.958031
42  0.499512  7.979335  0.504395  7.901403
43  0.494629  8.057027  0.500854  7.957722
44  0.498169  8.000498  0.505005  7.891486
45  0.499878  7.973199  0.497681  8.008211
46  0.504395  7.901164  0.498779  7.990675
47  0.505737  7.879741  0.501343  7.949795
48  0.502197  7.936169  0.499512  7.978981
49  0.498779  7.990656  0.509888  7.813561
50  0.496094  8.033468  0.494507  8.058767
51  0.507446  7.852481  0.499268  7.963658
52  0.495972  8.350644  0.494019  8.396691
53  0.489258  8.463713  0.501221  8.261415
54  0.494385  8.362721  0.511597  8.076584
55  0.488892  8.434305  0.498291  8.274683
56  0.499512  8.247279  0.500122  8.229803
57  0.502197  8.189056  0.500000  8.217246
58  0.501343  8.188677  0.499390  8.213294
59  0.510864  8.021755  0.510254  8.025058
60  0.496338  8.243082  0.507812  8.051911
61  0.500854  8.158086  0.492920  8.280054
62  0.496704  8.213383  0.508667  8.014942
63  0.505615  8.058751  0.507812  8.018016

2018-02-25 04:23:17.527055 Finish.
Total elapsed time: 07:56:08.53.
