2018-02-24 20:27:13.858217: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.858586: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.858609: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.858619: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.858628: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.623293 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit10, unit01, unit02.
Validation set: unit03, unit05.
Test set: unit07.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.965576  0.175213  0.982300  0.093692
1   0.979980  0.103783  0.971191  0.112085
2   0.798950  3.171884  0.576660  6.882772
3   0.613159  6.289271  0.576782  6.871369
4   0.747925  4.103941  0.798584  3.288098
5   0.743896  4.149474  0.511841  7.832874
6   0.499512  8.026472  0.505371  7.930943
7   0.503662  7.956000  0.506836  7.904082
8   0.494141  8.104900  0.502441  7.971006
9   0.496460  8.064919  0.506348  7.906134
10  0.486572  8.219898  0.506836  7.896095
11  0.490356  8.157667  0.513062  7.794806
12  0.496582  8.056497  0.510376  7.835920
13  0.496582  8.054444  0.515991  7.744569
14  0.537842  7.413950  0.604004  6.428240
15  0.697754  4.918002  0.539429  7.498059
16  0.551025  7.303750  0.524048  7.736065
17  0.560669  7.144313  0.569214  7.006641
18  0.577881  6.864359  0.531372  7.612401
19  0.557007  7.197979  0.533325  7.578509
20  0.556396  7.205515  0.531250  7.609856
21  0.549316  7.317670  0.524170  7.722052
22  0.549194  7.317740  0.528198  7.655330
23  0.558716  7.162592  0.515503  7.858257
24  0.543213  7.410811  0.535156  7.539859
25  0.583740  6.754758  0.495850  8.154660
26  0.494385  8.165454  0.491943  8.196324
27  0.493164  8.172453  0.509277  7.911937
28  0.499878  8.059174  0.499268  8.066586
29  0.498291  8.080298  0.497559  8.090261
30  0.489014  8.225028  0.490234  8.204187
31  0.503784  7.986948  0.511719  7.859277
32  0.506592  7.939940  0.507446  7.925275
33  0.504395  7.972956  0.492310  8.164667
34  0.497559  8.080083  0.503174  7.989672
35  0.500977  8.023849  0.501709  8.011325
36  0.505981  7.942391  0.496216  8.097259
37  0.496216  8.096460  0.498779  8.054791
38  0.507935  7.908048  0.496094  8.096029
39  0.508057  7.904532  0.503296  7.979645
40  0.499146  8.045032  0.504395  7.960564
41  0.499023  8.045410  0.499146  8.042673
42  0.499634  8.034100  0.495239  8.103361
43  0.505005  7.946876  0.498657  8.047264
44  0.509277  7.877146  0.499023  8.039798
45  0.507690  7.900804  0.497437  8.063443
46  0.496582  8.076231  0.494141  8.114307
47  0.499390  8.029776  0.497314  8.062000
48  0.503418  7.963833  0.500610  8.007720
49  0.503784  7.956246  0.499023  8.031257
50  0.503418  7.960310  0.503906  7.951627
51  0.500610  8.003272  0.505859  7.918680
52  0.503418  7.956693  0.505127  7.928529
53  0.502075  7.976264  0.490845  8.154377
54  0.499756  8.011389  0.508423  7.872285
55  0.490601  8.155486  0.497925  8.037784
56  0.504883  7.925927  0.496948  8.051486
57  0.490479  8.153699  0.499390  8.010698
58  0.501587  7.974741  0.495605  8.069166
59  0.487915  8.190848  0.498413  8.022556
60  0.512207  7.801733  0.497925  8.028507
61  0.512329  7.797964  0.489990  8.153192
62  0.500732  7.981045  0.500854  7.978207
63  0.502075  7.957873  0.499390  7.999813

2018-02-25 03:59:52.512278 Finish.
Total elapsed time: 07:32:43.51.
