2018-02-24 20:27:15.506472: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.506742: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.506760: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.506768: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.506775: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.741687 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit10, unit01, unit02.
Validation set: unit03, unit05.
Test set: unit07.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.498779  8.096225  0.503540  8.017752
1   0.497803  8.108768  0.505615  7.981488
2   0.496948  8.120028  0.497803  8.105172
3   0.497925  8.102271  0.494263  8.160418
4   0.504150  8.000283  0.502808  8.021203
5   0.507324  7.947772  0.503296  8.012102
6   0.511719  7.914689  0.501587  8.142374
7   0.504028  8.083371  0.503174  8.082334
8   0.504639  8.049030  0.493164  8.225596
9   0.499756  8.112890  0.501709  8.075553
10  0.504639  8.023518  0.501587  8.068251
11  0.503174  8.038903  0.499023  8.102276
12  0.512329  7.884797  0.505493  7.992149
13  0.500610  8.068418  0.506836  7.965791
14  0.499634  8.079915  0.500122  8.070206
15  0.500366  8.064697  0.501343  8.047485
16  0.501587  8.042297  0.499268  8.078513
17  0.501465  8.042109  0.498657  8.086445
18  0.502563  8.022715  0.506836  7.953139
19  0.499390  8.072567  0.507812  7.936261
20  0.498535  8.085344  0.508545  7.923593
21  0.499268  8.072787  0.495605  8.131505
22  0.506714  7.952208  0.506836  7.950012
23  0.491333  8.199705  0.492920  8.173960
24  0.497803  8.095125  0.499146  8.073361
25  0.499023  8.075233  0.491699  8.193199
26  0.506226  7.958994  0.501831  8.029766
27  0.503296  8.006109  0.496094  8.122153
28  0.518433  7.762062  0.497559  8.098484
29  0.501343  8.015828  0.500732  8.030658
30  0.502930  7.995467  0.501831  8.012827
31  0.504395  7.971811  0.494873  8.123460
32  0.497070  8.088285  0.503418  7.986935
33  0.500854  8.027639  0.499878  8.043036
34  0.502319  8.003930  0.499634  8.046553
35  0.495361  8.114462  0.490601  8.190150
36  0.503174  7.989478  0.498169  8.069035
37  0.503784  7.979272  0.496216  8.099676
38  0.503052  7.990425  0.497437  8.079667
39  0.502441  7.999583  0.497437  8.079068
40  0.489624  8.203300  0.504028  7.973332
41  0.489746  8.200678  0.496338  8.095232
42  0.499512  8.044262  0.495361  8.110045
43  0.506226  7.936444  0.498779  8.054746
44  0.498047  8.065997  0.498657  8.055829
45  0.505371  7.948342  0.495850  8.099674
46  0.499756  8.036922  0.496704  8.085086
47  0.506714  7.925006  0.495239  8.107425
48  0.495972  8.095224  0.510254  7.866995
49  0.500244  8.026028  0.503662  7.970979
50  0.497314  8.071606  0.507568  7.907554
51  0.492310  8.150224  0.500610  8.017286
52  0.505493  7.938828  0.497803  8.060806
53  0.493896  8.122443  0.492432  8.145144
54  0.514893  7.786399  0.491211  8.163262
55  0.491455  8.158676  0.507812  7.897190
56  0.502197  7.985985  0.501221  8.000810
57  0.500977  8.003939  0.500122  8.016781
58  0.500244  8.014032  0.495972  8.081322
59  0.491699  8.148590  0.500732  8.003712
60  0.494873  8.096233  0.495850  8.079750
61  0.489990  8.172224  0.507324  7.894917
62  0.492065  8.137193  0.496460  8.066124
63  0.503662  7.950272  0.506836  7.898619

2018-02-25 04:27:02.042766 Finish.
Total elapsed time: 07:59:53.04.
