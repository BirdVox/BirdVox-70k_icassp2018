2018-02-24 20:27:15.314751: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.315008: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.315027: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.315037: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.315046: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:08.360193 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit07, unit10, unit01.
Validation set: unit02, unit03.
Test set: unit05.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.953369  0.143990  0.902344  0.319282
1   0.956787  0.148887  0.927246  0.220945
2   0.947144  0.180927  0.940674  0.206940
3   0.951416  0.158342  0.925293  0.241526
4   0.950928  0.166599  0.918457  0.283322
5   0.902710  1.047666  0.501953  8.064201
6   0.498169  8.117947  0.495972  8.148084
7   0.506226  7.979451  0.499512  8.084756
8   0.492310  8.198603  0.500122  8.070661
9   0.505127  7.988354  0.492554  8.189508
10  0.505005  7.987572  0.495728  8.135953
11  0.507446  7.946104  0.498535  8.088840
12  0.496338  8.123504  0.507202  7.947696
13  0.497437  8.104514  0.497803  8.098069
14  0.494873  8.144836  0.496704  8.114903
15  0.512695  7.856805  0.501221  8.041431
16  0.492432  8.182826  0.499268  8.072397
17  0.497314  8.103675  0.495239  8.136936
18  0.494385  8.150555  0.489502  8.229116
19  0.506348  7.957479  0.495850  8.126582
20  0.502808  8.014346  0.494385  8.150027
21  0.491455  8.197184  0.494385  8.149904
22  0.496948  8.108537  0.500122  8.057337
23  0.497192  8.104522  0.496826  8.110392
24  0.501831  8.029696  0.495483  8.131984
25  0.494751  8.143769  0.502808  8.013893
26  0.508667  7.919436  0.503906  7.996157
27  0.497314  8.102394  0.501587  8.033520
28  0.499390  8.068928  0.488403  8.245999
29  0.510254  7.893804  0.505127  7.976435
30  0.489868  8.222374  0.497559  8.098415
31  0.491821  8.190887  0.501343  8.037416
32  0.505493  7.970517  0.491821  8.190880
33  0.495850  8.125950  0.502808  8.013799
34  0.492188  8.183441  0.508057  7.862271
35  0.504272  7.935575  0.497559  8.029561
36  0.509521  7.836498  0.507568  7.866077
37  0.490845  8.131817  0.505981  7.889768
38  0.494385  8.074083  0.499634  7.989879
39  0.498413  8.008882  0.504883  7.905295
40  0.493042  8.093650  0.489258  8.153569
41  0.494019  8.077276  0.508911  7.839459
42  0.500488  7.973355  0.508545  7.844529
43  0.509644  7.826640  0.499146  7.993629
44  0.499268  7.991317  0.502686  7.936460
45  0.496704  8.031463  0.498901  7.996079
46  0.493164  8.087202  0.504272  7.909766
47  0.503784  7.917221  0.502563  7.936355
48  0.487793  8.171519  0.496216  8.036929
49  0.500366  7.970467  0.499878  7.977960
50  0.501709  7.948494  0.492188  8.100018
51  0.496094  8.037488  0.500366  7.969124
52  0.505005  7.894939  0.504150  7.908333
53  0.502075  7.941203  0.505615  7.884559
54  0.495483  8.045892  0.507202  7.858881
55  0.498291  8.000773  0.503296  7.920817
56  0.506592  7.868119  0.501099  7.955545
57  0.503540  7.916487  0.497803  8.007823
58  0.502075  7.939590  0.496216  8.032888
59  0.503296  7.919910  0.507935  7.845857
60  0.496826  8.022860  0.503052  7.923521
61  0.502808  7.927334  0.498047  8.003155
62  0.498047  8.003085  0.501221  7.952420
63  0.505981  7.876463  0.495605  8.041823

2018-02-25 04:31:46.302790 Finish.
Total elapsed time: 08:04:38.30.
