2018-02-24 20:27:19.083880: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:19.084158: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:19.084171: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:11.924755 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit07, unit10, unit01.
Validation set: unit02, unit03.
Test set: unit05.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.959961  0.162117  0.979492  0.096501
1   0.948242  0.208412  0.978027  0.114981
2   0.951172  0.178575  0.974731  0.108600
3   0.958984  0.153884  0.978271  0.101863
4   0.966431  0.135239  0.971069  0.150513
5   0.967285  0.128746  0.980225  0.111618
6   0.969360  0.131550  0.983521  0.085545
7   0.968750  0.121937  0.983398  0.092722
8   0.953247  0.177491  0.980713  0.100867
9   0.966064  0.138780  0.973267  0.131105
10  0.962646  0.156201  0.979492  0.107330
11  0.806519  2.834932  0.491577  8.255533
12  0.526001  7.690924  0.571411  6.964325
13  0.518066  7.751949  0.504761  7.951509
14  0.511475  7.841617  0.498291  8.049136
15  0.493408  8.124675  0.491699  8.149728
16  0.504395  7.945375  0.500366  8.007712
17  0.499512  8.019622  0.505859  7.916768
18  0.494873  8.090390  0.496338  8.065552
19  0.494263  8.097255  0.499023  8.020007
20  0.494019  8.098531  0.499634  8.007767
21  0.502319  7.963777  0.497681  8.036570
22  0.500610  7.988762  0.503296  7.944858
23  0.499390  8.006090  0.491211  8.135445
24  0.493530  8.097477  0.504028  7.929128
25  0.498291  8.019645  0.493042  8.102385
26  0.497559  8.029471  0.492554  8.108358
27  0.504883  7.910933  0.501343  7.966505
28  0.499756  7.990972  0.498779  8.005715
29  0.499512  7.993244  0.494141  8.078085
30  0.499146  7.997541  0.499390  7.992902
31  0.487183  8.186799  0.504272  7.913642
32  0.484009  8.236024  0.494263  8.071893
33  0.496948  8.028455  0.495239  8.055087
34  0.505859  7.885201  0.497314  8.020863
35  0.499634  7.983359  0.494873  8.058741
36  0.501709  7.949282  0.503662  7.917679
37  0.504517  7.903628  0.493774  8.074468
38  0.502563  7.933971  0.496094  8.036748
39  0.498535  7.997495  0.497192  8.018585
40  0.504761  7.897643  0.498779  7.992730
41  0.509644  7.819287  0.493042  8.083728
42  0.491577  8.106882  0.511841  7.783642
43  0.503296  7.919707  0.505493  7.884525
44  0.496582  8.026460  0.497559  8.010772
45  0.505371  7.886121  0.500732  7.959980
46  0.497070  8.018287  0.493896  8.068816
47  0.500977  7.955886  0.494873  8.053140
48  0.504028  7.907143  0.502808  7.926569
49  0.493530  8.074444  0.502808  7.926516
50  0.509644  7.817517  0.502075  7.938158
51  0.499512  7.979015  0.490479  8.123015
52  0.497925  8.004297  0.500366  7.965369
53  0.505615  7.881683  0.504639  7.897164
54  0.500366  7.989884  0.499146  8.104340
55  0.496826  8.140063  0.493774  8.187778
56  0.509888  7.926914  0.502075  8.051770
57  0.491943  8.214148  0.503296  8.030279
58  0.508911  7.938968  0.510620  7.910642
59  0.502197  8.045677  0.501953  8.048902
60  0.511719  7.890828  0.495605  8.149882
61  0.506104  7.980041  0.492676  8.195844
62  0.505737  7.984712  0.495239  8.153318
63  0.499756  8.079935  0.505249  7.990812

2018-02-25 04:30:18.239691 Finish.
Total elapsed time: 08:03:07.24.
