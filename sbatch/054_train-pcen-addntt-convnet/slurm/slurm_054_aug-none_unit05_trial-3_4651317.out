2018-02-24 20:27:13.588782: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.589011: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.589025: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.589030: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:13.589034: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.623191 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit07, unit10, unit01.
Validation set: unit02, unit03.
Test set: unit05.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.494751  8.159168  0.505981  7.975428
1   0.486938  8.282372  0.499634  8.076514
2   0.496826  8.120800  0.502808  8.023284
3   0.501953  8.036348  0.492065  8.194475
4   0.495117  8.145017  0.501465  8.041684
5   0.496826  8.116199  0.506958  7.951572
6   0.498901  8.081676  0.497803  8.098299
7   0.500732  8.051254  0.500000  8.060954
8   0.501343  8.040647  0.498901  8.079654
9   0.502441  8.022292  0.513550  7.839640
10  0.498901  8.078808  0.499634  8.064142
11  0.506104  7.962273  0.504761  7.976544
12  0.490479  8.213748  0.504272  7.985476
13  0.499268  8.074492  0.508179  7.923944
14  0.497192  8.080317  0.496582  8.076110
15  0.496826  8.063685  0.491577  8.140262
16  0.501343  7.979488  0.501709  7.969192
17  0.505981  7.897635  0.496582  8.044384
18  0.504150  7.921233  0.501465  7.961770
19  0.492798  8.098074  0.492676  8.098303
20  0.494995  8.059906  0.501221  7.959347
21  0.487915  8.170389  0.508057  7.848288
22  0.502197  7.940881  0.501099  7.957644
23  0.490601  8.124393  0.500122  7.972038
24  0.503662  7.915148  0.513184  7.762941
25  0.508545  7.836564  0.500366  7.966656
26  0.509277  7.824358  0.494995  8.051842
27  0.489746  8.135362  0.490234  8.127434
28  0.508179  7.841249  0.495972  8.035028
29  0.491699  8.103802  0.496826  8.022003
30  0.491821  8.101747  0.512573  7.770103
31  0.503540  7.971663  0.491455  8.273444
32  0.485718  8.334367  0.512817  7.880996
33  0.505005  8.000204  0.510742  7.902772
34  0.500610  8.063135  0.501465  8.046954
35  0.491943  8.198752  0.505249  7.982846
36  0.501343  8.044718  0.495483  8.138189
37  0.500000  8.064622  0.495850  8.130821
38  0.492310  8.187313  0.496094  8.125799
39  0.500122  8.060439  0.514038  7.835742
40  0.494263  8.154150  0.502441  8.022016
41  0.503784  8.000112  0.500244  8.056927
42  0.497314  8.225145  0.499756  8.262387
43  0.495239  8.331764  0.500610  8.242391
44  0.499756  8.254040  0.495728  8.316967
45  0.494995  8.326889  0.492798  8.360410
46  0.496338  8.301438  0.495483  8.313247
47  0.503662  8.179393  0.490356  8.391764
48  0.505371  8.147585  0.504639  8.157148
49  0.503418  8.174493  0.503540  8.170121
50  0.491943  8.354537  0.501709  8.194555
51  0.508911  8.075791  0.497681  8.254044
52  0.493408  8.320046  0.494751  8.295456
53  0.496460  8.264861  0.500854  8.190894
54  0.503296  8.148310  0.492920  8.312230
55  0.498535  8.218309  0.501221  8.171525
56  0.513428  7.971188  0.500488  8.176082
57  0.503418  8.125126  0.487915  8.371192
58  0.499878  8.174506  0.499756  8.172539
59  0.502563  8.123314  0.507080  8.046486
60  0.514893  7.916521  0.498169  8.181985
61  0.496094  8.211356  0.502930  8.097062
62  0.496094  8.203173  0.503662  8.077095
63  0.509155  7.984534  0.504761  8.051338

2018-02-25 04:00:59.279176 Finish.
Total elapsed time: 07:33:50.28.
