2018-02-24 20:27:15.193975: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.194268: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.194281: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:12.070528 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit02, unit03, unit05.
Validation set: unit07, unit10.
Test set: unit01.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.498779  8.008414  0.496704  8.040242
1   0.498657  8.007977  0.497192  8.030249
2   0.496094  8.043581  0.497070  8.153489
3   0.496582  8.175684  0.491211  8.256997
4   0.494873  8.193691  0.495361  8.182033
5   0.491821  8.236045  0.496826  8.152554
6   0.495850  8.165862  0.503784  8.035660
7   0.498291  8.122121  0.498413  8.118143
8   0.492065  8.218600  0.511841  7.898046
9   0.504028  8.022271  0.500854  8.071761
10  0.494873  8.166598  0.495239  8.159150
11  0.500488  8.073083  0.499023  8.095255
12  0.502686  8.034872  0.504883  7.998123
13  0.500732  8.063765  0.505981  7.977932
14  0.495239  8.149927  0.500977  8.056330
15  0.504272  8.002162  0.495850  8.136906
16  0.504761  7.992338  0.501953  8.036682
17  0.500244  8.063396  0.503296  8.013403
18  0.505859  7.971356  0.502319  8.027714
19  0.500122  8.062500  0.507202  7.947781
20  0.506958  7.951180  0.502319  8.025438
21  0.504395  7.991542  0.498657  8.083593
22  0.500610  8.051745  0.498291  8.088783
23  0.492432  8.182929  0.493286  8.168880
24  0.507080  7.946314  0.502197  8.024800
25  0.494141  8.154477  0.492310  8.183825
26  0.494751  8.144339  0.495850  8.126508
27  0.498901  8.063150  0.493896  8.089420
28  0.499878  7.984706  0.506104  7.881242
29  0.498657  7.998286  0.491577  8.109876
30  0.495850  8.040929  0.501587  7.948753
31  0.494019  8.068891  0.496704  8.025622
32  0.496704  8.229402  0.503906  8.154080
33  0.499512  8.206777  0.500244  8.182391
34  0.502808  8.133790  0.499512  8.180814
35  0.490112  8.327719  0.503296  8.111026
36  0.502197  8.125133  0.494385  8.247614
37  0.495972  8.218877  0.498657  8.172496
38  0.494263  8.240385  0.500977  8.129250
39  0.500122  8.140194  0.493286  8.247554
40  0.499756  8.140517  0.502319  8.096438
41  0.500000  8.131118  0.503174  8.077253
42  0.499268  8.137562  0.499023  8.138841
43  0.489746  8.285776  0.500732  8.106099
44  0.501953  8.083889  0.490967  8.258438
45  0.492188  8.236302  0.496948  8.157117
46  0.493408  8.211801  0.509644  7.947757
47  0.490479  8.254384  0.489746  8.263930
48  0.496582  8.151580  0.501465  8.070732
49  0.504028  8.027363  0.491577  8.226028
50  0.498535  8.111955  0.503418  8.031360
51  0.490845  8.232227  0.497070  8.130126
52  0.496216  8.142249  0.506104  7.981262
53  0.510376  7.910889  0.495239  8.153392
54  0.503418  8.020201  0.504028  8.009033
55  0.504639  7.997970  0.494507  8.160088
56  0.493408  8.176707  0.503418  8.014317
57  0.511353  7.885471  0.504028  8.002602
58  0.495850  8.133597  0.499878  8.067871
59  0.502686  8.021905  0.504883  7.985809
60  0.501709  8.036361  0.504150  7.996436
61  0.495728  8.131693  0.490112  8.221724
62  0.493164  8.172122  0.502808  8.016298
63  0.493530  8.165498  0.498657  8.082549

2018-02-25 04:25:17.230211 Finish.
Total elapsed time: 07:58:05.23.
