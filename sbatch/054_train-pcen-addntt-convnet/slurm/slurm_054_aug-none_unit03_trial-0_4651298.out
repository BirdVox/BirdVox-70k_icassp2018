2018-02-24 20:27:15.120580: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.120843: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.120858: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.120865: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 20:27:15.120871: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
2018-02-24 20:27:09.042340 Start.
Training mixture of experts with adaptive threshold on BirdVox-70k with PCEN input. 
Training set: unit05, unit07, unit10.
Validation set: unit01, unit02.
Test set: unit03.

h5py version: 2.6.0
keras version: 2.0.6
numpy version: 1.13.1
pandas version: 0.20.3
pescador version: 1.0.0
tensorflow version: 1.2.1

____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
spec_input (InputLayer)          (None, 128, 104, 1)   0                                            
____________________________________________________________________________________________________
spec_bn (BatchNormalization)     (None, 128, 104, 1)   4           spec_input[0][0]                 
____________________________________________________________________________________________________
spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn[0][0]                    
____________________________________________________________________________________________________
bg_input (InputLayer)            (None, 128, 9)        0                                            
____________________________________________________________________________________________________
spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 
____________________________________________________________________________________________________
bg_pool (AveragePooling1D)       (None, 32, 9)         0           bg_input[0][0]                   
____________________________________________________________________________________________________
spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 
____________________________________________________________________________________________________
bg_permute (Permute)             (None, 9, 32)         0           bg_pool[0][0]                    
____________________________________________________________________________________________________
spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 
____________________________________________________________________________________________________
bg_conv (Conv1D)                 (None, 9, 8)          264         bg_permute[0][0]                 
____________________________________________________________________________________________________
spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 
____________________________________________________________________________________________________
bg_flatten (Flatten)             (None, 72)            0           bg_conv[0][0]                    
____________________________________________________________________________________________________
spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 
____________________________________________________________________________________________________
bg_dense1 (Dense)                (None, 64)            4672        bg_flatten[0][0]                 
____________________________________________________________________________________________________
spec_dense (Dense)               (None, 64)            589888      spec_flatten[0][0]               
____________________________________________________________________________________________________
bg_experts (Dense)               (None, 4)             260         bg_dense1[0][0]                  
____________________________________________________________________________________________________
spec_reshape (Reshape)           (None, 16, 4)         0           spec_dense[0][0]                 
____________________________________________________________________________________________________
bg_reshape (Reshape)             (None, 1, 4)          0           bg_experts[0][0]                 
____________________________________________________________________________________________________
multiply (Multiply)              (None, 16, 4)         0           spec_reshape[0][0]               
                                                                   bg_reshape[0][0]                 
____________________________________________________________________________________________________
mixture_of_experts (Flatten)     (None, 64)            0           multiply[0][0]                   
____________________________________________________________________________________________________
adaptive_threshold (Dense)       (None, 1)             64          bg_dense1[0][0]                  
____________________________________________________________________________________________________
concatenate (Concatenate)        (None, 65)            0           mixture_of_experts[0][0]         
                                                                   adaptive_threshold[0][0]         
____________________________________________________________________________________________________
dense (Dense)                    (None, 1)             66          concatenate[0][0]                
====================================================================================================
Total params: 682,338
Trainable params: 682,336
Non-trainable params: 2
____________________________________________________________________________________________________
         acc      loss   val_acc  val_loss
0   0.979370  0.095477  0.778809  0.481528
1   0.762451  3.684468  0.507812  7.965415
2   0.498413  8.113101  0.503052  8.035047
3   0.503540  8.024609  0.495605  8.150155
4   0.500854  8.063606  0.508789  7.933910
5   0.505371  7.987468  0.489136  8.247716
6   0.509033  7.925775  0.497070  8.117435
7   0.508667  7.929515  0.493042  8.180414
8   0.495117  8.146139  0.502197  8.031240
9   0.499390  8.075808  0.490479  8.218787
10  0.503662  8.005719  0.499390  8.074036
11  0.499146  8.077489  0.499146  8.077028
12  0.503540  8.005789  0.502808  8.017206
13  0.491211  8.203779  0.498535  8.085399
14  0.502563  8.020181  0.500488  8.053354
15  0.504517  7.988184  0.498291  8.088299
16  0.498901  8.078262  0.496094  8.123328
17  0.498657  8.081847  0.501221  8.040376
18  0.496826  8.111077  0.507324  7.941747
19  0.506958  7.947547  0.498047  8.091083
20  0.497437  8.100841  0.505371  7.972877
21  0.497681  8.096773  0.502686  8.016049
22  0.494263  8.168282  0.507568  8.003254
23  0.492920  8.205646  0.490234  8.226769
24  0.494385  8.147920  0.507080  7.934990
25  0.497314  8.083067  0.498047  8.064661
26  0.494141  8.121617  0.504883  7.945506
27  0.500732  8.007646  0.502075  7.982498
28  0.498291  8.039634  0.496582  8.063880
29  0.494873  8.088520  0.496460  8.060755
30  0.498413  8.027449  0.500854  7.986464
31  0.507324  7.881489  0.491333  8.134676
32  0.500244  7.991044  0.498291  8.020678
33  0.492065  8.118574  0.496826  8.041372
34  0.498047  8.020728  0.500000  7.988448
35  0.504883  7.909561  0.502563  7.945527
36  0.505371  7.899841  0.507568  7.863912
37  0.501099  7.966226  0.495239  8.058833
38  0.502197  7.947162  0.500610  7.971737
39  0.503662  7.922414  0.501709  7.952899
40  0.485107  8.216964  0.506958  7.868025
41  0.495728  8.046522  0.503540  7.921444
42  0.495361  8.051345  0.501465  7.953568
43  0.500488  7.968702  0.501831  7.946874
44  0.513306  7.763557  0.499390  7.985040
45  0.494873  8.056707  0.500854  7.961023
46  0.498169  8.003542  0.504517  7.902062
47  0.495850  8.039980  0.504639  7.899617
48  0.502075  7.940267  0.498657  7.994550
49  0.498657  7.994365  0.498779  7.992242
50  0.499878  7.974572  0.494385  8.061998
51  0.492310  8.094951  0.489136  8.145426
52  0.494507  8.059690  0.499268  7.983690
53  0.503174  7.921325  0.491455  8.108066
54  0.485840  8.197512  0.496094  8.033972
55  0.497314  8.014450  0.504028  7.907359
56  0.511353  7.790545  0.502808  7.926725
57  0.491699  8.103781  0.503784  7.911081
58  0.507446  7.852668  0.500610  7.961620
59  0.500732  7.959650  0.507935  7.844808
60  0.504150  8.004327  0.496338  8.160340
61  0.508301  7.946719  0.499634  8.068321
62  0.499390  8.062064  0.509644  7.890031
63  0.489136  8.210644  0.503662  7.973407

2018-02-25 04:39:44.439142 Finish.
Total elapsed time: 08:12:35.44.
