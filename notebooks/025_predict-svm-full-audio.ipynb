{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-27 09:48:12.732515 Start.\n",
      "Running probabilistic SVM on BirdVox-70k full audio.\n",
      "Test unit: unit05.\n",
      "Trial ID: 6.\n",
      "\n",
      "h5py version: 2.6.0\n",
      "numpy version: 1.13.1\n",
      "pandas version: 0.20.3\n",
      "scikit-learn version: 0.18.2\n",
      "skm version: 0.0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import h5py\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn.preprocessing\n",
    "import sklearn.svm\n",
    "import skm\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "import localmodule\n",
    "\n",
    "\n",
    "# Define constants.\n",
    "data_dir = localmodule.get_data_dir()\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "patch_width = 32\n",
    "n_patches_per_clip = 1\n",
    "aug_str = \"original\"\n",
    "instanced_aug_str = aug_str\n",
    "clip_length = 104\n",
    "hop_length = 34\n",
    "hop_duration = hop_length * 32 / 22050\n",
    "patch_width = 32\n",
    "n_patches_per_clip = 3\n",
    "\n",
    "\n",
    "# Parse arguments.\n",
    "args = [\"unit05\", \"6\"]\n",
    "test_unit_str = args[0]\n",
    "trial_id = int(args[1])\n",
    "\n",
    "\n",
    "# Print header.\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "print(\"Running probabilistic SVM on \" + dataset_name + \" full audio.\")\n",
    "print(\"Test unit: \" + test_unit_str + \".\")\n",
    "print(\"Trial ID: \" + str(trial_id) + \".\")\n",
    "print(\"\")\n",
    "print(\"h5py version: {:s}\".format(h5py.__version__))\n",
    "print(\"numpy version: {:s}\".format(np.__version__))\n",
    "print(\"pandas version: {:s}\".format(pd.__version__))\n",
    "print(\"scikit-learn version: {:s}\".format(sklearn.__version__))\n",
    "print(\"skm version: {:s}\".format(skm.__version__))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Load SKM model.\n",
    "models_dir = localmodule.get_models_dir()\n",
    "model_name = \"skm-cv\"\n",
    "model_dir = os.path.join(models_dir, model_name)\n",
    "unit_dir = os.path.join(model_dir, test_unit_str)\n",
    "trial_str = \"trial-\" + str(trial_id)\n",
    "trial_dir = os.path.join(unit_dir, trial_str)\n",
    "skm_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    model_name,\n",
    "    test_unit_str,\n",
    "    trial_str,\n",
    "    \"model.pkl\"\n",
    "])\n",
    "skm_path = os.path.join(trial_dir, skm_name)\n",
    "skm_model = skm.SKM(k=256)\n",
    "skm_model = skm_model.load(skm_path)\n",
    "\n",
    "\n",
    "# Load scaler.\n",
    "scaler_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    model_name,\n",
    "    test_unit_str,\n",
    "    trial_str,\n",
    "    \"scaler.pkl\"\n",
    "])\n",
    "scaler_path = os.path.join(trial_dir, scaler_name)\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "\n",
    "# Load SVM model.\n",
    "val_metrics_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    model_name,\n",
    "    test_unit_str,\n",
    "    trial_str,\n",
    "    \"svm-model\",\n",
    "    \"val-metrics.csv\"])\n",
    "val_metrics_path = os.path.join(trial_dir, val_metrics_name)\n",
    "val_metrics_df = pd.read_csv(val_metrics_path, header=None,\n",
    "    names=[\n",
    "        \"Dataset\",\n",
    "        \"Test unit\",\n",
    "        \"Trial ID\",\n",
    "        \"log2(C)\",\n",
    "        \"Validation accuracy (%)\"\n",
    "    ])\n",
    "log2Cs = np.array(val_metrics_df[\"log2(C)\"])\n",
    "best_log2C_id = np.argmax(val_metrics_df[\"Validation accuracy (%)\"])\n",
    "best_log2C = log2Cs[best_log2C_id]\n",
    "if np.sign(best_log2C) >= 0:\n",
    "    best_log2C_str = \"+\" + str(abs(best_log2C)).zfill(2)\n",
    "else:\n",
    "    best_log2C_str = \"-\" + str(abs(best_log2C)).zfill(2)\n",
    "svm_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    model_name,\n",
    "    test_unit_str,\n",
    "    trial_str,\n",
    "    \"svm-proba-model\",\n",
    "    \"log2C-(\" + best_log2C_str + \").pkl\"\n",
    "])\n",
    "svm_path = os.path.join(trial_dir, svm_name)\n",
    "svc = joblib.load(svm_path)\n",
    "\n",
    "\n",
    "# Load features.\n",
    "logmelspec_name = \"_\".join([dataset_name, \"skm-full-logmelspec\"])\n",
    "logmelspec_dir = os.path.join(data_dir, logmelspec_name)\n",
    "hdf5_path = os.path.join(logmelspec_dir, test_unit_str + \".hdf5\")\n",
    "lms_container = h5py.File(hdf5_path)\n",
    "lms_group = lms_container[\"logmelspec\"]\n",
    "\n",
    "\n",
    "# Compute number of hops.\n",
    "n_hops = int(lms_group.shape[1] / hop_length) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-27 09:49:03.730064 Start.\n",
      "23\n",
      "2017-10-27 09:49:03.895166 Finish.\n",
      "Total elapsed time: 00:00:00.90.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create CSV file.\n",
    "prediction_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    model_name,\n",
    "    \"test-\" + test_unit_str,\n",
    "    trial_str,\n",
    "    \"predict-\" + test_unit_str,\n",
    "    \"full-predictions\"\n",
    "])\n",
    "prediction_path = os.path.join(trial_dir, prediction_name + \".csv\")\n",
    "csv_file = open(prediction_path, 'w')\n",
    "csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "\n",
    "\n",
    "# Create CSV header.\n",
    "csv_header = [\n",
    "    \"Dataset\",\n",
    "    \"Model\",\n",
    "    \"Test unit\",\n",
    "    \"Prediction unit\",\n",
    "    \"Timestamp\",\n",
    "    \"Predicted probability\"\n",
    "]\n",
    "csv_writer.writerow(csv_header)\n",
    "csv_file.close()\n",
    "\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "\n",
    "\n",
    "chunk_size = 100\n",
    "n_chunks = int(n_hops / chunk_size) + 1\n",
    "\n",
    "\n",
    "# Loop over hops.\n",
    "for chunk_id in [n_chunks-1]:#range(n_chunks):\n",
    "\n",
    "\n",
    "    # Initialize list of clips.\n",
    "    Xs = []\n",
    "\n",
    "\n",
    "    # Loop over clips.\n",
    "    n_hops_in_chunk = min(chunk_size, n_hops - chunk_id * chunk_size)\n",
    "    for hop_id in range(n_hops_in_chunk):\n",
    "\n",
    "        # Load clip in full logmelspec data.\n",
    "        clip_start = (chunk_id*chunk_size + hop_id) * hop_length\n",
    "        clip_stop = clip_start + patch_width\n",
    "        Xs.append(np.ravel(lms_group[:, clip_start:clip_stop]))\n",
    "\n",
    "\n",
    "    # Vectorize clips.\n",
    "    X = np.stack(Xs)\n",
    "\n",
    "\n",
    "    # Transform with SKM.\n",
    "    X = skm_model.transform(X.T).T\n",
    "\n",
    "\n",
    "    # Scale.\n",
    "    X = scaler.transform(X)\n",
    "\n",
    "\n",
    "    # Predict.\n",
    "    y_pred = svc.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "    # Open CSV file.\n",
    "    csv_file = open(prediction_path, 'a')\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "\n",
    "\n",
    "    # Loop over clips.\n",
    "    for hop_id in range(n_hops_in_chunk):\n",
    "        # Store prediction as DataFrame row.\n",
    "        timestamp = (chunk_id*chunk_size + hop_id) * hop_duration\n",
    "        timestamp_str = \"{:9.3f}\".format(timestamp)\n",
    "        predicted_probability_str = \"{:.16f}\".format(y_pred[hop_id])\n",
    "        row = [\n",
    "            dataset_name,\n",
    "            model_name,\n",
    "            test_unit_str,\n",
    "            test_unit_str,\n",
    "            timestamp_str,\n",
    "            predicted_probability_str]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "    # Close CSV file.\n",
    "    csv_file.close()\n",
    "    \n",
    "    \n",
    "\n",
    "print(str(datetime.datetime.now()) + \" Finish.\")\n",
    "elapsed_time = time.time() - int(start_time)\n",
    "elapsed_hours = int(elapsed_time / (60 * 60))\n",
    "elapsed_minutes = int((elapsed_time % (60 * 60)) / 60)\n",
    "elapsed_seconds = elapsed_time % 60.\n",
    "elapsed_str = \"{:>02}:{:>02}:{:>05.2f}\".format(elapsed_hours,\n",
    "                                               elapsed_minutes,\n",
    "                                               elapsed_seconds)\n",
    "print(\"Total elapsed time: \" + elapsed_str + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
