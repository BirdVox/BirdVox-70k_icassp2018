{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import h5py\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('../src')\n",
    "import localmodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-09 05:07:03.999838 Start.\n",
      "Evaluating Old Bird on BirdVox-70k, unit01.\n",
      "h5py version: 2.6.0\n",
      "mir_eval version: 0.4\n",
      "numpy version: 1.13.1\n",
      "pandas version: 0.20.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define constants.\n",
    "data_dir = localmodule.get_data_dir()\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "models_dir = localmodule.get_models_dir()\n",
    "negative_labels = localmodule.get_negative_labels()\n",
    "tolerances = localmodule.get_tolerances()\n",
    "n_thresholds = 100\n",
    "\n",
    "\n",
    "# Read command-line arguments.                           ENABLE\n",
    "#args = sys.argv[1:]\n",
    "#unit_str = args[0]\n",
    "#odf_str = args[1]\n",
    "#suppressor_str = args[2]\n",
    "unit_str = \"unit01\"\n",
    "odf_str = \"tseep\"\n",
    "clip_suppressor_str = \"clip-suppressor\"\n",
    "\n",
    "\n",
    "# Print header.\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "print(\"Evaluating Old Bird on \" + dataset_name + \", \" + unit_str + \".\")\n",
    "print('h5py version: {:s}'.format(h5py.__version__))\n",
    "print('mir_eval version: {:s}'.format(mir_eval.__version__))\n",
    "print('numpy version: {:s}'.format(np.__version__))\n",
    "print('pandas version: {:s}'.format(pd.__version__))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Define directory for predictions.\n",
    "oldbird_models_dir = os.path.join(models_dir, \"oldbird\")\n",
    "unit_dir = os.path.join(oldbird_models_dir, unit_str)\n",
    "predictions_name = \"_\".join([\"predictions\", clip_suppressor_str])\n",
    "predictions_dir = os.path.join(unit_dir, predictions_name)\n",
    "\n",
    "\n",
    "# Open annotation as Pandas DataFrame.\n",
    "annotations_name = \"_\".join([dataset_name, \"annotations\"])\n",
    "annotations_dir = os.path.join(data_dir, annotations_name)\n",
    "annotation_name = unit_str + \".txt\"\n",
    "annotation_path = os.path.join(annotations_dir, annotation_name)\n",
    "ann_df = pd.read_csv(annotation_path, delimiter=\"\\t\")\n",
    "\n",
    "\n",
    "# Restrict rows to negative labels.\n",
    "if \"Calls\" in ann_df.columns:\n",
    "    ann_df = ann_df.loc[~ann_df[\"Calls\"].isin(negative_labels)]\n",
    "\n",
    "\n",
    "# Restrict rows to frequency range of interest.\n",
    "if odf_str in [\"thrush\", \"tseep\"]:\n",
    "    oldbird_data_name = \"_\".join([dataset_name, \"oldbird\"])\n",
    "    oldbird_data_dir = os.path.join(data_dir, oldbird_data_name)\n",
    "    oldbird_data_path = os.path.join(oldbird_data_dir, unit_str + \".hdf5\")\n",
    "    oldbird_hdf5 = h5py.File(oldbird_data_path, \"r\")\n",
    "    settings_key = \"_\".join([odf_str, \"settings\"])\n",
    "    settings = oldbird_hdf5[settings_key]\n",
    "    filter_f0 = settings[\"filter_f0\"].value\n",
    "    filter_f1 = settings[\"filter_f1\"].value\n",
    "    ann_df = ann_df[\n",
    "        ((0.5*(ann_df[\"Low Freq (Hz)\"]+ann_df[\"High Freq (Hz)\"])) > filter_f0) &\n",
    "        ((0.5*(ann_df[\"Low Freq (Hz)\"]+ann_df[\"High Freq (Hz)\"])) < filter_f1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load middle times of true events.\n",
    "begin_times = np.array(ann_df[\"Begin Time (s)\"])\n",
    "end_times = np.array(ann_df[\"End Time (s)\"])\n",
    "relevant = 0.5 * (begin_times+end_times)\n",
    "n_relevant = len(relevant)\n",
    "\n",
    "\n",
    "# Prepare header for metrics.\n",
    "csv_header = [\n",
    "    \"Dataset\", \"Unit\", \"ODF\", \"Clip suppressor\", \"Tolerance\",\n",
    "    \"Threshold ID\", \"Relevant\", \"Selected\", \"True positives\",\n",
    "    \"False positives\", \"False negatives\", \"Precision\", \"Recall\", \"F1 Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-09 04:21:46.548750 Finish.\n",
      "Total elapsed time: 00:00:05.55.\n"
     ]
    }
   ],
   "source": [
    "# Loop over tolerances.\n",
    "for tolerance in tolerances:\n",
    "\n",
    "    # Create a CSV file for metrics.\n",
    "    tolerance_str = \"tol-\" + str(int(np.round(1000*tolerance)))\n",
    "    csv_file_name = \"_\".join([dataset_name, \"oldbird\", odf_str,\n",
    "        clip_suppressor_str, unit_str, tolerance_str, \"metrics.csv\"])\n",
    "    csv_file_path = os.path.join(unit_dir, csv_file_name)\n",
    "    csv_file = open(csv_file_path, 'w')\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "    csv_writer.writerow(csv_header)\n",
    "\n",
    "    # Loop over thresholds.\n",
    "    for threshold_id in range(n_thresholds):\n",
    "\n",
    "        # Load middle times of prediction.\n",
    "        threshold_str = \"th-\" + str(threshold_id).zfill(2)\n",
    "        prediction_name_components = [dataset_name, \"oldbird\", odf_str,\n",
    "            unit_str, threshold_str, \"predictions\"]\n",
    "        if clip_suppressor_str == \"clip-suppressor\":\n",
    "            prediction_name_components.append(clip_suppressor_str)\n",
    "        prediction_name = \"_\".join(prediction_name_components) + \".csv\"\n",
    "        prediction_path = os.path.join(predictions_dir, prediction_name)\n",
    "        prediction_df = pd.read_csv(prediction_path)\n",
    "        selected = prediction_df[\"Time (s)\"]\n",
    "\n",
    "        # Match selected events with relevant events using the mir_eval toolbox.\n",
    "        selected_relevant = mir_eval.util.match_events(\n",
    "            relevant, selected, tolerance)\n",
    "\n",
    "        # Define metrics.\n",
    "        true_positives = len(selected_relevant)\n",
    "        n_selected = len(selected)\n",
    "        false_positives = n_selected - true_positives\n",
    "        false_negatives = n_relevant - true_positives\n",
    "        if n_selected == 0 or true_positives == 0:\n",
    "            precision = 0.0\n",
    "            recall = 0.0\n",
    "            f1_score = 0.0\n",
    "        else:\n",
    "            precision = 100 * true_positives / n_selected\n",
    "            recall = 100 * true_positives / n_relevant\n",
    "            f1_score = 2*precision*recall / (precision+recall)\n",
    "\n",
    "        # Write row.\n",
    "        row = [\n",
    "            dataset_name,\n",
    "            unit_str,\n",
    "            clip_suppressor_str,\n",
    "            str(int(np.round(1000*tolerance))).rjust(4),\n",
    "            threshold_str,\n",
    "            str(n_relevant).rjust(5),\n",
    "            str(n_selected).rjust(6),\n",
    "            str(true_positives).rjust(5),\n",
    "            str(false_positives).rjust(5),\n",
    "            str(false_negatives).rjust(5),\n",
    "            format(precision, \".6f\"),\n",
    "            format(recall, \".6f\"),\n",
    "            format(f1_score, \".6f\")\n",
    "        ]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "# Close CSV file.\n",
    "csv_file.close()\n",
    "\n",
    "\n",
    "# Print elapsed time.\n",
    "print(str(datetime.datetime.now()) + \" Finish.\")\n",
    "elapsed_time = time.time() - int(start_time)\n",
    "elapsed_hours = int(elapsed_time / (60 * 60))\n",
    "elapsed_minutes = int((elapsed_time % (60 * 60)) / 60)\n",
    "elapsed_seconds = elapsed_time % 60.\n",
    "elapsed_str = \"{:>02}:{:>02}:{:>05.2f}\".format(elapsed_hours,\n",
    "                                               elapsed_minutes,\n",
    "                                               elapsed_seconds)\n",
    "print(\"Total elapsed time: \" + elapsed_str + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/vl1019/spl2017_models/oldbird/BirdVox-70k_oldbird_thrush_clip-suppressor_unit01_tol-100_metrics.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
