{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-26 01:11:54.238864 Start.\n",
      "Evaluating Salamon's ICASSP 2017 convnet for binary classification in BirdVox-70k clips. \n",
      "\n",
      "h5py version: 2.6.0\n",
      "numpy version: 1.13.1\n",
      "pandas version: 0.20.3\n",
      "scikit-learn version: 0.18.2\n",
      "\n",
      "2017-08-26 01:12:29.219592 Finish.\n",
      "Total elapsed time: 00:00:35.22.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "import localmodule\n",
    "\n",
    "\n",
    "args = [\"all\"]\n",
    "aug_kind_str = args[0]\n",
    "\n",
    "\n",
    "data_dir = localmodule.get_data_dir()\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "folds = localmodule.fold_units()\n",
    "models_dir = localmodule.get_models_dir()\n",
    "units = localmodule.get_units()\n",
    "model_name = \"icassp-convnet\"\n",
    "if not aug_kind_str == \"none\":\n",
    "    model_name = \"_\".join(\n",
    "        [model_name, \"aug-\" + aug_kind_str])\n",
    "model_dir = os.path.join(models_dir, model_name)\n",
    "\n",
    "\n",
    "# Print header.\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "print(\"Evaluating Salamon's ICASSP 2017 convnet for binary classification in \" +\n",
    "    dataset_name + \" clips. \")\n",
    "print(\"\")\n",
    "print('h5py version: {:s}'.format(h5py.__version__))\n",
    "print('numpy version: {:s}'.format(np.__version__))\n",
    "print('pandas version: {:s}'.format(pd.__version__))\n",
    "print('scikit-learn version: {:s}'.format(sklearn.__version__))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Loop over recording units.\n",
    "for test_unit_str in units:\n",
    "\n",
    "    # Define directory for test unit.\n",
    "    unit_dir = os.path.join(model_dir, test_unit_str)\n",
    "    \n",
    "    # Create CSV file for metrics.\n",
    "    metrics_name = \"_\".join([\n",
    "        dataset_name,\n",
    "        model_name,\n",
    "        test_unit_str,\n",
    "        \"clip-metrics\"\n",
    "    ])\n",
    "    metrics_path = os.path.join(unit_dir, metrics_name + \".csv\")\n",
    "    csv_file = open(metrics_path, 'w')\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "    \n",
    "    # Write CSV header.\n",
    "    csv_header = [\n",
    "    \"Dataset\",\n",
    "    \"Augmentation kind\",\n",
    "    \"Test unit\",\n",
    "    \"Trial\",\n",
    "    \"Ad hoc threshold\",\n",
    "    \"Ad hoc validation TP\",\n",
    "    \"Ad hoc validation FP\",\n",
    "    \"Ad hoc validation TN\",\n",
    "    \"Ad hoc validation FN\",\n",
    "    \"Ad hoc validation accuracy (%)\",\n",
    "    \"Ad hoc test TP\",\n",
    "    \"Ad hoc test FP\",\n",
    "    \"Ad hoc test TN\",\n",
    "    \"Ad hoc test FN\",\n",
    "    \"Ad hoc test accuracy (%)\",\n",
    "    \"Cross-validated threshold\",\n",
    "    \"Cross-validated validation TP\",\n",
    "    \"Cross-validated validation FP\",\n",
    "    \"Cross-validated validation TN\",\n",
    "    \"Cross-validated validation FN\",\n",
    "    \"Cross-validated validation accuracy (%)\",\n",
    "    \"Cross-validated test TP\",\n",
    "    \"Cross-validated test FP\",\n",
    "    \"Cross-validated test TN\",\n",
    "    \"Cross-validated test FN\",\n",
    "    \"Oracle threshold\",\n",
    "    \"Test oracle TP\",\n",
    "    \"Test oracle FP\",\n",
    "    \"Test oracle TN\",\n",
    "    \"Test oracle FN\",\n",
    "    \"Test oracle accuracy (%)\",\n",
    "    \"Validation AUC\",\n",
    "    \"Test AUC\"]\n",
    "    csv_writer.writerow(csv_header)\n",
    "\n",
    "    # Loop over trials.\n",
    "    for trial_id in range(10): # TODO UPDATE ME\n",
    "        # Define directory for trial.\n",
    "        trial_str = \"trial-\" + str(trial_id)\n",
    "        trial_dir = os.path.join(unit_dir, trial_str)\n",
    "\n",
    "        # Fold units.\n",
    "        fold = [f for f in folds if test_unit_str in f[0]][0]\n",
    "        validation_units = fold[2]\n",
    "\n",
    "        # Load prediction for validation set as Pandas DataFrame.\n",
    "        val_df_list = []\n",
    "        for val_unit_str in validation_units:\n",
    "            val_pred_name = \"_\".join([\n",
    "                dataset_name,\n",
    "                model_name,\n",
    "                \"test-\" + test_unit_str,\n",
    "                trial_str,\n",
    "                \"predict-\" + val_unit_str,\n",
    "                \"clip-predictions.csv\"])\n",
    "            val_pred_path = os.path.join(trial_dir, val_pred_name)\n",
    "            val_df = pd.read_csv(val_pred_path)\n",
    "            val_df_list.append(val_df)\n",
    "        val_df = pd.concat(val_df_list, ignore_index=True)\n",
    "        val_y_true = list(val_df[\"Ground truth\"])\n",
    "        val_y_score = list(val_df[\"Predicted probability\"])\n",
    "\n",
    "        # Get ROC curve of validation set.\n",
    "        val_fprs, val_tprs, val_thresholds =\\\n",
    "            sklearn.metrics.roc_curve(val_y_true, val_y_score)\n",
    "\n",
    "        # Compute accuracies.\n",
    "        #     ACC = (TN + TP) / (NEG + POS)\n",
    "        # The dataset is balanced (NEG = POS) so\n",
    "        #     ACC = 0.5 * (TN/NEG + TP/POS)\n",
    "        # We have NEG = FP + TN so\n",
    "        #     ACC = 0.5 * ((NEG-FP)/NEG + TP/POS)\n",
    "        # We have FPR = FP/NEG and TPR = TP/POS so\n",
    "        #     ACC = 0.5 * (1.0 - FPR + TPR)\n",
    "        val_accuracies = 0.5 * (1.0 - val_fprs + val_tprs)\n",
    "\n",
    "        # Find threshold that maximizes validation accuracy.\n",
    "        cv_best_threshold_id = np.argmax(val_accuracies)\n",
    "        cv_threshold = val_thresholds[cv_best_threshold_id]\n",
    "\n",
    "        # Compute confusion matrix on validation set with optimal threshold.\n",
    "        val_cv_y_pred = np.greater(val_y_score, cv_threshold)\n",
    "        val_cv_cm = sklearn.metrics.confusion_matrix(\n",
    "            val_y_true, val_cv_y_pred)\n",
    "        val_cv_tp = val_cv_cm[0][0]\n",
    "        val_cv_fp = val_cv_cm[0][1]\n",
    "        val_cv_fn = val_cv_cm[1][0]\n",
    "        val_cv_tn = val_cv_cm[1][1]\n",
    "\n",
    "        # Compute validation accuracy with optimal threshold.\n",
    "        val_tnr = 1.0 - val_fprs[cv_best_threshold_id]\n",
    "        val_tpr = val_tprs[cv_best_threshold_id]\n",
    "        val_cv_acc = val_accuracies[cv_best_threshold_id]\n",
    "\n",
    "        # Compute confusion matrix on validation set with ad hoc threshold.\n",
    "        val_adhoc_y_pred = np.greater(val_y_score, 0.5)\n",
    "        val_adhoc_cm = sklearn.metrics.confusion_matrix(\n",
    "            val_y_true, val_adhoc_y_pred)\n",
    "        val_adhoc_tp = val_adhoc_cm[0][0]\n",
    "        val_adhoc_fp = val_adhoc_cm[0][1]\n",
    "        val_adhoc_fn = val_adhoc_cm[1][0]\n",
    "        val_adhoc_tn = val_adhoc_cm[1][1]\n",
    "\n",
    "        # Compute validation acuracy with ad hoc threshold.\n",
    "        val_adhoc_acc =\\\n",
    "            (val_adhoc_tn+val_adhoc_tp) /\\\n",
    "            (val_adhoc_tn+val_adhoc_tp+val_adhoc_fn+val_adhoc_fp)\n",
    "\n",
    "        # Compute area under ROC curve on validation set.\n",
    "        val_auc = sklearn.metrics.roc_auc_score(\n",
    "            val_y_true, val_y_score)\n",
    "\n",
    "        # Load predictions for test set as Pandas Dataframe.\n",
    "        test_pred_name = \"_\".join([\n",
    "            dataset_name,\n",
    "            model_name,\n",
    "            \"test-\" + test_unit_str,\n",
    "            trial_str,\n",
    "            \"predict-\" + test_unit_str,\n",
    "            \"clip-predictions.csv\"])\n",
    "        test_pred_path = os.path.join(trial_dir, test_pred_name)\n",
    "        test_df = pd.read_csv(test_pred_path)\n",
    "        test_y_true = list(test_df[\"Ground truth\"])\n",
    "        test_y_score = list(test_df[\"Predicted probability\"])\n",
    "\n",
    "        # Compute confusion matrix on test set with cross-validated threshold.\n",
    "        test_cv_y_pred = np.greater(test_y_score, cv_threshold)\n",
    "        test_cv_cm = sklearn.metrics.confusion_matrix(\n",
    "            test_y_true, test_cv_y_pred)\n",
    "        test_cv_tp = test_cv_cm[0][0]\n",
    "        test_cv_fp = test_cv_cm[0][1]\n",
    "        test_cv_fn = test_cv_cm[1][0]\n",
    "        test_cv_tn = test_cv_cm[1][1]\n",
    "\n",
    "        # Compute test accuracy with cross-validated threshold.\n",
    "        test_cv_acc =\\\n",
    "            (test_cv_tn+test_cv_tp) /\\\n",
    "            (test_cv_tn+test_cv_tp+test_cv_fn+test_cv_fp)\n",
    "\n",
    "        # Compute confusion matrix on test set with ad hoc threshold.\n",
    "        test_adhoc_y_pred = np.greater(test_y_score, 0.5)\n",
    "        test_adhoc_cm = sklearn.metrics.confusion_matrix(\n",
    "            test_y_true, test_adhoc_y_pred)\n",
    "        test_adhoc_tp = test_adhoc_cm[0][0]\n",
    "        test_adhoc_fp = test_adhoc_cm[0][1]\n",
    "        test_adhoc_fn = test_adhoc_cm[1][0]\n",
    "        test_adhoc_tn = test_adhoc_cm[1][1]\n",
    "\n",
    "        # Compute test accuracy with ad hoc threshold.\n",
    "        test_adhoc_acc =\\\n",
    "            (test_adhoc_tn+test_adhoc_tp) /\\\n",
    "            (test_adhoc_tn+test_adhoc_tp+test_adhoc_fn+test_adhoc_fp)\n",
    "\n",
    "        # Get ROC curve of test set.\n",
    "        test_fprs, test_tprs, test_thresholds =\\\n",
    "            sklearn.metrics.roc_curve(test_y_true, test_y_score)\n",
    "        test_accuracies = 0.5 * (1.0 - test_fprs + test_tprs)\n",
    "\n",
    "        # Find \"oracle\" threshold maximizing test accuracy.\n",
    "        oracle_best_threshold_id = np.argmax(test_accuracies)\n",
    "        oracle_threshold = test_thresholds[oracle_best_threshold_id]\n",
    "        test_oracle_y_pred = np.greater(test_y_score, oracle_threshold)\n",
    "\n",
    "        # Compute confusion matrix on test set with oracle threshold.\n",
    "        test_oracle_cm = sklearn.metrics.confusion_matrix(\n",
    "            test_y_true, test_oracle_y_pred)\n",
    "        test_oracle_tp = test_oracle_cm[0][0]\n",
    "        test_oracle_fp = test_oracle_cm[0][1]\n",
    "        test_oracle_fn = test_oracle_cm[1][0]\n",
    "        test_oracle_tn = test_oracle_cm[1][1]\n",
    "\n",
    "        # Compute test accuracy with oracle threshold.\n",
    "        test_oracle_acc =\\\n",
    "            (test_oracle_tn+test_oracle_tp) /\\\n",
    "            (test_oracle_tn+test_oracle_tp+test_oracle_fn+test_oracle_fp)\n",
    "\n",
    "        # Compute area under ROC curve for test set.\n",
    "        test_auc = sklearn.metrics.roc_auc_score(test_y_true, test_y_score)\n",
    "\n",
    "        # Format all metrics into a string of comma-separated values.\n",
    "        row = [\n",
    "            dataset_name,\n",
    "            aug_kind_str.rjust(7),\n",
    "            test_unit_str,\n",
    "            trial_str,\n",
    "            \"{:.16f}\".format(0.5),\n",
    "            \"{:5d}\".format(val_adhoc_tp),\n",
    "            \"{:5d}\".format(val_adhoc_fp),\n",
    "            \"{:5d}\".format(val_adhoc_tn),\n",
    "            \"{:5d}\".format(val_adhoc_fn),\n",
    "            \"{:7.3f}\".format(val_adhoc_acc*100),\n",
    "            \"{:5d}\".format(test_adhoc_tp),\n",
    "            \"{:5d}\".format(test_adhoc_fp),\n",
    "            \"{:5d}\".format(test_adhoc_tn),\n",
    "            \"{:5d}\".format(test_adhoc_fn),\n",
    "            \"{:7.3f}\".format(test_adhoc_acc*100),\n",
    "            \"{:.16f}\".format(cv_threshold),\n",
    "            \"{:5d}\".format(val_cv_tp),\n",
    "            \"{:5d}\".format(val_cv_fp),\n",
    "            \"{:5d}\".format(val_cv_tn),\n",
    "            \"{:5d}\".format(val_cv_fn),\n",
    "            \"{:7.3f}\".format(val_cv_acc*100),\n",
    "            \"{:5d}\".format(test_cv_tp),\n",
    "            \"{:5d}\".format(test_cv_fp),\n",
    "            \"{:5d}\".format(test_cv_tn),\n",
    "            \"{:5d}\".format(test_cv_fn),\n",
    "            \"{:.16f}\".format(oracle_threshold),\n",
    "            \"{:5d}\".format(test_oracle_tp),\n",
    "            \"{:5d}\".format(test_oracle_fp),\n",
    "            \"{:5d}\".format(test_oracle_tn),\n",
    "            \"{:5d}\".format(test_oracle_fn),\n",
    "            \"{:7.3f}\".format(test_oracle_acc*100),\n",
    "            \"{:7.3f}\".format(val_auc*100),\n",
    "            \"{:7.3f}\".format(test_auc*100)\n",
    "            ]\n",
    "\n",
    "        # Write row to CSV file.\n",
    "        csv_writer.writerow(row)\n",
    "        \n",
    "    # Close CSV file.\n",
    "    csv_file.close()\n",
    "    \n",
    "\n",
    "# Print elapsed time.\n",
    "print(str(datetime.datetime.now()) + \" Finish.\")\n",
    "elapsed_time = time.time() - int(start_time)\n",
    "elapsed_hours = int(elapsed_time / (60 * 60))\n",
    "elapsed_minutes = int((elapsed_time % (60 * 60)) / 60)\n",
    "elapsed_seconds = elapsed_time % 60.\n",
    "elapsed_str = \"{:>02}:{:>02}:{:>05.2f}\".format(elapsed_hours,\n",
    "                                               elapsed_minutes,\n",
    "                                               elapsed_seconds)\n",
    "print(\"Total elapsed time: \" + elapsed_str + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
