{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-25 09:41:26.448167 Start.\n",
      "Using Salamon's ICASSP 2017 convnet for binary classigification in BirdVox-70k. \n",
      "Training set: unit02, unit03, unit05.\n",
      "Validation set: unit07, unit10.\n",
      "Test set: unit01.\n",
      "\n",
      "h5py version: 2.6.0\n",
      "keras version: 2.0.6\n",
      "numpy version: 1.13.1\n",
      "tensorflow version: 1.2.1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import h5py\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "import localmodule\n",
    "\n",
    "\n",
    "# Define constants.\n",
    "data_dir = localmodule.get_data_dir()\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "folds = localmodule.fold_units()\n",
    "models_dir = localmodule.get_models_dir()\n",
    "n_input_hops = 104\n",
    "\n",
    "\n",
    "# Read command-line arguments.\n",
    "args = [\"none\", \"unit01\", \"trial-0\", \"unit01\"]\n",
    "aug_kind_str = args[0]\n",
    "test_unit_str = args[1]\n",
    "trial_str = args[2]\n",
    "predict_unit_str = args[3]\n",
    "\n",
    "\n",
    "# Retrieve fold such that unit_str is in the test set.\n",
    "fold = [f for f in folds if test_unit_str in f[0]][0]\n",
    "test_units = fold[0]\n",
    "training_units = fold[1]\n",
    "validation_units = fold[2]\n",
    "\n",
    "\n",
    "# Print header.\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "print(\"Using Salamon's ICASSP 2017 convnet for binary classigification in \" +\n",
    "    dataset_name + \". \")\n",
    "print(\"Training set: \" + \", \".join(training_units) + \".\")\n",
    "print(\"Validation set: \" + \", \".join(validation_units) + \".\")\n",
    "print(\"Test set: \" + \", \".join(test_units) + \".\")\n",
    "print(\"\")\n",
    "print('h5py version: {:s}'.format(h5py.__version__))\n",
    "print('keras version: {:s}'.format(keras.__version__))\n",
    "print('numpy version: {:s}'.format(np.__version__))\n",
    "print('tensorflow version: {:s}'.format(tf.__version__))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Load model.\n",
    "model_name = \"icassp-convnet\"\n",
    "if not aug_kind_str == \"none\":\n",
    "    model_name = \"_\".join([model_name, \"aug-\" + aug_kind_str])\n",
    "model_dir = os.path.join(models_dir, model_name)\n",
    "unit_dir = os.path.join(model_dir, test_unit_str)\n",
    "trial_dir = os.path.join(unit_dir, trial_str)\n",
    "network_name = \"_\".join(\n",
    "    [dataset_name, model_name, test_unit_str, trial_str, \"network\"])\n",
    "network_path = os.path.join(trial_dir, network_name + \".hdf5\")\n",
    "model = keras.models.load_model(network_path)\n",
    "\n",
    "\n",
    "# Open logmelspec container with h5py.\n",
    "aug_str = \"original\"\n",
    "logmelspec_dir = os.path.join(data_dir,\n",
    "    \"_\".join([dataset_name, \"logmelspec\"]))\n",
    "original_logmelspec_dir = os.path.join(logmelspec_dir, aug_str)\n",
    "hdf5_name = \"_\".join([dataset_name, aug_str, predict_unit_str])\n",
    "hdf5_path = os.path.join(original_logmelspec_dir, hdf5_name + \".hdf5\")\n",
    "lms_container = h5py.File(hdf5_path, \"r\")\n",
    "lms_group = lms_container[\"logmelspec\"]\n",
    "\n",
    "\n",
    "# Create HDF5 container for predictions.\n",
    "clip_predictions_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    model_name,\n",
    "    \"test-\" + test_unit_str,\n",
    "    \"predict-\" + predict_unit_str,\n",
    "    \"clip-predictions\"\n",
    "])\n",
    "\n",
    "\n",
    "# List keys.\n",
    "keys = sorted(list(lms_group.keys()))\n",
    "\n",
    "\n",
    "# Create CSV file.\n",
    "prediction_name = \"_\".join([dataset_name, model_name,\n",
    "    \"test-\" + test_unit_str, trial_str, \"predict-\" + predict_unit_str,\n",
    "    \"clip-predictions\"])\n",
    "prediction_path = os.path.join(trial_dir, prediction_name + \".csv\")\n",
    "csv_file = open(prediction_path, 'w')\n",
    "csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "                            \n",
    "\n",
    "# Create CSV header.\n",
    "csv_header = [\"Dataset\", \"Test unit\", \"Prediction unit\", \"Timestamp\",\n",
    "    \"Center frequency (Hz)\", \"Augmentation\", \"Key\", \"Ground truth\",\n",
    "    \"Predicted probability\"]\n",
    "csv_writer.writerow(csv_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop over keys.\n",
    "for key in keys:\n",
    "    # Load logmelspec.\n",
    "    X = lms_group[key]\n",
    "\n",
    "    # Trim logmelspec in time to required number of hops.\n",
    "    X_width = X.shape[1]\n",
    "    first_col = int((X_width-n_input_hops) / 2)\n",
    "    last_col = int((X_width+n_input_hops) / 2)\n",
    "    X = X[:, first_col:last_col]\n",
    "\n",
    "    # Add trailing singleton dimension for Keras interoperability.\n",
    "    X = X[np.newaxis, :, :, np.newaxis]\n",
    "\n",
    "    # Predict.\n",
    "    predicted_probability = model.predict(X)[0, 0]\n",
    "\n",
    "    # Store prediction as DataFrame row.\n",
    "    key_split = key.split(\"_\")\n",
    "    timestamp_str = key_split[1]\n",
    "    freq_str = key_split[2]\n",
    "    ground_truth_str = key_split[3]\n",
    "    aug_str = key_split[4]\n",
    "    predicted_probability_str = \"{:.16f}\".format(predicted_probability)\n",
    "    row = [dataset_name, test_unit_str, predict_unit_str, timestamp_str,\n",
    "         freq_str, aug_str, key, ground_truth_str, predicted_probability_str]\n",
    "    csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-25 09:43:31.324736 Finish.\n",
      "Total elapsed time: 00:02:05.33.\n"
     ]
    }
   ],
   "source": [
    "# Close HDF5 containers.\n",
    "lms_container.close()\n",
    "\n",
    "\n",
    "# Close CSV file.\n",
    "csv_file.close()\n",
    "\n",
    "\n",
    "# Print elapsed time.\n",
    "print(str(datetime.datetime.now()) + \" Finish.\")\n",
    "elapsed_time = time.time() - int(start_time)\n",
    "elapsed_hours = int(elapsed_time / (60 * 60))\n",
    "elapsed_minutes = int((elapsed_time % (60 * 60)) / 60)\n",
    "elapsed_seconds = elapsed_time % 60.\n",
    "elapsed_str = \"{:>02}:{:>02}:{:>05.2f}\".format(elapsed_hours,\n",
    "                                               elapsed_minutes,\n",
    "                                               elapsed_seconds)\n",
    "print(\"Total elapsed time: \" + elapsed_str + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/vl1019/spl2017_models/icassp-convnet/unit01/trial-0/BirdVox-70k_icassp-convnet_test-unit01_trial-0_predict-unit01_clip-predictions.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
