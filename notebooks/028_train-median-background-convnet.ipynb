{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-22 18:09:01.318225 Start.\n",
      "Training Salamon's ICASSP 2017 convnet on BirdVox-70k. \n",
      "Training set: unit02, unit03, unit05.\n",
      "Validation set: unit07, unit10.\n",
      "Test set: unit01.\n",
      "\n",
      "h5py version: 2.6.0\n",
      "keras version: 2.0.6\n",
      "numpy version: 1.13.1\n",
      "pandas version: 0.20.3\n",
      "pescador version: 1.0.0\n",
      "tensorflow version: 1.2.1\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "spec_input (InputLayer)          (None, 128, 104, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "spec_bn1 (BatchNormalization)    (None, 128, 104, 1)   4           spec_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "spec_conv1 (Conv2D)              (None, 128, 104, 24)  624         spec_bn1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "spec_pool1 (MaxPooling2D)        (None, 64, 26, 24)    0           spec_conv1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "spec_conv2 (Conv2D)              (None, 64, 26, 48)    28848       spec_pool1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "spec_pool2 (MaxPooling2D)        (None, 32, 6, 48)     0           spec_conv2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "spec_conv3 (Conv2D)              (None, 32, 6, 48)     57648       spec_pool2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "bg_input (InputLayer)            (None, 128, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "spec_flatten (Flatten)           (None, 9216)          0           spec_conv3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "bg_pool1 (AveragePooling1D)      (None, 32, 1)         0           bg_input[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "spec_dense1 (Dense)              (None, 64)            589888      spec_flatten[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bg_flatten1 (Flatten)            (None, 32)            0           bg_pool1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "reshape_49 (Reshape)             (None, 16, 4)         0           spec_dense1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "bg_dense1 (Dense)                (None, 32)            1056        bg_flatten1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)             (None, 64)            0           reshape_49[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "bg_dense2 (Dense)                (None, 64)            2112        bg_dense1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "multiply_60 (Multiply)           (None, 64)            0           flatten_47[0][0]                 \n",
      "                                                                   bg_dense2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_63 (Dense)                 (None, 1)             65          multiply_60[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 680,245\n",
      "Trainable params: 680,243\n",
      "Non-trainable params: 2\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import h5py\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pescador\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import localmodule\n",
    "\n",
    "# Define constants.\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "folds = localmodule.fold_units()\n",
    "models_dir = localmodule.get_models_dir()\n",
    "n_input_hops = 104\n",
    "n_filters = [24, 48, 48]\n",
    "kernel_size = [5, 5]\n",
    "pool_size = [2, 4]\n",
    "n_hidden_units = 64\n",
    "steps_per_epoch = 256\n",
    "epochs = 32\n",
    "validation_steps = 256\n",
    "batch_size = 32\n",
    "n_context_classes = 4\n",
    "\n",
    "\n",
    "# Read command-line arguments.\n",
    "args = [\"3600\", \"unit01\"]\n",
    "aug_kind_str = \"original\"\n",
    "bg_duration = int(args[0])\n",
    "unit_str = args[1]\n",
    "\n",
    "\n",
    "# Retrieve fold such that unit_str is in the test set.\n",
    "fold = [f for f in folds if unit_str in f[0]][0]\n",
    "test_units = fold[0]\n",
    "training_units = fold[1]\n",
    "validation_units = fold[2]\n",
    "\n",
    "\n",
    "# Print header.\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "print(\"Training Salamon's ICASSP 2017 convnet on \" + dataset_name + \". \")\n",
    "print(\"Training set: \" + \", \".join(training_units) + \".\")\n",
    "print(\"Validation set: \" + \", \".join(validation_units) + \".\")\n",
    "print(\"Test set: \" + \", \".join(test_units) + \".\")\n",
    "print(\"\")\n",
    "print('h5py version: {:s}'.format(h5py.__version__))\n",
    "print('keras version: {:s}'.format(keras.__version__))\n",
    "print('numpy version: {:s}'.format(np.__version__))\n",
    "print('pandas version: {:s}'.format(pd.__version__))\n",
    "print('pescador version: {:s}'.format(pescador.__version__))\n",
    "print('tensorflow version: {:s}'.format(tf.__version__))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Define and compile Keras model.\n",
    "# NB: the original implementation of Justin Salamon in ICASSP 2017 relies on\n",
    "# glorot_uniform initialization for all layers, and the optimizer is a\n",
    "# stochastic gradient descent (SGD) with a fixed learning rate of 0.1.\n",
    "# Instead, we use a he_normal initialization for the layers followed\n",
    "# by rectified linear units (see He ICCV 2015), and replace the SGD by\n",
    "# the Adam adaptive stochastic optimizer (see Kingma ICLR 2014).\n",
    "# Moreover, we disable dropout because we found that it consistently prevented\n",
    "# the model to train at all.\n",
    "\n",
    "# Main channel.\n",
    "# Input\n",
    "spec_input = keras.layers.Input(\n",
    "    shape=(128, n_input_hops, 1), name=\"spec_input\")\n",
    "\n",
    "# Layer 1\n",
    "spec_bn1 = keras.layers.normalization.BatchNormalization(\n",
    "    name=\"spec_bn1\")(spec_input)\n",
    "spec_conv1 = keras.layers.Convolution2D(n_filters[0], kernel_size,\n",
    "    padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "    name=\"spec_conv1\")(spec_bn1)\n",
    "spec_pool1 = keras.layers.MaxPooling2D(\n",
    "    pool_size=pool_size, name=\"spec_pool1\")(spec_conv1)\n",
    "\n",
    "# Layer 2\n",
    "spec_conv2 = keras.layers.Convolution2D(n_filters[1], kernel_size,\n",
    "    padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "    activation=\"relu\", name=\"spec_conv2\")(spec_pool1)\n",
    "spec_pool2 = keras.layers.MaxPooling2D(\n",
    "    pool_size=pool_size, name=\"spec_pool2\")(spec_conv2)\n",
    "\n",
    "# Layer 3\n",
    "spec_conv3 = keras.layers.Convolution2D(n_filters[2], kernel_size,\n",
    "    padding=\"same\", kernel_initializer=\"he_normal\",\n",
    "    activation=\"relu\", name=\"spec_conv3\")(spec_pool2)\n",
    "\n",
    "# Layer 4\n",
    "spec_flatten1 = keras.layers.Flatten(\n",
    "    name=\"spec_flatten\")(spec_conv3)\n",
    "spec_dense1 = keras.layers.Dense(n_hidden_units,\n",
    "    kernel_initializer=\"he_normal\", activation=\"relu\",\n",
    "    kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "    name=\"spec_dense1\")(spec_flatten1)\n",
    "\n",
    "# Reshape.\n",
    "spec_shape = (-1, 4)\n",
    "spec_reshape = keras.layers.Reshape(spec_shape)(spec_dense1)\n",
    "spec_flatten2 = keras.layers.Flatten()(spec_reshape)\n",
    "\n",
    "\n",
    "# Side channel.\n",
    "# Input\n",
    "bg_input = keras.layers.Input(\n",
    "    shape=(128, 1), name=\"bg_input\")\n",
    "\n",
    "# Pool\n",
    "bg_pool1 = keras.layers.AveragePooling1D(\n",
    "    pool_size=4, name=\"bg_pool1\")(bg_input)\n",
    "\n",
    "# Flatten\n",
    "bg_flatten = keras.layers.Flatten(\n",
    "    name=\"bg_flatten1\")(bg_pool1)\n",
    "\n",
    "# Layer 1\n",
    "bg_dense1 = keras.layers.Dense(32,\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    activation=\"relu\", name=\"bg_dense1\")(bg_flatten)\n",
    "\n",
    "# Layer 2\n",
    "bg_dense2 = keras.layers.Dense(64,\n",
    "    kernel_initializer=\"he_normal\",\n",
    "    activation=\"relu\", name=\"bg_dense2\")(bg_dense1)\n",
    "\n",
    "\n",
    "# Element-wise multiplication\n",
    "multiply = keras.layers.Multiply()([spec_flatten2, bg_dense2])\n",
    "\n",
    "\n",
    "# Layer 5\n",
    "# We put a single output instead of 43 in the original paper, because this\n",
    "# is binary classification instead of multilabel classification.\n",
    "# Furthermore, this layer contains 43 times less connections than in the\n",
    "# original paper, so we divide the l2 weight penalization by 50, which is\n",
    "# of the same order of magnitude as 43.\n",
    "# 0.001 / 50 = 0.00002\n",
    "dense2 = keras.layers.Dense(1,\n",
    "    kernel_initializer=\"normal\", activation=\"sigmoid\",\n",
    "    kernel_regularizer=keras.regularizers.l2(0.00002))(multiply)\n",
    "\n",
    "\n",
    "\n",
    "# Compile model, print model summary.\n",
    "inputs = [spec_input, bg_input]\n",
    "model = keras.models.Model(inputs=inputs, outputs=dense2)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        output_shape = self.compute_output_shape(input_shape)\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(1,) + output_shape[1:],\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "\n",
    "\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        return K.tf.multiply(x, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],self.output_dim)+input_shape[1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
