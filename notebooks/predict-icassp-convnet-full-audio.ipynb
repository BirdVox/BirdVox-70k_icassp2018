{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-28 16:12:00.833433 Start.\n",
      "Using Salamon's ICASSP 2017 convnet for binary classification in BirdVox-70k, full audio. \n",
      "Training set: unit02, unit03, unit05.\n",
      "Validation set: unit07, unit10.\n",
      "Test set: unit01.\n",
      "\n",
      "h5py version: 2.6.0\n",
      "keras version: 2.0.6\n",
      "numpy version: 1.13.1\n",
      "tensorflow version: 1.2.1\n",
      "\n",
      "2017-08-28 16:12:05.527136 Finish.\n",
      "Total elapsed time: 00:00:05.53.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import h5py\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "import localmodule\n",
    "\n",
    "\n",
    "# Define constants.\n",
    "data_dir = localmodule.get_data_dir()\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "folds = localmodule.fold_units()\n",
    "models_dir = localmodule.get_models_dir()\n",
    "model_name = \"icassp-convnet\"\n",
    "if not aug_kind_str == \"none\":\n",
    "    model_name = \"_\".join([model_name, \"aug-\" + aug_kind_str])\n",
    "clip_length = 104\n",
    "hop_length = int(np.round(clip_length / 2))\n",
    "hop_duration = hop_length * 32 / 22050\n",
    "\n",
    "\n",
    "# Read command-line arguments.\n",
    "args = [\"none\", \"unit01\", \"trial-0\", \"unit01\"]\n",
    "aug_kind_str = args[0]\n",
    "test_unit_str = args[1]\n",
    "trial_str = args[2]\n",
    "predict_unit_str = args[3]\n",
    "\n",
    "\n",
    "# Retrieve fold such that unit_str is in the test set.\n",
    "fold = [f for f in folds if test_unit_str in f[0]][0]\n",
    "test_units = fold[0]\n",
    "training_units = fold[1]\n",
    "validation_units = fold[2]\n",
    "\n",
    "\n",
    "# Print header.\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "print(\"Using Salamon's ICASSP 2017 convnet for binary classification in \" +\n",
    "    dataset_name + \", full audio. \")\n",
    "print(\"Training set: \" + \", \".join(training_units) + \".\")\n",
    "print(\"Validation set: \" + \", \".join(validation_units) + \".\")\n",
    "print(\"Test set: \" + \", \".join(test_units) + \".\")\n",
    "print(\"\")\n",
    "print('h5py version: {:s}'.format(h5py.__version__))\n",
    "print('keras version: {:s}'.format(keras.__version__))\n",
    "print('numpy version: {:s}'.format(np.__version__))\n",
    "print('tensorflow version: {:s}'.format(tf.__version__))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Load model.\n",
    "model_name = \"icassp-convnet\"\n",
    "if not aug_kind_str == \"none\":\n",
    "    model_name = \"_\".join([model_name, \"aug-\" + aug_kind_str])\n",
    "model_dir = os.path.join(models_dir, model_name)\n",
    "unit_dir = os.path.join(model_dir, test_unit_str)\n",
    "trial_dir = os.path.join(unit_dir, trial_str)\n",
    "network_name = \"_\".join(\n",
    "    [dataset_name, model_name, test_unit_str, trial_str, \"network\"])\n",
    "network_path = os.path.join(trial_dir, network_name + \".hdf5\")\n",
    "model = keras.models.load_model(network_path)\n",
    "\n",
    "\n",
    "# Open logmelspec container with h5py.\n",
    "logmelspec_dir = os.path.join(data_dir, \"_\".join(\n",
    "    [dataset_name, \"full-logmelspec\"]))\n",
    "hdf5_path = os.path.join(logmelspec_dir, predict_unit_str + \".hdf5\")\n",
    "lms_container = h5py.File(hdf5_path, \"r\")\n",
    "lms_group = lms_container[\"logmelspec\"]\n",
    "\n",
    "\n",
    "# Create HDF5 container for predictions.\n",
    "clip_predictions_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    model_name,\n",
    "    \"test-\" + test_unit_str,\n",
    "    \"predict-\" + predict_unit_str,\n",
    "    \"full-audio-predictions\"\n",
    "])\n",
    "\n",
    "\n",
    "# Create CSV file.\n",
    "prediction_name = \"_\".join([dataset_name, model_name,\n",
    "    \"test-\" + test_unit_str, trial_str, \"predict-\" + predict_unit_str,\n",
    "    \"full-predictions\"])\n",
    "prediction_path = os.path.join(trial_dir, prediction_name + \".csv\")\n",
    "csv_file = open(prediction_path, 'w')\n",
    "csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "\n",
    "\n",
    "# Create CSV header.\n",
    "csv_header = [\"Dataset\", \"Model\", \"Test unit\", \"Prediction unit\", \"Timestamp\",\n",
    "    \"Predicted probability\"]\n",
    "csv_writer.writerow(csv_header)\n",
    "\n",
    "\n",
    "# Compute number of hops.\n",
    "n_hops = int(lms_group.shape[1] / hop_length) - 1\n",
    "\n",
    "\n",
    "# Loop over hops.\n",
    "for hop_id in range(n_hops)[:100]:\n",
    "\n",
    "    # Load clip in full logmelspec data.\n",
    "    clip_start = hop_id * hop_length\n",
    "    clip_stop = clip_start + clip_length\n",
    "    X = lms_group[:, clip_start:clip_stop]\n",
    "\n",
    "    # Add leading and trailing singleton dimension for Keras interoperability.\n",
    "    X = X[np.newaxis, :, :, np.newaxis]\n",
    "\n",
    "    # Predict.\n",
    "    predicted_probability = model.predict(X)[0,0]\n",
    "\n",
    "    # Store prediction as DataFrame row.\n",
    "    timestamp = (hop_id+1) * hop_duration\n",
    "    timestamp_str = \"{:9.3f}\".format(timestamp)\n",
    "    predicted_probability_str = \"{:.16f}\".format(predicted_probability)\n",
    "    row = [dataset_name, model_name, test_unit_str, predict_unit_str,\n",
    "           timestamp_str, predicted_probability_str]\n",
    "    csv_writer.writerow(row)\n",
    "    \n",
    "\n",
    "# Close CSV file.\n",
    "csv_file.close()\n",
    "\n",
    "\n",
    "# Print elapsed time.\n",
    "print(str(datetime.datetime.now()) + \" Finish.\")\n",
    "elapsed_time = time.time() - int(start_time)\n",
    "elapsed_hours = int(elapsed_time / (60 * 60))\n",
    "elapsed_minutes = int((elapsed_time % (60 * 60)) / 60)\n",
    "elapsed_seconds = elapsed_time % 60.\n",
    "elapsed_str = \"{:>02}:{:>02}:{:>05.2f}\".format(elapsed_hours,\n",
    "                                               elapsed_minutes,\n",
    "                                               elapsed_seconds)\n",
    "print(\"Total elapsed time: \" + elapsed_str + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3636363636363635"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
