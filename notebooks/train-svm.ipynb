{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-21 23:01:38.528896 Start.\n",
      "Training SVM for BirdVox-70k clips.\n",
      "Test Unit: unit01.\n",
      "Trial ID: 0.\n",
      "\n",
      "h5py version: 2.6.0\n",
      "librosa version: 0.5.1\n",
      "numpy version: 1.13.1\n",
      "skm version: 0.0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import h5py\n",
    "from sklearn.externals import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn.svm\n",
    "import skm\n",
    "import soundfile as sf\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "import localmodule\n",
    "\n",
    "\n",
    "# Define constants.\n",
    "data_dir = localmodule.get_data_dir()\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "patch_width = 32\n",
    "n_patches_per_clip = 1\n",
    "aug_str = \"original\"\n",
    "instanced_aug_str = aug_str\n",
    "log2Cs = range(-10, 10)\n",
    "\n",
    "\n",
    "# Parse arguments.\n",
    "args = [\"unit01\", \"0\"]\n",
    "test_unit_str = args[0]\n",
    "trial_id = int(args[1])\n",
    "\n",
    "\n",
    "# Retrieve fold such that test_unit_str is in the test set.\n",
    "folds = localmodule.fold_units()\n",
    "fold = [f for f in folds if test_unit_str in f[0]][0]\n",
    "test_units = fold[0]\n",
    "training_units = fold[1]\n",
    "validation_units = fold[2]\n",
    "\n",
    "\n",
    "# Print header.\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "print(\"Training SVM for \" + dataset_name + \" clips.\")\n",
    "print(\"Test Unit: \" + test_unit_str + \".\")\n",
    "print(\"Trial ID: \" + str(trial_id) + \".\")\n",
    "print(\"\")\n",
    "print(\"h5py version: {:s}\".format(h5py.__version__))\n",
    "print(\"librosa version: {:s}\".format(librosa.__version__))\n",
    "print(\"numpy version: {:s}\".format(np.__version__))\n",
    "print(\"skm version: {:s}\".format(skm.__version__))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Define input folder.\n",
    "logmelspec_name = \"_\".join([dataset_name, \"skm-logmelspec\"])\n",
    "logmelspec_dir = os.path.join(data_dir, logmelspec_name)\n",
    "aug_dir = os.path.join(logmelspec_dir, aug_str)\n",
    "\n",
    "\n",
    "# Initialize matrix of training data.\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Loop over training units.\n",
    "for train_unit_str in training_units:\n",
    "\n",
    "    # Load HDF5 container of logmelspecs.\n",
    "    hdf5_name = \"_\".join([dataset_name, instanced_aug_str, train_unit_str])\n",
    "    in_path = os.path.join(aug_dir, hdf5_name + \".hdf5\")\n",
    "    in_file = h5py.File(in_path)\n",
    "\n",
    "\n",
    "    # List clips.\n",
    "    clip_names = list(in_file[\"logmelspec\"].keys())\n",
    "\n",
    "\n",
    "    # Loop over clips.\n",
    "    for clip_name in clip_names[:100]: #UPDATE\n",
    "        # Read label.\n",
    "        y_clip = int(clip_name.split(\"_\")[3])\n",
    "\n",
    "        # Load logmelspec.\n",
    "        logmelspec = in_file[\"logmelspec\"][clip_name].value\n",
    "\n",
    "        # Load time-frequency patches.\n",
    "        logmelspec_width = logmelspec.shape[1]\n",
    "        logmelspec_mid = np.round(logmelspec_width * 0.5).astype('int')\n",
    "        logmelspec_start = logmelspec_mid -\\\n",
    "            np.round(patch_width * n_patches_per_clip * 0.5).astype('int')\n",
    "\n",
    "        # Extract patch.\n",
    "        patch_start = logmelspec_start\n",
    "        patch_stop = patch_start + patch_width\n",
    "        patch = logmelspec[:, patch_start:patch_stop]\n",
    "\n",
    "        # Ravel patch.\n",
    "        X_train.append(np.ravel(patch))\n",
    "\n",
    "        # Append label.\n",
    "        y_train.append(y_clip)\n",
    "\n",
    "            \n",
    "# Concatenate raveled patches as rows.\n",
    "X_train = np.stack(X_train)\n",
    "\n",
    "\n",
    "# Load SKM model.\n",
    "models_dir = localmodule.get_models_dir()\n",
    "model_name = \"skm-cv\"\n",
    "model_dir = os.path.join(models_dir, model_name)\n",
    "unit_dir = os.path.join(model_dir, test_unit_str)\n",
    "trial_str = \"trial-\" + str(trial_id)\n",
    "trial_dir = os.path.join(unit_dir, trial_str)\n",
    "model_name = \"_\".join([\n",
    "    dataset_name, model_name, test_unit_str, trial_str, \"model.pkl\"\n",
    "])\n",
    "model_path = os.path.join(trial_dir, model_name)\n",
    "skm_model = skm.SKM(k=256)\n",
    "skm_model = skm_model.load(model_path)\n",
    "\n",
    "\n",
    "# Transform training set.\n",
    "X_train = skm_model.transform(X_train.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =   0.000977; acc = 30.00%\n",
      "C =   0.001953; acc = 30.00%\n",
      "C =   0.003906; acc = 30.00%\n",
      "C =   0.007812; acc = 30.00%\n",
      "C =   0.015625; acc = 30.00%\n",
      "C =   0.031250; acc = 30.00%\n",
      "C =   0.062500; acc = 30.00%\n",
      "C =   0.125000; acc = 37.50%\n",
      "C =   0.250000; acc = 52.50%\n",
      "C =   0.500000; acc = 78.50%\n",
      "C =   1.000000; acc = 72.00%\n",
      "C =   2.000000; acc = 69.00%\n",
      "C =   4.000000; acc = 69.00%\n",
      "C =   8.000000; acc = 69.00%\n",
      "C =  16.000000; acc = 69.00%\n",
      "C =  32.000000; acc = 69.00%\n",
      "C =  64.000000; acc = 69.00%\n",
      "C = 128.000000; acc = 69.00%\n",
      "C = 256.000000; acc = 69.00%\n",
      "C = 512.000000; acc = 69.00%\n",
      "\n",
      "Best: C =   0.500000; acc = 78.50%\n"
     ]
    }
   ],
   "source": [
    "# Initialize matrix of validation data..\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "\n",
    "# Loop over validation units.\n",
    "for val_unit_str in validation_units:\n",
    "\n",
    "    # Load HDF5 container of logmelspecs.\n",
    "    hdf5_name = \"_\".join([dataset_name, instanced_aug_str, val_unit_str])\n",
    "    in_path = os.path.join(aug_dir, hdf5_name + \".hdf5\")\n",
    "    in_file = h5py.File(in_path)\n",
    "\n",
    "\n",
    "    # List clips.\n",
    "    clip_names = list(in_file[\"logmelspec\"].keys())\n",
    "\n",
    "\n",
    "    # Loop over clips.\n",
    "    for clip_name in clip_names[:100]:\n",
    "        # Read label.\n",
    "        y_clip = int(clip_name.split(\"_\")[3])\n",
    "\n",
    "        # Load logmelspec.\n",
    "        logmelspec = in_file[\"logmelspec\"][clip_name].value\n",
    "\n",
    "        # Load time-frequency patches.\n",
    "        logmelspec_width = logmelspec.shape[1]\n",
    "        logmelspec_mid = np.round(logmelspec_width * 0.5).astype('int')\n",
    "        logmelspec_start = logmelspec_mid -\\\n",
    "            np.round(patch_width * n_patches_per_clip * 0.5).astype('int')\n",
    "\n",
    "        # Extract patch.\n",
    "        patch_start = logmelspec_start\n",
    "        patch_stop = patch_start + patch_width\n",
    "        patch = logmelspec[:, patch_start:patch_stop]\n",
    "\n",
    "        X_val.append(np.ravel(patch))\n",
    "        y_val.append(y_clip)\n",
    "\n",
    "\n",
    "# Concatenate raveled patches as rows and transpose.\n",
    "X_val = np.stack(X_val)\n",
    "\n",
    "# Transform training set.\n",
    "X_val = skm_model.transform(X_val.T).T\n",
    "\n",
    "\n",
    "# Define CSV file for validation metrics.\n",
    "val_metrics_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    \"skm-cv\",\n",
    "    test_unit_str,\n",
    "    trial_str,\n",
    "    \"svm-model\",\n",
    "    \"val-metrics.csv\"\n",
    "])\n",
    "val_metrics_path = os.path.join(\n",
    "    trial_dir, val_metrics_name)\n",
    "\n",
    "\n",
    "# Open CSV file.\n",
    "csv_file = open(val_metrics_path, 'w')\n",
    "csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "csv_header = \n",
    "csv_writer.writerow(csv_header)\n",
    "\n",
    "\n",
    "# Loop over C (regularization parameter).\n",
    "val_accs = []\n",
    "for log2C in log2Cs:\n",
    "\n",
    "\n",
    "    # Define SVM.\n",
    "    svc = sklearn.svm.SVC(\n",
    "        C=2.0**log2C,\n",
    "        kernel='rbf',\n",
    "        degree=3,\n",
    "        gamma='auto',\n",
    "        coef0=0.0,\n",
    "        shrinking=True,\n",
    "        probability=False,\n",
    "        tol=0.001,\n",
    "        cache_size=200,\n",
    "        class_weight=None,\n",
    "        verbose=False,\n",
    "        max_iter=-1,\n",
    "        random_state=None)\n",
    "\n",
    "\n",
    "    # Train classifier.\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Save model.\n",
    "    if np.sign(1) >= 0:\n",
    "        log2C_str = \"+\" + str(abs(log2C)).zfill(2)\n",
    "    else:\n",
    "        log2C_str = \"-\" + str(abs(log2C)).zfill(2) \n",
    "    svm_name = \"_\".join([\n",
    "        dataset_name,\n",
    "        \"skm-cv\",\n",
    "        test_unit_str,\n",
    "        trial_str,\n",
    "        \"svm-model\",\n",
    "        \"log2C-(\" + log2C_str + \").pkl\"\n",
    "    ])\n",
    "    svm_path = os.path.join(trial_dir, svm_name)\n",
    "    joblib.dump(svc, svm_path) \n",
    "    \n",
    "    # Print validation score.\n",
    "    val_acc = svc.score(X_val, y_val)\n",
    "    val_accs.append(val_acc)\n",
    "    print(\"C = {:10.6f}; acc = {:5.2f}%\".format(2.0**log2C, 100*val_acc))\n",
    "\n",
    "\n",
    "# Compute best C.\n",
    "val_accs = np.array(val_accs)\n",
    "best_acc = np.max(val_accs)\n",
    "best_log2C = log2Cs[np.argmax(val_accs)]\n",
    "\n",
    "\n",
    "# Print best C.\n",
    "print(\"\")\n",
    "print(\"Best: C = {:10.6f}; acc = {:5.2f}%\".format(\n",
    "    2.0**best_log2C, 100*best_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write row.\n",
    "row = [\n",
    "    dataset_name,\n",
    "    unit_str,\n",
    "    str(trial_id),\n",
    "    str(log2_C),\n",
    "    \"{:5.2f}\".format()\n",
    "]\n",
    "csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "trial_str = \"trial-\" + str(trial_id)\n",
    "trial_dir = os.path.join(unit_dir, trial_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log10C_str = np.sign(log10C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
