{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import h5py\n",
    "import itertools\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pescador\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "import localmodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-21 19:31:41.069062 Start.\n",
      "Training Salamon's ICASSP 2017 convnet on BirdVox-70k. \n",
      "Training set: unit02, unit03, unit05.\n",
      "Validation set: unit07, unit10.\n",
      "Test set: unit01.\n",
      "\n",
      "h5py version: 2.6.0\n",
      "keras version: 2.0.6\n",
      "numpy version: 1.13.1\n",
      "pandas version: 0.20.3\n",
      "pescador version: 1.0.0\n",
      "tensorflow version: 1.2.1\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 104, 1)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 104, 1)       4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 104, 24)      624       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 26, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 26, 48)        28848     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 6, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 6, 48)         57648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 6, 48)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9217      \n",
      "=================================================================\n",
      "Total params: 96,341\n",
      "Trainable params: 96,339\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define constants.\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "folds = localmodule.fold_units()\n",
    "models_dir = localmodule.get_models_dir()\n",
    "n_input_hops = 104\n",
    "n_filters = [24, 48, 48]\n",
    "kernel_size = [5, 5]\n",
    "pool_size = [2, 4]\n",
    "n_hidden_units = 64\n",
    "steps_per_epoch = 1\n",
    "epochs = 128\n",
    "validation_steps = 1\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Read command-line arguments.\n",
    "args = [\"none\", \"unit01\", \"trial-9\"]\n",
    "aug_kind_str = args[0]\n",
    "unit_str = args[1]\n",
    "trial_str = args[2]\n",
    "\n",
    "\n",
    "# Retrieve fold such that unit_str is in the test set.\n",
    "fold = [f for f in folds if unit_str in f[0]][0]\n",
    "test_units = fold[0]\n",
    "training_units = fold[1]\n",
    "validation_units = fold[2]\n",
    "\n",
    "\n",
    "# Print header.\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "print(\"Training Salamon's ICASSP 2017 convnet on \" + dataset_name + \". \")\n",
    "print(\"Training set: \" + \", \".join(training_units) + \".\")\n",
    "print(\"Validation set: \" + \", \".join(validation_units) + \".\")\n",
    "print(\"Test set: \" + \", \".join(test_units) + \".\")\n",
    "print(\"\")\n",
    "print('h5py version: {:s}'.format(h5py.__version__))\n",
    "print('keras version: {:s}'.format(keras.__version__))\n",
    "print('numpy version: {:s}'.format(np.__version__))\n",
    "print('pandas version: {:s}'.format(pd.__version__))\n",
    "print('pescador version: {:s}'.format(pescador.__version__))\n",
    "print('tensorflow version: {:s}'.format(tf.__version__))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Define and compile Keras model.\n",
    "# NB: the original implementation of Justin Salamon in ICASSP 2017 relies on\n",
    "# glorot_uniform initialization for all layers, and the optimizer is a\n",
    "# stochastic gradient descent (SGD) with a fixed learning rate of 0.1.\n",
    "# Instead, we use a he_uniform initialization for the layers followed\n",
    "# by rectified linear units (see He ICCV 2015), and replace the SGD by\n",
    "# the Adam adaptive stochastic optimizer (see Kingma ICLR 2014).\n",
    "\n",
    "# Input\n",
    "inputs = keras.layers.Input(shape=(128, n_input_hops, 1))\n",
    "\n",
    "# Layer 1\n",
    "bn = keras.layers.normalization.BatchNormalization()(inputs)\n",
    "conv1 = keras.layers.Convolution2D(n_filters[0], kernel_size,\n",
    "    padding=\"same\", kernel_initializer=\"he_normal\")(bn)\n",
    "pool1 = keras.layers.MaxPooling2D(pool_size=pool_size)(conv1)\n",
    "\n",
    "# Layer 2\n",
    "conv2 = keras.layers.Convolution2D(n_filters[1], kernel_size,\n",
    "    padding=\"same\", kernel_initializer=\"he_normal\", activation=\"relu\")(pool1)\n",
    "pool2 = keras.layers.MaxPooling2D(pool_size=pool_size)(conv2)\n",
    "\n",
    "# Layer 3\n",
    "conv3 = keras.layers.Convolution2D(n_filters[2], kernel_size,\n",
    "    padding=\"same\", kernel_initializer=\"he_normal\", activation=\"relu\")(pool2)\n",
    "\n",
    "# Layer 4\n",
    "#flatten = keras.layers.Flatten()(conv3)\n",
    "#drop1 = keras.layers.Dropout(0.5)(flatten)\n",
    "drop1 = keras.layers.Dropout(0.5)(conv3)\n",
    "flatten = keras.layers.Flatten()(drop1)\n",
    "dense1 = keras.layers.Dense(n_hidden_units,\n",
    "    kernel_initializer=\"he_normal\", activation=\"relu\",\n",
    "    kernel_regularizer=keras.regularizers.l2(0.001))(drop1)\n",
    "\n",
    "# Layer 5\n",
    "# We put a single output instead of 43 in the original paper, because this\n",
    "# is binary classification instead of multilabel classification.\n",
    "# Furthermore, this layer contains 43 times less connections than in the\n",
    "# original paper, so we divide the l2 weight penalization by 50, which is\n",
    "# of the same order of magnitude as 43.\n",
    "# 0.001 / 50 = 0.00002\n",
    "drop2 = keras.layers.Dropout(0.5)(flatten)\n",
    "dense2 = keras.layers.Dense(1,\n",
    "    kernel_initializer=\"normal\", activation=\"sigmoid\",\n",
    "    kernel_regularizer=keras.regularizers.l2(0.00002))(drop2)\n",
    "\n",
    "\n",
    "# Compile model, print model summary.\n",
    "model = keras.models.Model(inputs=inputs, outputs=dense2)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Build Pescador streamers corresponding to log-mel-spectrograms in augmented\n",
    "# training set.\n",
    "training_streamer = localmodule.multiplex_logmelspec(\n",
    "    aug_kind_str, training_units, n_input_hops, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
