{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-26 03:30:25.320615 Start.\n",
      "Training probabilistic SVM for BirdVox-70k clips.\n",
      "Test unit: unit05.\n",
      "Trial ID: 6.\n",
      "\n",
      "h5py version: 2.6.0\n",
      "numpy version: 1.13.1\n",
      "pandas version: 0.20.3\n",
      "scikit-learn version: 0.18.2\n",
      "skm version: 0.0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import h5py\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn.preprocessing\n",
    "import sklearn.svm\n",
    "import skm\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "import localmodule\n",
    "\n",
    "\n",
    "# Define constants.\n",
    "data_dir = localmodule.get_data_dir()\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "patch_width = 32\n",
    "n_patches_per_clip = 1\n",
    "aug_str = \"original\"\n",
    "instanced_aug_str = aug_str\n",
    "\n",
    "\n",
    "# Parse arguments.\n",
    "args = [\"unit05\", \"6\"]\n",
    "test_unit_str = args[0]\n",
    "trial_id = int(args[1])\n",
    "\n",
    "\n",
    "# Print header.\n",
    "start_time = int(time.time())\n",
    "print(str(datetime.datetime.now()) + \" Start.\")\n",
    "print(\"Training probabilistic SVM for \" + dataset_name + \" clips.\")\n",
    "print(\"Test unit: \" + test_unit_str + \".\")\n",
    "print(\"Trial ID: \" + str(trial_id) + \".\")\n",
    "print(\"\")\n",
    "print(\"h5py version: {:s}\".format(h5py.__version__))\n",
    "print(\"numpy version: {:s}\".format(np.__version__))\n",
    "print(\"pandas version: {:s}\".format(pd.__version__))\n",
    "print(\"scikit-learn version: {:s}\".format(sklearn.__version__))\n",
    "print(\"skm version: {:s}\".format(skm.__version__))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Retrieve fold such that test_unit_str is in the test set.\n",
    "folds = localmodule.fold_units()\n",
    "fold = [f for f in folds if test_unit_str in f[0]][0]\n",
    "test_units = fold[0]\n",
    "training_units = fold[1]\n",
    "validation_units = fold[2]\n",
    "\n",
    "\n",
    "# Define input folder.\n",
    "logmelspec_name = \"_\".join([dataset_name, \"skm-logmelspec\"])\n",
    "logmelspec_dir = os.path.join(data_dir, logmelspec_name)\n",
    "aug_dir = os.path.join(logmelspec_dir, aug_str)\n",
    "\n",
    "\n",
    "# Initialize matrix of training data.\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "\n",
    "# Loop over training units.\n",
    "for train_unit_str in training_units:\n",
    "\n",
    "    # Load HDF5 container of logmelspecs.\n",
    "    hdf5_name = \"_\".join([dataset_name, instanced_aug_str, train_unit_str])\n",
    "    in_path = os.path.join(aug_dir, hdf5_name + \".hdf5\")\n",
    "    in_file = h5py.File(in_path)\n",
    "\n",
    "\n",
    "    # List clips.\n",
    "    clip_names = list(in_file[\"logmelspec\"].keys())\n",
    "\n",
    "\n",
    "    # Loop over clips.\n",
    "    for clip_name in clip_names:\n",
    "        # Read label.\n",
    "        y_clip = int(clip_name.split(\"_\")[3])\n",
    "\n",
    "        # Load logmelspec.\n",
    "        logmelspec = in_file[\"logmelspec\"][clip_name].value\n",
    "\n",
    "        # Load time-frequency patches.\n",
    "        logmelspec_width = logmelspec.shape[1]\n",
    "        logmelspec_mid = np.round(logmelspec_width * 0.5).astype('int')\n",
    "        logmelspec_start = logmelspec_mid -\\\n",
    "            np.round(patch_width * n_patches_per_clip * 0.5).astype('int')\n",
    "\n",
    "        # Extract patch.\n",
    "        patch_start = logmelspec_start\n",
    "        patch_stop = patch_start + patch_width\n",
    "        patch = logmelspec[:, patch_start:patch_stop]\n",
    "\n",
    "        # Ravel patch.\n",
    "        X_train.append(np.ravel(patch))\n",
    "\n",
    "        # Append label.\n",
    "        y_train.append(y_clip)\n",
    "\n",
    "\n",
    "# Concatenate raveled patches as rows.\n",
    "X_train = np.stack(X_train)\n",
    "\n",
    "\n",
    "# Load SKM model.\n",
    "models_dir = localmodule.get_models_dir()\n",
    "model_name = \"skm-cv\"\n",
    "model_dir = os.path.join(models_dir, model_name)\n",
    "unit_dir = os.path.join(model_dir, test_unit_str)\n",
    "trial_str = \"trial-\" + str(trial_id)\n",
    "trial_dir = os.path.join(unit_dir, trial_str)\n",
    "model_name = \"_\".join([\n",
    "    dataset_name, model_name, test_unit_str, trial_str, \"model.pkl\"\n",
    "])\n",
    "model_path = os.path.join(trial_dir, model_name)\n",
    "skm_model = skm.SKM(k=256)\n",
    "skm_model = skm_model.load(model_path)\n",
    "\n",
    "\n",
    "# Transform training set with SKM.\n",
    "X_train = skm_model.transform(X_train.T).T\n",
    "\n",
    "\n",
    "# Load standardizer.\n",
    "scaler_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    \"skm-cv\",\n",
    "    test_unit_str,\n",
    "    trial_str,\n",
    "    \"scaler.pkl\"\n",
    "])\n",
    "scaler_path = os.path.join(trial_dir, scaler_name)\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "\n",
    "# Standardize training set.\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "# Define CSV file for validation metrics.\n",
    "val_metrics_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    \"skm-cv\",\n",
    "    test_unit_str,\n",
    "    trial_str,\n",
    "    \"svm-model\",\n",
    "    \"val-metrics.csv\"\n",
    "])\n",
    "csv_header = [\n",
    "    \"Dataset\",\n",
    "    \"Test unit\",\n",
    "    \"Trial ID\",\n",
    "    \"log2(C)\",\n",
    "    \"Validation accuracy (%)\"\n",
    "]\n",
    "val_metrics_path = os.path.join(\n",
    "    trial_dir, val_metrics_name)\n",
    "\n",
    "\n",
    "# Open CSV file as Pandas DataFrame.\n",
    "val_metrics_df = pd.read_csv(val_metrics_path, header=None, names=csv_header)\n",
    "\n",
    "\n",
    "# Find C maximizing validation accuracy.\n",
    "max_val_acc = np.max(val_metrics_df[\"Validation accuracy (%)\"])\n",
    "best_log2C = val_metrics_df[\"log2(C)\"][np.argmax(val_metrics_df[\"Validation accuracy (%)\"])]\n",
    "\n",
    "\n",
    "# Define SVM model.\n",
    "svc = sklearn.svm.SVC(\n",
    "    C=2.0**best_log2C,\n",
    "    kernel='rbf',\n",
    "    degree=3,\n",
    "    gamma='auto',\n",
    "    coef0=0.0,\n",
    "    shrinking=True,\n",
    "    probability=True,\n",
    "    tol=0.001,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    random_state=None)\n",
    "\n",
    "\n",
    "# Train SVM model.\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Save SVM model.\n",
    "if np.sign(best_log2C) >= 0:\n",
    "    best_log2C_str = \"+\" + str(abs(best_log2C)).zfill(2)\n",
    "else:\n",
    "    best_log2C_str = \"-\" + str(abs(best_log2C)).zfill(2)\n",
    "svm_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    \"skm-cv\",\n",
    "    test_unit_str,\n",
    "    trial_str,\n",
    "    \"svm-proba-model\",\n",
    "    \"log2C-(\" + best_log2C_str + \").pkl\"\n",
    "])\n",
    "svm_path = os.path.join(trial_dir, svm_name)\n",
    "joblib.dump(svc, svm_path)\n",
    "\n",
    "\n",
    "# Initialize matrix of test data.\n",
    "X_test = []\n",
    "y_test_true = []\n",
    "\n",
    "\n",
    "# Load HDF5 container of logmelspecs.\n",
    "hdf5_name = \"_\".join([dataset_name, instanced_aug_str, test_unit_str])\n",
    "in_path = os.path.join(aug_dir, hdf5_name + \".hdf5\")\n",
    "in_file = h5py.File(in_path)\n",
    "\n",
    "\n",
    "# List clips.\n",
    "clip_names = list(in_file[\"logmelspec\"].keys())\n",
    "\n",
    "\n",
    "# Loop over clips.\n",
    "for clip_name in clip_names:\n",
    "    # Read label.\n",
    "    y_clip = int(clip_name.split(\"_\")[3])\n",
    "\n",
    "    # Load logmelspec.\n",
    "    logmelspec = in_file[\"logmelspec\"][clip_name].value\n",
    "\n",
    "    # Load time-frequency patches.\n",
    "    logmelspec_width = logmelspec.shape[1]\n",
    "    logmelspec_mid = np.round(logmelspec_width * 0.5).astype('int')\n",
    "    logmelspec_start = logmelspec_mid -\\\n",
    "        np.round(patch_width * n_patches_per_clip * 0.5).astype('int')\n",
    "\n",
    "    # Extract patch.\n",
    "    patch_start = logmelspec_start\n",
    "    patch_stop = patch_start + patch_width\n",
    "    patch = logmelspec[:, patch_start:patch_stop]\n",
    "\n",
    "    # Ravel patch.\n",
    "    X_test.append(np.ravel(patch))\n",
    "\n",
    "    # Append label.\n",
    "    y_test_true.append(y_clip)\n",
    "\n",
    "\n",
    "# Concatenate raveled patches as rows.\n",
    "X_test = np.stack(X_test)\n",
    "\n",
    "\n",
    "# Transform test set with SKM.\n",
    "X_test = skm_model.transform(X_test.T).T\n",
    "\n",
    "\n",
    "# Standardize test set.\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Predict.\n",
    "y_test_pred = svc.predict(X_test)\n",
    "\n",
    "\n",
    "# Create CSV file.\n",
    "model_name = \"skm-proba\"\n",
    "predict_unit_str = test_unit_str\n",
    "prediction_name = \"_\".join([dataset_name, model_name,\n",
    "    \"test-\" + test_unit_str, trial_str, \"predict-\" + predict_unit_str,\n",
    "    \"clip-predictions\"])\n",
    "prediction_path = os.path.join(trial_dir, prediction_name + \".csv\")\n",
    "csv_file = open(prediction_path, 'w')\n",
    "csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "\n",
    "\n",
    "# Create CSV header.\n",
    "csv_header = [\"Dataset\", \"Test unit\", \"Prediction unit\", \"Timestamp\",\n",
    "    \"Key\", \"Predicted probability\"]\n",
    "csv_writer.writerow(csv_header)\n",
    "\n",
    "\n",
    "# Loop over keys.\n",
    "for clip_id, key in enumerate(clip_names[:1000]):\n",
    "    # Store prediction as DataFrame row.\n",
    "    key_split = key.split(\"_\")\n",
    "    timestamp_str = key_split[1]\n",
    "    freq_str = key_split[2]\n",
    "    ground_truth_str = key_split[3]\n",
    "    aug_str = key_split[4]\n",
    "    predicted_probability = y_test_pred[clip_id]\n",
    "    predicted_probability_str = \"{:.16f}\".format(predicted_probability)\n",
    "    row = [dataset_name, test_unit_str, predict_unit_str, timestamp_str,\n",
    "         freq_str, aug_str, key, ground_truth_str, predicted_probability_str]\n",
    "    csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "# Close CSV file.\n",
    "csv_file.close()\n",
    "\n",
    "\n",
    "# Print score.\n",
    "print(\"Accuracy = {:5.2f}\".format(\n",
    "    100 * sklearn.metrics.accuracy_score(y_test_pred, y_test_true)))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Print elapsed time.\n",
    "print(str(datetime.datetime.now()) + \" Finish.\")\n",
    "elapsed_time = time.time() - int(start_time)\n",
    "elapsed_hours = int(elapsed_time / (60 * 60))\n",
    "elapsed_minutes = int((elapsed_time % (60 * 60)) / 60)\n",
    "elapsed_seconds = elapsed_time % 60.\n",
    "elapsed_str = \"{:>02}:{:>02}:{:>05.2f}\".format(elapsed_hours,\n",
    "                                               elapsed_minutes,\n",
    "                                               elapsed_seconds)\n",
    "print(\"Total elapsed time: \" + elapsed_str + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10528"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
