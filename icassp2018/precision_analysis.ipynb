{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import h5py\n",
    "import librosa\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import peakutils\n",
    "import scipy.signal\n",
    "import soundfile as sf\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import localmodule\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define constants.\n",
    "data_dir = localmodule.get_data_dir()\n",
    "dataset_name = localmodule.get_dataset_name()\n",
    "models_dir = localmodule.get_models_dir()\n",
    "units = localmodule.get_units()\n",
    "n_units = len(units)\n",
    "n_false_alarms = 20\n",
    "test_unit_id = 2\n",
    "aug_kind_str = \"all\"\n",
    "\n",
    "threshold_ids =\\\n",
    "      [[103, 102,  79, 115,   0,  91,   0, 106,   0, 135],\n",
    "       [205,   0, 207,   0, 189, 170, 206, 193, 191, 184],\n",
    "       [143,   0, 137, 150,   0, 158,   0, 145, 154, 118],\n",
    "       [130, 158,   0, 136, 162, 133, 174, 134, 158, 140],\n",
    "       [134, 131, 203, 126, 140, 131, 123, 121, 125, 139],\n",
    "       [159, 186, 130, 133, 140, 161, 170, 141, 166, 168]]\n",
    "threshold_ids = np.array(threshold_ids)\n",
    "\n",
    "trials =\\\n",
    "      [[4, 8, 9, 6, 3, 0, 2, 1, 5, 7],\n",
    "       [1, 3, 0, 9, 2, 6, 4, 8, 5, 7],\n",
    "       [1, 4, 6, 8, 0, 9, 7, 5, 3, 2],\n",
    "       [2, 9, 1, 5, 6, 3, 4, 8, 7, 0],\n",
    "       [2, 8, 1, 0, 4, 9, 5, 7, 3, 6],\n",
    "       [4, 9, 8, 6, 1, 2, 5, 3, 7, 0]]\n",
    "trials = np.array(trials)\n",
    "\n",
    "thresholds = 1.0 - np.concatenate((\n",
    "    np.logspace(-9, -2, 141), np.delete(np.logspace(-2, 0, 81), 0)\n",
    "))\n",
    "n_thresholds = len(thresholds)\n",
    "\n",
    "tolerance = 0.5 # in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992920542156 7898 9113 3112\n"
     ]
    }
   ],
   "source": [
    "# Define directory for annotations.\n",
    "annotations_name = \"_\".join([dataset_name, \"annotations\"])\n",
    "annotations_dir = os.path.join(data_dir, annotations_name)\n",
    "\n",
    "\n",
    "# Load annotation.\n",
    "test_unit_str = units[test_unit_id]\n",
    "annotation_path = os.path.join(annotations_dir,\n",
    "    test_unit_str + \".txt\")\n",
    "annotation = pd.read_csv(annotation_path, '\\t')\n",
    "begin_times = np.array(annotation[\"Begin Time (s)\"])\n",
    "end_times = np.array(annotation[\"End Time (s)\"])\n",
    "relevant = 0.5 * (begin_times + end_times)\n",
    "relevant = np.sort(relevant)\n",
    "high_freqs = np.array(annotation[\"High Freq (Hz)\"])\n",
    "low_freqs = np.array(annotation[\"Low Freq (Hz)\"])\n",
    "mid_freqs = 0.5 * (high_freqs + low_freqs)\n",
    "n_relevant = len(relevant)\n",
    "\n",
    "\n",
    "# Define directory for model.\n",
    "aug_str = \"all\"\n",
    "model_name = \"icassp-convnet\"\n",
    "if not aug_kind_str == \"none\":\n",
    "    model_name = \"_\".join([model_name, \"aug-\" + aug_kind_str])\n",
    "model_dir = os.path.join(models_dir, model_name)\n",
    "\n",
    "\n",
    "# Select trial maximizing validation accuracy.\n",
    "trial_id = trials[test_unit_id, -1]\n",
    "\n",
    "\n",
    "# Selet threshold maximizing validation accuracy.\n",
    "threshold_id = threshold_ids[test_unit_id, trial_id]\n",
    "\n",
    "\n",
    "# Load prediction.\n",
    "test_unit_str = units[test_unit_id]\n",
    "unit_dir = os.path.join(model_dir, test_unit_str)\n",
    "trial_str = \"trial-\" + str(trial_id)\n",
    "trial_dir = os.path.join(unit_dir, trial_str)\n",
    "prediction_name = \"_\".join([\n",
    "    dataset_name,\n",
    "    model_name,\n",
    "    \"test-\" + test_unit_str,\n",
    "    trial_str,\n",
    "    \"predict-\" + test_unit_str,\n",
    "    \"full-predictions.csv\"])\n",
    "prediction_path = os.path.join(trial_dir, prediction_name)\n",
    "prediction_df = pd.read_csv(prediction_path)\n",
    "odf = np.array(prediction_df[\"Predicted probability\"])\n",
    "timestamps = np.array(prediction_df[\"Timestamp\"])\n",
    "\n",
    "\n",
    "# Select peaks.\n",
    "threshold = thresholds[threshold_id]\n",
    "peak_locations = peakutils.indexes(odf, thres=threshold, min_dist=3)\n",
    "selected = timestamps[peak_locations]\n",
    "\n",
    "\n",
    "# Match events.\n",
    "selected_relevant = mir_eval.util.match_events(relevant, selected, tolerance)\n",
    "tp_relevant_ids = list(zip(*selected_relevant))[0]\n",
    "tp_relevant_times = [relevant[i] for i in tp_relevant_ids]\n",
    "tp_selected_ids = list(zip(*selected_relevant))[1]\n",
    "tp_selected_times = [selected[i] for i in tp_selected_ids]\n",
    "\n",
    "\n",
    "# Find false negatives\n",
    "fn_times = [relevant[i] for i in range(len(relevant))\n",
    "    if i not in tp_relevant_ids]\n",
    "\n",
    "\n",
    "# Sample false alarms uniformly in relative time (*not* physical time)\n",
    "downsampling = int(len(fn_times) / n_false_alarms)\n",
    "fa_times = fn_times[::downsampling]\n",
    "if len(fa_times) > n_false_alarms:\n",
    "    fa_times = fa_times[:n_false_alarms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1207.4754380000002,\n",
       " 6287.2804070000002,\n",
       " 9088.526170000001,\n",
       " 14003.949269999999,\n",
       " 20273.97006,\n",
       " 24354.39515,\n",
       " 28633.012220000001,\n",
       " 32685.898550000002,\n",
       " 34836.239730000001,\n",
       " 36661.494579999999,\n",
       " 37677.98173,\n",
       " 38217.127869999997,\n",
       " 38345.342089999998,\n",
       " 38459.4833,\n",
       " 38531.461760000006,\n",
       " 38598.28787,\n",
       " 38696.585269999996,\n",
       " 38777.065819999996,\n",
       " 38852.247019999995,\n",
       " 38954.255410000005]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
